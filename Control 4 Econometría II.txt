Universidad de Lima
Facultad de Ciencias Empresariales y EconÃ³micas
Carrera de EconomÃ­a

Resumen Control 4: Lecturas semanas 10-13
Curso: EconometrÃ­a 2

â€œHe insistido en que la econometrÃ­a debe tener relevancia en realidades
concretas, de lo contrario degenera en algo que no merece el nombre de
econometrÃ­a, sino que mÃ¡s bien deberÃ­a llamarse 'jugometrÃ­a.â€
-Ragnar Frisch.

Profesor
Jose Luis Nolazco Cama
Julio de 2024

Lima â€“ PerÃº

INTRODUCTION (BALTAGI CAP 1)
1.1. PANEL DATA: ALGUNOS EJEMPLOS
os datos de panel se refieren a la combinaciÃ³n de observaciones sobre un mismo grupo de individuos,
paÃ­ses, empresas, etc., a lo largo de varios periodos de tiempo. Este tipo de datos permite seguir a los
mismos sujetos a lo largo del tiempo, proporcionando una visiÃ³n mÃ¡s rica y detallada de los fenÃ³menos
estudiados en comparaciÃ³n con estudios transversales o de series temporales puras. A continuaciÃ³n, se
comentarÃ¡n ciertos estudios de ejemplo.
En Estados Unidos, los datos de panel incluyen estudios significativos como el Panel Study of Income
Dynamics (PSID), iniciado en 1968, que sigue a familias y sus descendientes para recoger datos sobre
ingresos, empleo y salud, cubriendo mÃ¡s de 65,000 individuos hasta 2003 con entrevistas anuales hasta
1996 y bianuales desde 1997. El National Longitudinal Surveys (NLS) documenta transiciones
importantes en la vida de jÃ³venes, incluyendo grupos como NLSY97 y NLSY79, y ha estudiado a hijos
biolÃ³gicos de mujeres desde 1967. La Current Population Survey (CPS), realizada mensualmente por la
Oficina del Censo, tiene una muestra mÃ¡s grande y representativa, aunque con menos variables y menor
cobertura temporal comparada con PSID y NLS, proporcionando datos extensivos durante mÃ¡s de 50
aÃ±os.
En Europa, ejemplos destacados de datos de panel incluyen el German Socio-Economic Panel (GSOEP),
iniciado en 1984, que recopila datos demogrÃ¡ficos y socioeconÃ³micos en Alemania Occidental y
Oriental desde 1990, con una baja tasa de desgaste. El British Household Panel Survey (BHPS),
comenzado en 1991, recoge anualmente datos sobre demografÃ­a, mercado laboral y salud en alrededor
de 5500 hogares britÃ¡nicos. El European Community Household Panel (ECHP), coordinado por Eurostat
desde 1994, cubre varios paÃ­ses de la UE y proporciona informaciÃ³n comparable sobre ingresos, empleo
y pobreza, vinculÃ¡ndose a paneles nacionales existentes o corriendo en paralelo a ellos para obtener
datos homogÃ©neos entre los paÃ­ses miembros.
1.2 Â¿POR QUÃ‰ DEBERIAMOS USAR PANEL DATA? SUS BENEFICIOS Y LIMITACIONES
Beneficios de los Datos de Panel
1. Control de Heterogeneidad Individual: Permiten controlar efectos especÃ­ficos de individuos,
empresas o paÃ­ses que no varÃ­an en el tiempo, evitando sesgos. Por ejemplo, en un estudio sobre la
demanda de cigarrillos, se pueden controlar variables como la religiÃ³n o el nivel educativo.
2. Datos MÃ¡s Informativos: Ofrecen mayor variabilidad y menos colinealidad entre las variables, con
mÃ¡s grados de libertad y eficiencia en las estimaciones. Permiten descomponer la variabilidad en
variaciÃ³n entre individuos y dentro de los individuos a lo largo del tiempo.
3. Estudio de DinÃ¡micas de Ajuste: Permiten analizar la duraciÃ³n de estados econÃ³micos como el
desempleo y la pobreza, evaluando la duraciÃ³n y velocidad de los cambios econÃ³micos. Adecuados para
estudiar la duraciÃ³n del desempleo y la movilidad residencial e ingresos.
4. IdentificaciÃ³n de Efectos No Detectables en Datos Transversales o Temporales Puros: Permiten
observar cambios individuales en el tiempo, como determinar si la membresÃ­a sindical afecta los salarios
o diferenciar patrones de participaciÃ³n laboral.
5. Modelos Comportamentales MÃ¡s Complejos: Facilitan la construcciÃ³n y prueba de modelos de
comportamiento mÃ¡s complejos que los datos transversales o de series temporales puras, como estudiar
la eficiencia tÃ©cnica de las empresas a lo largo del tiempo.
6. MediciÃ³n MÃ¡s Precisa a Nivel Micro: Los datos de panel a nivel micro son mÃ¡s precisos que las
variables medidas a nivel macro, reduciendo o eliminando sesgos de agregaciÃ³n de datos.
7. Pruebas de RaÃ­ces Unitarias y CointegraciÃ³n: Permiten realizar pruebas de raÃ­ces unitarias y
cointegraciÃ³n con distribuciones asintÃ³ticas estÃ¡ndar, una ventaja sobre las pruebas en series temporales
puras.

Limitaciones de los Datos de Panel
1. Problemas de DiseÃ±o y RecopilaciÃ³n de Datos: Incluyen problemas de cobertura, no respuesta,
errores de memoria, frecuencia de entrevistas y manejo de datos.
2. Errores de MediciÃ³n: Respuestas inexactas debido a preguntas poco claras, distorsiÃ³n deliberada,
informantes inapropiados y errores de registro por parte de los entrevistadores.
3. Problemas de Selectividad: AutoselecciÃ³n, donde los individuos eligen no participar o trabajar,
introduciendo sesgos en las muestras. La falta de cooperaciÃ³n de los encuestados resulta en no respuesta
y pÃ©rdida de datos, mientras que la atriciÃ³n, o pÃ©rdida de participantes a lo largo del tiempo, puede
afectar la representatividad del panel.
4. DimensiÃ³n Temporal Corta: Los paneles de microdatos suelen cubrir periodos cortos, limitando los
anÃ¡lisis a largo plazo. Aumentar el periodo de tiempo puede incrementar la atriciÃ³n y la dificultad
computacional para modelos con variables dependientes limitadas.
5. Dependencia Transversal: Los paneles macro que no consideran la dependencia entre paÃ­ses pueden
conducir a inferencias errÃ³neas. Es crucial considerar la dependencia transversal en paneles macro para
obtener conclusiones vÃ¡lidas.

THE ONE-WAY ERROR COMPONENT REGRESSION MODEL (BALTAGI CAP 2)
2.1. INTRODUCCIÃ“N
Una regresiÃ³n con datos de panel se diferencia de una regresiÃ³n tÃ­pica de series temporales o de corte
transversal porque tiene un doble subÃ­ndice en sus variables:

AquÃ­, ğ‘– denota hogares, individuos, empresas, paÃ­ses, etc., y ğ‘¡ denota tiempo. Por lo tanto, ğ‘– representa
la dimensiÃ³n de corte transversal, mientras que t representa la dimensiÃ³n de series temporales. En esta
ecuaciÃ³n, ğ›¼ es un escalar, ğ›½ es un vector de ğ¾ Ã— 1ğ¾, y ğ‘‹ğ‘–ğ‘¡ es la observaciÃ³n ğ‘–ğ‘¡ sobre ğ¾ variables
explicativas.
Modelo de Error de Componente Ãšnico
La mayorÃ­a de las aplicaciones de datos de panel utilizan un modelo de error de componente Ãºnico para
las perturbaciones, como en el caso de ğ‘¦ğ‘–ğ‘¡ de arriba, este error decomponente Ãºnico se expresa asÃ­:
ğ’–ğ’Šğ’• = ğğ’Š + ğ‚ğ’Šğ’• (ğŸ. ğŸ)
Donde ğœ‡ğ‘– denota el efecto especÃ­fico no observable de cada individuo y ğ‘£ğ‘–ğ‘¡ denota la perturbaciÃ³n
residual.
Por ejemplo, en una ecuaciÃ³n de ingresos en economÃ­a laboral, ğ‘¦ğ‘–ğ‘¡ medirÃ¡ los ingresos del jefe del hogar,
mientras que ğ‘‹ğ‘–ğ‘¡ puede contener variables como experiencia, educaciÃ³n, sexo, raza, etc. En este caso,
ğœ‡ğ‘– serÃ­a invariante en el tiempo y representa cualquier efecto especÃ­fico del individuo que no estÃ©
incluido en la regresiÃ³n, como la habilidad no observada del individuo. Mientras que la perturbaciÃ³n
residual ğœˆğ‘–ğ‘¡ varÃ­a entre individuos y tiempo y puede ser vista como la perturbaciÃ³n usual en la regresiÃ³n.
RepresentaciÃ³n en Forma Vectorial
La ecuaciÃ³n (2.1) puede ser escrita en forma vectorial como:

Donde ğ‘¦ es un vector de dimensiÃ³n ğ‘ğ‘‡ Ã— 1, ğ‘‹ es una matriz de dimensiÃ³n ğ‘ğ‘‡ Ã— ğ¾, ğ‘ = [ğœ„ğ‘ğ‘‡, ğ‘‹], ğ›¿Â´ =
(ğ›¼Â´, ğ›½Â´) y ğœ„ğ‘ğ‘‡ es un vector de unos de dimensiÃ³n ğ‘ğ‘‡.
La ecuaciÃ³n (2.2) puede ser reescrita como:

Con las ecuaciones anteriores (2.4 y 2.3) se puede encontrar P y Q, los cuales se utilizan para manejar
los datos de manera efectiva:
â€¢
â€¢

âˆ’1

La matriz P: definida como: ğ‘ƒ = ğ‘ğœ‡ (ğ‘ğœ‡â€² ğ‘ğœ‡ ) ğ‘ğœ‡â€² (dÃ³nde ğ‘ğœ‡ es la matriz de dummys.) Promedia
las observaciones a lo largo del tiempo para cada individuo.
La matriz Q: definida como: ğ‘„ = ğ¼ğ‘ğ‘‡ âˆ’ ğ‘ƒ, obtiene las desviaciones de las observaciones
respecto a sus medias individuales.

Ambas matrices son idempotentes y simÃ©tricas (si se multiplica por la misma, sale la misma matriz) y
la suma de sus rangos es igual a su traza (ğ‘Ÿğ‘ğ‘›ğ‘˜(ğ‘ƒ) = ğ‘¡ğ‘Ÿ(ğ‘ƒ) = ğ‘) y ğ‘Ÿğ‘ğ‘›ğ‘˜(ğ‘„) = ğ‘¡ğ‘Ÿ(ğ‘„) = ğ‘(ğ‘‡ âˆ’ 1)
AdemÃ¡s, ğ‘ƒ y ğ‘„ son ortogonales (ğ‘ƒğ‘„ = 0), y su suma es la matriz identidad (ğ‘ƒ + ğ‘„ = ğ¼ğ‘ğ‘‡).
2.2 EL MODELO DE EFECTOS FIJOS
En el anÃ¡lisis de datos de panel, el modelo de efectos fijos asume que los ğœ‡ğ‘– son parÃ¡metros fijos para
estimar y que las perturbaciones residuales ğœˆğ‘–ğ‘¡ son independientes e idÃ©nticamente distribuidas (IID)
con media cero y varianza ğœ 2 . Las variables ğ‘‹ğ‘–ğ‘¡ se asumen independientes de ğœˆğ‘–ğ‘¡ para todos los ğ‘– y ğ‘¡.

Este modelo es adecuado cuando se analiza un conjunto especÃ­fico de ğ‘ unidades (como empresas o
paÃ­ses) y el anÃ¡lisis se limita a este conjunto particular.
Se menciona la siguiente regresiÃ³n:

y promediando en el tiempo se obtiene:

Por lo tanto, restando (2.9) de (2.8) se obtiene:

AdemÃ¡s, el promedio de todas las observaciones en (2.8) da como resultado:

Se impone una restricciÃ³n âˆ‘ğ‘
ğ‘–=1 ğœ‡ğ‘– = 0 para evitar la multicolinealidad perfecta al incluir variables
dummy. Esta restricciÃ³n permite estimar ğ›½ y (ğ›¼ + ğœ‡ğ‘– ) pero no ğ›¼ y ğœ‡ğ‘– por separado. El estimador de
efectos fijos (FE), tambiÃ©n conocido como mÃ­nimos cuadrados con variables dummy (LSDV), puede
tener problemas cuando el nÃºmero de individuos N es grande, debido a la pÃ©rdida de grados de libertad
y la multicolinealidad entre los regresores.
Para estimar los parÃ¡metros del modelo, se realiza una regresiÃ³n de mÃ­nimos cuadrados ordinarios (OLS)
en un modelo transformado que elimina los efectos individuales, conocida como la transformaciÃ³n
â€œwithinâ€, que permite obtener estimaciones consistentes de los parÃ¡metros de interÃ©s (ğ›¼ ğ‘¦ ğ›½) al reducir
la dimensionalidad del problema.
El modelo tambiÃ©n permite la obtenciÃ³n de estimaciones robustas de los errores estÃ¡ndar utilizando
mÃ©todos como los propuestos por Arellano, que consiste en apilar el panel como una ecuaciÃ³n para cada
individuo y luego realizar la transformaciÃ³n Within en estas ecuaciones, obteniendo el estimador Within
de ğ›½ con distribuciÃ³n asintÃ³tica.
El modelo de efectos fijos es especialmente Ãºtil cuando se trata de paneles grandes, ya que puede
manejar la presencia de muchos efectos individuales (ğœ‡ğ‘– ) y proporciona estimaciones consistentes
siempre que las perturbaciones sigan las suposiciones clÃ¡sicas. Sin embargo, no puede estimar el efecto
de variables invariantes en el tiempo, como el sexo o la raza, ya que estas variables son eliminadas por
la transformaciÃ³n dentro, y si se aplica un MCO con un modelo de efectos fijos sin incluir las dummies
individuales se tendrÃ­an estimaciones sesgadas e inconsistentes por omisiÃ³n de variables relevantes
Para verificar la presencia de efectos fijos, se puede realizar una prueba F de Chow para la significancia
conjunta de las variables ficticias individuales, que compara modelos con suma de cuadrados
restringidas (RRSS) y no restringidas (URSS) para determinar la importancia de los efectos fijos.

Asimismo, se debe de considerar que Al usar la regresiÃ³n Within (2.10), es necesario ajustar las
varianzas obtenidas multiplicando la matriz de varianza-covarianza por: ğ‘  âˆ— 2/ğ‘  2
2.3 EL MODELO DE EFECTOS ALEATORIOS
El modelo de efectos aleatorios es una alternativa al modelo de efectos fijos, especialmente Ãºtil cuando
se trabaja con grandes paneles de datos. En lugar de tratar los efectos individuales (ğœ‡ğ‘– ) como constantes,
se asumen como aleatorios y se distribuyen como IID, mientras que las perturbaciones residuales (ğœˆğ‘–ğ‘¡)
se distribuyen como IID, y ambos son independientes entre sÃ­. AdemÃ¡s, las variables explicativas (ğ‘‹ğ‘–ğ‘¡ )
son independientes de ğœ‡ğ‘– y ğœˆğ‘–ğ‘¡ para todos los individuos y perÃ­odos de tiempo.

Este modelo es adecuado cuando los individuos se seleccionan aleatoriamente de una poblaciÃ³n grande,
lo cual es comÃºn en estudios de panel de hogares. En estos estudios, el nÃºmero de individuos (N) es
generalmente grande, y usar un modelo de efectos fijos podrÃ­a resultar en una significativa pÃ©rdida de
grados de libertad. El modelo de efectos aleatorios permite hacer inferencias sobre la poblaciÃ³n de la
cual se ha extraÃ­do la muestra.
SegÃºn Nerlove y Balestra (1996), la poblaciÃ³n no consiste en un nÃºmero infinito de individuos, sino en
un nÃºmero infinito de decisiones que cada individuo podrÃ­a tomar, por lo que las perturbaciones de un
mismo individuo estÃ¡n correlacionadas a lo largo del tiempo, pero no entre diferentes individuos.
Asimismo, se puede usar el mÃ©todo simplificado de Wansbeek y Kapteyn, que se basa en simplificar los
cÃ¡lculos usando una descomposiciÃ³n de la matriz de varianza-covarianza en componentes mÃ¡s
manejables, descomponiÃ©ndola en dos partes: Una que captura la varianza de los efectos aleatorios y
otra que captura la varianza de los errores residuales.
Varianza y Covarianza: En el modelo de efectos aleatorios, la varianza de las perturbaciones es la
misma para todos los individuos y perÃ­odos de tiempo. AdemÃ¡s, hay una correlaciÃ³n entre las
perturbaciones de un mismo individuo a lo largo del tiempo. Esta estructura de correlaciÃ³n permite
descomponer la matriz de varianza-covarianza en dos componentes principales, lo que facilita su
inversiÃ³n.
Fuller y Battese sugieren transformar la ecuaciÃ³n de regresiÃ³n original y luego aplicar mÃ­nimos
cuadrados ordinarios (OLS) a la ecuaciÃ³n transformada. Esto facilita la obtenciÃ³n de estimaciones
precisas de los coeficientes de regresiÃ³n. Los estimadores cuadrÃ¡ticos insesgados de las varianzas
permiten calcular eficientemente la varianza de los efectos aleatorios y de los errores residuales.
Comparado con otros mÃ©todos, el estimador GLS basado en componentes de varianza es el mejor
estimador lineal insesgado (BLUE) y es mÃ¡s eficiente en grandes paneles de datos. Estudios como los
de Maddala y Mount, y experimentos de Monte Carlo han demostrado que los distintos estimadores
GLS factibles tienen un desempeÃ±o comparable y son recomendables para su uso prÃ¡ctico.
Taylor (1980) comparÃ³ el estimador Within con el estimador GLS factible de Swamy-Arora y encontrÃ³
que el GLS factible es generalmente mÃ¡s eficiente que los mÃ­nimos cuadrados con variables dummy
(LSDV) para casi todos los grados de libertad, y su varianza nunca supera en mÃ¡s del 17% al lÃ­mite
inferior de Cramer-Rao. Sin embargo, estimadores mÃ¡s eficientes de los componentes de varianza no
siempre conducen a estimadores GLS factibles mÃ¡s eficientes. Estos resultados fueron confirmados por
experimentos de Monte Carlo realizados por Maddala y Mount (1973) y Baltagi (1981a). Bellmann,
Breitung y Wagner (1989) investigaron el sesgo en la estimaciÃ³n de componentes de varianza y
coeficientes de regresiÃ³n, encontrando un sesgo considerable en la estimaciÃ³n de ğœğœ‡2 en un panel a nivel
de industria, pero no afectando significativamente los coeficientes de regresiÃ³n.
2.3.1 Fijo vs Aleatorio
La elecciÃ³n entre los modelos de efectos fijos y aleatorios ha sido un tema de debate en biometrÃ­a,
estadÃ­sticas y econometrÃ­a de datos de panel. Mundlak (1961) y Wallace y Hussain (1969) apoyaron los
efectos fijos, mientras que Balestra y Nerlove (1966) prefirieron los efectos aleatorios. Hausman (1978)
propuso una prueba para diferenciar entre ambos modelos, pero se ha malinterpretado, ya que algunos
investigadores creen que un rechazo implica adoptar el modelo de efectos fijos y no rechazo, el de
efectos aleatorios.
Chamberlain (1984) demostrÃ³ que los efectos fijos imponen restricciones testables en los parÃ¡metros,
que deben verificarse. Mundlak (1978) seÃ±alÃ³ que los efectos aleatorios asumen exogeneidad de todos
los regresores con los efectos individuales, mientras que los efectos fijos permiten endogeneidad.
Hausman y Taylor (1981) sugirieron un enfoque intermedio, donde algunos regresores pueden estar
correlacionados con los efectos individuales. Para los investigadores aplicados, es esencial no solo
realizar pruebas bÃ¡sicas, sino tambiÃ©n verificar las restricciones del modelo de efectos fijos y considerar
la especificaciÃ³n de Hausman y Taylor como una alternativa viable.

2.4 MAXIMUM LIKELIHOOD ESTIMATION
Bajo la normalidad de las perturbaciones, se puede escribir la funciÃ³n de verosimilitud como:

Donde
En la funciÃ³n de probabilidad encontramos

:

Breusch: Muestra que este parÃ¡metro tiene una propiedad notable de formar una secuencia monÃ³tona.
A partir del estimador â€œwithinâ€ se consigue una secuencia monÃ³tona creciente. Con el estimador
â€œBetweenâ€ se consigue una secuencia monÃ³tona decreciente. Por ello debemos protegernos de un
mÃ¡ximo, para esto comenzamos con ğ›½Ìƒğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› y ğ›½Ì‚ğµğ‘’ğ‘¡ğ‘¤ğ‘’ğ‘’ğ‘› e iteramos.
Maddala: Encuentra que hay como mÃ¡ximo dos â€œmÃ¡ximosâ€ para la probabilidad 0 < ğœ™ 2 â‰¤ 1, por ello
debemos protegernos de un mÃ¡ximo local.
2.5 PREDICTION
Para predecir ğ‘† periodos futuros en un modelo de efectos aleatorios, Goldberger (1962) desarrollÃ³ un
mÃ©todo llamado Mejor Predictor Lineal Insesgado (BLUP). Este mÃ©todo utiliza la estructura de
varianza-covarianza de las perturbaciones y ajusta las predicciones con una fracciÃ³n de los residuales
de los modelos GLS. Baillie y Baltagi (1999) analizaron diferentes mÃ©todos de predicciÃ³n cuando los
componentes de varianza no son conocidos y evaluaron cuatro enfoques:
1.
2.
3.
4.

Un predictor ordinario que usa estimaciones de mÃ¡xima verosimilitud (MLE).
Un predictor truncado que ignora la correcciÃ³n del error.
Un predictor mal especificado que usa estimaciones OLS.
Un predictor de efectos fijos que asume que los efectos individuales son parÃ¡metros fijos.

Sus hallazgos indican que el predictor ordinario es superior en tÃ©rminos de error cuadrÃ¡tico medio
(MSE) en comparaciÃ³n con los predictores truncado y mal especificado, especialmente cuando la
proporciÃ³n de varianza de los efectos individuales es alta. El predictor de efectos fijos tambiÃ©n mostrÃ³
un buen desempeÃ±o, siendo casi tan efectivo como el predictor ordinario. En general, tanto el predictor
ordinario como el de efectos fijos superaron a los otros mÃ©todos y se recomiendan en las investigaciones.
En la prÃ¡ctica, es crucial considerar los efectos individuales al hacer predicciones.
2.6. EJEMPLOS
Ejemplo 1: EcuaciÃ³n de inversiÃ³n de Grunfeld
Se considerÃ³ la siguiente ecuaciÃ³n:

ğ¼ğ‘–ğ‘¡ = ğ¼ğ‘›ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘–Ã³ğ‘› ğ‘ğ‘Ÿğ‘¢ğ‘¡ğ‘ ğ‘Ÿğ‘’ğ‘ğ‘™ ğ‘‘ğ‘’ ğ‘™ğ‘ ğ‘’ğ‘šğ‘ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘– ğ‘’ğ‘› ğ‘’ğ‘™ ğ‘Ã±ğ‘œ ğ‘¡
ğ¹ğ‘–ğ‘¡ = ğ‘‰ğ‘ğ‘™ğ‘œğ‘Ÿ ğ‘Ÿğ‘’ğ‘ğ‘™ ğ‘‘ğ‘’ ğ‘™ğ‘ ğ‘’ğ‘šğ‘ğ‘Ÿğ‘’ğ‘ ğ‘ (ğ‘ğ‘ğ‘ğ‘–ğ‘œğ‘›ğ‘’ğ‘  ğ‘’ğ‘› ğ‘ğ‘–ğ‘Ÿğ‘ğ‘¢ğ‘™ğ‘ğ‘ğ‘–Ã³ğ‘›)
ğ¶ğ‘–ğ‘¡ = ğ‘‰ğ‘ğ‘™ğ‘œğ‘Ÿ ğ‘Ÿğ‘’ğ‘ğ‘™ ğ‘‘ğ‘’ğ‘™ ğ‘ğ‘ğ‘ğ‘–ğ‘¡ğ‘ğ‘™ ğ‘ ğ‘œğ‘ğ‘–ğ‘ğ‘™
Los datos son de 10 empresas grandes manufactureras durante 20 aÃ±os (1935-1954) La tabla 2.1 muestra
los OLS, Between y Whitin estimadores.

Los resultados de OLS y GLS son combinaciones ponderadas por matriz de estos estimadores. Los GLS
factibles de la regresiÃ³n son WALHUS, AMEMIYA y SWAR junto sus estimaciones correspondientes
ğœŒ , ğœğ‘¢ , ğœğ‘£ . Por otro lado, tenemos la estimaciÃ³n de mÃ¡xima verosimilitud iterativa de Breusch (1987)
(IMLE) donde converge a un mÃ¡ximo global de 3 o cuatro iteraciones dependiendo del estimador.
La tabla 2.2 muestra al estimador Wallace and Hussain (1969) como una opciÃ³n dentro del
procedimiento de datos de panel de efectos aleatorios.

La tabla 2.3 muestra el procedimiento Amemiya (1971), que se denomina Wansbeek and Kapteyn (1989)
por tratar con paneles desequilibrados o incompletos. Asimismo, la tabla 2.4 presenta el procedimiento
de Swamy y Arora (1972). Donde ğœğ‘£ es 52.77 y Ï es 0.72 por ello Î¸ es 0.86

La estimaciÃ³n de mÃ¡xima verosimilitud iterativa de Breusch (1987) se realizÃ³, convergiendo a un
mÃ¡ximo global en tres a cuatro iteraciones dependiendo del punto de inicio (estimadores Between o
Within). No hay mucha diferencia entre las estimaciones GLS factibles y la MLE iterativa; todas estÃ¡n
cerca de las estimaciones Within, lo cual es comprensible dado que Î¸ para estos estimadores es cercano
a 1.
Ejemplo 2: Demanda de Gasolina
Baltagi y Griffin (1983) consideraron la siguiente ecuaciÃ³n de demanda de gasolina

Donde Gas/car es el consumo de gasolina de motor por automÃ³vil, Y/N es el ingreso real percapita,
PMG/PGDP es el precio real de la gasolina para automÃ³viles y Car/N denota la cantidad de

automÃ³viles per cÃ¡pita. La muestra son observaciones anuales en 18 paÃ­ses de la OCDE (1960-1978).
La Tabla 2.5 presenta las estimaciones de parÃ¡metros para OLS, Between, Within y tres estimaciones
GLS factibles de los coeficientes y las estimaciones correspondientes de Ï, ÏƒÂµ y ÏƒÎ½.

AdemÃ¡s, la mÃ¡xima verosimilitud iterativa de Breusch (1987) convergiÃ³ a un mÃ¡ximo global en cuatro
a seis iteraciones. El procedimiento SWAR, ÏƒÂµ = 0.196, ÏƒÎ½ = 0.092, Ï = 0.82 y Î¸ = 0.89. Una vez mÃ¡s,
las estimaciones de Î¸ estÃ¡n mÃ¡s cerca de 1 que de 0, lo que explica por quÃ© GLS factible estÃ¡ mÃ¡s
cerca del estimador Within que del estimador OLS.
Ejemplo 3: Productividad del capital pÃºblico
Munnell (1990), Baltagi y Pinnoi (1995) consideraron la siguiente relaciÃ³n de funciÃ³n de producciÃ³n
Cobb-Douglas que investiga la productividad del capital pÃºblico en la producciÃ³n privada:

En este ejemplo se analiza el producto bruto estatal (Y) de 48 estados contiguos de EE.UU. durante
1970-1986, considerando:
â€¢
â€¢
â€¢
â€¢

K1 (capital pÃºblico, incluyendo carreteras, calles, instalaciones de agua y alcantarillado, y otros
edificios y estructuras pÃºblicas)
K2 (capital privado, basado en estimaciones nacionales del Bureau of Economic Analysis)
L (insumo laboral medido como empleo en nÃ³minas no agrÃ­colas)
Unemp (tasa de desempleo estatal para capturar los efectos del ciclo econÃ³mico).

La Tabla 2.6 muestra estimaciones de un modelo de componente de error unidireccional, donde los
estimadores OLS y Between indican que el capital pÃºblico es productivo y significativo, mientras que
los estimadores Within y GLS factibles lo consideran insignificante, como tambiÃ©n encontrÃ³ HoltzEakin (1994).

Las Tablas 2.7 y 2.8 reproducen las estimaciones Between y Within usando Stata, destacando una
prueba F significativa para los efectos estatales, indicando que las estimaciones OLS sufren de omisiÃ³n
de variables. Se trata de la prueba F descrita en (2.12). Comprueba si todos los coeficientes de las

variables ficticias estatales son iguales y, en este caso, arroja un F(47.764) = 75,82, que es
estadÃ­sticamente significativo. Esto indica que las variables ficticias estatales son significativas
conjuntamente.

La Tabla 2.9 presenta el estimador de efectos aleatorios de Swamy y Arora (1972) y la Tabla 2.10
muestra el estimador de mÃ¡xima verosimilitud, ambos obtenidos con Stata. Estos resultados resaltan la
importancia de considerar los efectos especÃ­ficos del estado y elegir el mÃ©todo de estimaciÃ³n adecuado
en anÃ¡lisis de datos de panel.

Nota: FÃ­jense que uno utiliza el comando â€œreâ€ y el otro el comando â€œmleâ€

THE TWO-WAY ERROR COMPONENT REGRESSION MODEL (BALTAGI CAP 3)
3.1 INTRODUCCIÃ“N
Wallace y Hussain (1969), Nerlove (1971b) y Amemiya (1971), entre otros, consideraron el modelo de
regresiÃ³n dado por (2.1), pero con perturbaciones de componentes de error bidireccional.

donde ğœ‡ğ‘– representa el efecto individual no observable, ğœ†ğ‘¡ el efecto temporal no observable, y ğœˆğ‘–ğ‘¡ el
tÃ©rmino de perturbaciÃ³n residual. ğœ†ğ‘¡ es invariante para el individuo y captura efectos especÃ­ficos del
tiempo no incluidos en la regresiÃ³n, por ejemplo, huelgas, embargos de petrÃ³leo o leyes contra el tabaco
que pueden afectar el comportamiento de consumo.
De forma vectorial, esto se representa como:

3.2 EL MODELO DE FIJACIÃ“N DE ERRORES:
El modelo de fijaciÃ³n de errores para datos de panel estima parÃ¡metros fijos ğœ‡ğ‘– y ğœ†ğ‘¡ y maneja
perturbaciones estocÃ¡sticas ğœˆğ‘¡ que son independientes e idÃ©nticamente distribuidas (IID). La inferencia
es especÃ­fica para los individuos y periodos de tiempo observados.
Usar muchas variables dummy en regresiones grandes causa pÃ©rdida de grados de libertad y
multicolinealidad. En vez de invertir grandes matrices, se utiliza la transformaciÃ³n "Within" para obtener
estimaciones de efectos fijos, eliminando diferencias individuales.
El estimador Within no puede estimar variables invariantes en el tiempo e individuos, ya que la
transformaciÃ³n ğ‘„ las elimina. Las estimaciones por OLS son sesgadas si ignoran los efectos fijos
bidireccionales.
La ecuaciÃ³n muestra la transformaciÃ³n ğ‘„:

Esta transformaciÃ³n elimina las medias individuales y temporales, aislando las variaciones dentro de
cada unidad observacional y periodo.
3.2.1 Testeo para errores fijos
Para realizar el testeo de errores fijos y la significancia conjunta de las variables dummy, se pueden
probar dos hipÃ³tesis:
HipÃ³tesis Nula: Todos los efectos individuales y de tiempo son cero

HipÃ³tesis Alternativa: Solo los efectos individuales son cero, permitiendo efectos de tiempo:

Las sumas de cuadrados residuales restringidas (RSS) se obtienen usando el modelo de mÃ­nimos
cuadrados ordinarios agrupados (pooled OLS), mientras que las sumas de cuadrados residuales no
restringidas (URSS) provienen de la regresiÃ³n Within.
El URSS es la suma de los residuos al cuadrado del estimador Within, mientras que el RSS se calcula
usando solo las dummies de series temporales. La regresiÃ³n usada para esto es:

El RRSS se obtiene de la regresiÃ³n en (2.10), mientras que el URSS se obtiene de la regresiÃ³n completa.:

En este caso, el estadÃ­stico F resultante es ğ¹3~ğ»0 ğ¹(ğ‘¡ âˆ’ 1), (ğ‘ âˆ’ 1)(ğ‘¡ âˆ’ 1) âˆ’ ğ¾.
3.3 EL MODELO DE EFECTOS ALEATORIOS
El modelo de efectos aleatorios asume que ğœ‡ğ‘– , ğœ†ğ‘¡ y ğœˆğ‘–ğ‘¡ son independientes entre sÃ­ e IID. AdemÃ¡s, ğ‘‹ğ‘–ğ‘¡
es independiente de ğœ‡ğ‘– , ğœ†ğ‘¡ y ğ‘£ğ‘–ğ‘¡ para todo ğ‘– y ğ‘¡. La inferencia en este caso se refiere a la gran poblaciÃ³n
de la cual se extrajo esta muestra aleatoriamente. A partir de (3.2), se puede calcular la matriz de
varianza-covarianza.

Para obtener esta matriz, se reemplazan tÃ©rminos por sus correspondientes matrices y se reordenan,
llegando a:

AquÃ­, ğœ†ğ‘– son las raÃ­ces caracterÃ­sticas distintivas de Î© y los ğ‘„ğ‘– son las matrices de correspondencia de
eigenprojcetors.
Estimaciones GLS: Las ecuaciones para la transformaciÃ³n y el GLS (Generalized Least Squares) son:

Donde ğœƒ son coeficientes basados en ğœ y ğœ†. El GLS se puede obtener de ğ‘¦ âˆ— y ğ‘ âˆ— :

Estimadores CuadrÃ¡ticos Insesgados(BQU): Los mejores estimadores cuadrÃ¡ticos insesgados (BQU)
de los componentes de varianza surgen naturalmente del hecho de que Qiu ~ (0, Î»iQi). Por lo tanto,

Es el mejor estimador cuadrÃ¡tico insesgado (BQU) de los componentes de varianza, bajo la normalidad
de las perturbaciones, son mÃ­nimos de varianza insesgados (MVU). Se pueden obtener estimaciones
factibles de los componentes de varianza reemplazando las perturbaciones verdaderas por residuos OLS
(Wallace y Hussain, 1969). Aunque OLS es insesgado y consistente bajo el modelo de efectos aleatorios,
es ineficiente y produce errores estÃ¡ndar y estadÃ­sticas t sesgadas. Alternativamente, se pueden usar los
residuos Within segÃºn el mÃ©todo de Amemiya (1971), que muestra que sus estimaciones de componentes
de varianza tienen la misma distribuciÃ³n asintÃ³tica que si se conocieran las perturbaciones verdaderas.
Sustituir los residuos OLS o Within en lugar de las perturbaciones verdaderas en (3.17) introduce sesgo
en las estimaciones de los componentes de varianza. Las correcciones de grados de libertad necesarias
dependen de las trazas de matrices que incluyen la matriz de regresores X.
MÃ©todos Alternativos:
Swamy y Arora (1972) propusieron ejecutar tres regresiones de mÃ­nimos cuadrados y estimar los
componentes de varianza a partir de los errores cuadrÃ¡ticos medios de estas regresiones:
1. RegresiÃ³n Within
2. RegresiÃ³n entre individuos
3. RegresiÃ³n entre periodos de tiempo
El estimador ğ›½ğºğ¿ğ‘† se calcula como la combinaciÃ³n ponderada de estos regresores
Baltagi (1981a) y otros estudios compararon estimadores OLS, Within y varios GLS factibles,
encontrando que:
â€¢
â€¢

OLS es sesgado e ineficiente.
Within es no sesgado y eficiente.

â€¢

GLS es BLUE (mejor estimador lineal no sesgado) pero difÃ­cil de calcular en la prÃ¡ctica.

Swamy y Arora tambiÃ©n hallaron que, para muestras pequeÃ±as, SWAR es menos eficiente que OLS si
ğœ 2 es pequeÃ±o, y menos eficiente que Within si ğœ 2 es grande.
En resumen, los modelos de efectos aleatorios permiten la estimaciÃ³n eficiente de parÃ¡metros cuando
se cumplen ciertas condiciones de independencia y normalidad, utilizando mÃ©todos como GLS y BQU
para manejar la varianza y corregir sesgos.
3.3.1 Experimento de Monte Carlo
Baltagi (1981a) considerÃ³ la siguiente ecuaciÃ³n de regresiÃ³n simple

con
DÃ³nde ğœ‡ğ‘– , ğœ†ğ‘¡ y ğœˆğ‘–ğ‘¡ son independientes y distribuidos normalmente
GeneraciÃ³n de datos y parÃ¡metros: En el experimento, se generaron datos para ğ‘ = 25, ğ‘‡ = 10, y
ğœ”2 variando en el conjunto (0, 0.01, 0.2, 0.4, 0.6, 0.8) asegurando que (1 âˆ’ ğœŒ âˆ’ ğœ”) siempre sea positivo.
Se realizaron 100 replicaciones y los resultados fueron estos:
1. Modelo Bidireccional: Es difÃ­cil determinar si OLS es equivalente a GLS segÃºn el criterio de
MSE (error cuadrÃ¡tico medio), y la eliminaciÃ³n de una estimaciÃ³n negativa de varianza puede
afectar las estimaciones de los componentes de varianza.
2. Componentes de Varianza: Si estos componentes no son pequeÃ±os, hay una ganancia en MSE
al usar GLS factibles en lugar de mÃ­nimos cuadrados.
3. MÃ©todos GLS de Dos Etapas: Todos funcionaron razonablemente bien segÃºn MSE, y ningÃºn
mÃ©todo fue el mejor para todos los experimentos, con resultados similares en MSE.
4. Estimaciones de Componentes de Varianza: No necesariamente resultan en mejores
estimaciones de los coeficientes de regresiÃ³n, y confirma resultados previos y extiende el
modelo de unidireccional a bidireccional.
RecomendaciÃ³n: La recomendaciÃ³n de Maddala y Mount (1973) sigue siendo vÃ¡lida. El GLS de dos
etapas corrige la heterocedasticidad y la correlaciÃ³n serial en los errores del modelo, mejorando la
eficiencia y precisiÃ³n de las estimaciones en comparaciÃ³n con el mÃ©todo de mÃ­nimos cuadrados
ordinarios (MCO).
3.4 ESTIMACIÃ“N DE MÃXIMA VEROSIMILITUD
Para la estimaciÃ³n de mÃ¡xima verosimilitud, se asume la normalidad en los errores estructurales. La
funciÃ³n de logverosimilitud es:

donde Õˆ y Õˆâˆ’1 fueron dados en (3.13) y (3.14).
Los estimadores de MaxV de ğ‘¦, ğœğ‘£2, ğœğ‘šğ‘¢2, ğ‘¦ ğœ(Î»)2 se obtienen haciendo lagrangiano a la ecuaciÃ³n
(3.29).
Aunque los u fueran observables, las ecuaciones serÃ­an altamente no lineales y difÃ­ciles de resolver
explÃ­citamente.
3.5 PREDICCIÃ“N
Â¿CÃ³mo se ve el mejor predictor lineal insesgado para el i-Ã©simo individuo, S perÃ­odos adelante para el
modelo de dos vÃ­as? De (3.1), para el perÃ­odo T+S

y

entonces, el elemento tÃ­pico de

es

DespuÃ©s de algunos supuestos se llega a que, para el modelo de dos vÃ­as, si hay una constante en el
modelo, el BLUP (best linear unbiased prediction) para ğ‘¦ğ‘–,ğ‘‡+ğ‘† corrige la predicciÃ³n GLS por una
fracciÃ³n de la media de los residuos GLS correspondientes a ese i-Ã©simo individuo.

Esto se ve exactamente como el BLUP para el modelo de una vÃ­a, pero con un Õˆ diferente. Si no hay
una constante en el modelo, el Ãºltimo tÃ©rmino en (3.44) debe ser reemplazado por (3.43).
3.6 EJEMPLOS
3.6.1 Ejemplo 1: EcuaciÃ³n de Inversiones de Grunfeld
El ejemplo utiliza los datos del estudio de Grunfeld (1958) sobre la inversiÃ³n corporativa, aplicando un
modelo de componentes de error de dos vÃ­as. Este tipo de modelo considera la variabilidad especÃ­fica
tanto de las empresas (secciones transversales) como de los periodos de tiempo. La ecuaciÃ³n de
inversiÃ³n se estima utilizando diferentes mÃ©todos de estimaciÃ³n, cada uno capturando de manera distinta
los componentes de error.
Tabla 3.1: Resultados de Componentes de Error de Dos VÃ­as

Esta tabla presenta los resultados de varios mÃ©todos de estimaciÃ³n (OLS, Within, WALHUS,
AMEMIYA, SWAR e IMLE). Los puntos clave incluyen:
â€¢
â€¢
â€¢

OLS: Coeficientes bÃ¡sicos (ğ›½1 = 0.116, ğ›½2 = 0.231) pero con errores estÃ¡ndar sesgados.
Within: Utiliza efectos fijos, con coeficientes (ğ›½1 = 0.118, ğ›½2 = 0.358)
MÃ©todos de Efectos Aleatorios (WALHUS, AMEMIYA, SWAR, IMLE): Incluyen
componentes de varianza especÃ­ficos para capturar la variabilidad entre empresas y periodos.
Por ejemplo, AMEMIYA muestra una varianza de efectos de tiempo (ğœğœ† = 15.78)

Tabla 3.2: Estimador de Efectos Fijos de Dos VÃ­as

Esta tabla presenta los resultados de la estimaciÃ³n de efectos fijos utilizando mÃ­nimos cuadrados en
panel:
â€¢
â€¢
â€¢

Coeficientes Significativos: ğ¹ y ğ¾ tienen coeficientes positivos y significativos, indicando un
impacto positivo en la inversiÃ³n.
Constante Negativa: Refleja posibles costos fijos o iniciales altos.
EstadÃ­sticas de Ajuste: Alto ğ‘…2 y ğ‘…2 ajustado, indicando un buen ajuste del modelo a los datos.

Tabla 3.3: Estimador de Wallace y Hussain de Dos VÃ­as

Esta tabla muestra los resultados del estimador de efectos aleatorios de Wallace y Hussain:
â€¢
â€¢
â€¢

Coeficientes Positivos y Significativos: Para ğ¹ y ğ¾, similares a los efectos fijos.
Varianzas de Componentes de Error: ğœğœ‡ (empresa), ğœğœ† (tiempo) y ğœğœˆ (idiosincrÃ¡tica) capturan
diferentes fuentes de variabilidad.
EstadÃ­sticas de Ajuste: Menores que las del modelo de efectos fijos, pero aÃºn razonables.

Tabla 3.4: Estimador de Amemiya/Wansbeek y Kapteyn de Dos VÃ­as

Esta tabla presenta los resultados del estimador de efectos aleatorios de Amemiya, Wansbeek y Kapteyn:

â€¢
â€¢
â€¢

Coeficientes Significativos: Para ğ¹ y ğ¾, con significancia similar a otros mÃ©todos.
Varianzas de Componentes de Error: Incluye un componente adicional de varianza,
mostrando cÃ³mo se distribuye la variabilidad entre las empresas, periodos y efectos
idiosincrÃ¡ticos.
EstadÃ­sticas de Ajuste: Buen desempeÃ±o, aunque ligeramente inferior al de los efectos fijos.

ConclusiÃ³n: El anÃ¡lisis comparativo de estas tablas resalta la importancia de elegir el mÃ©todo adecuado
para manejar la variabilidad en los datos de panel. Los modelos de efectos fijos y aleatorios ofrecen
diferentes ventajas, con los efectos fijos proporcionando un mejor ajuste en este caso especÃ­fico de la
ecuaciÃ³n de inversiÃ³n de Grunfeld.
3.6.2 Ejemplo 2: Demanda de gasolina
La tabla 3.6 proporciona estimaciones OLS, Within, tres GLS factibles y MLE iterativas para los
coeficientes de pendiente. El estimador Within difiere drÃ¡sticamente de OLS. Los mÃ©todos WALHUS y
SWAR arrojan estimaciones negativas de de ÏƒÎ» y se sustituye por cero. IMLE se obtiene utilizando TSP.

3.6.3 Ejemplo 3: Productividad del Capital PÃºblico
En este ejemplo, se utilizan los datos del estudio de Munnell (1990) sobre el capital pÃºblico, analizados
por Baltagi y Pinnoi (1995), para estimar una funciÃ³n de producciÃ³n Cobb-Douglas utilizando un
modelo de componentes de error de dos vÃ­as. Este modelo considera la variabilidad especÃ­fica tanto de
las entidades (secciones transversales) como de los periodos de tiempo. Las estimaciones se realizan
utilizando diferentes mÃ©todos: OLS (MÃ­nimos Cuadrados Ordinarios), Within (efectos fijos), y varios
estimadores de efectos aleatorios (GLS factibles y MLE iterativo).
Tabla 3.7: Resultados de Componentes de Error de Dos VÃ­as para los Datos de Capital PÃºblico
La Tabla 3.7 muestra los resultados de varios mÃ©todos de estimaciÃ³n aplicados a los datos de
capital pÃºblico. El mÃ©todo OLS, aunque proporciona coeficientes bÃ¡sicos, tiene errores estÃ¡ndar
sesgados. Los coeficientes para ğ›½1 (0.155) y ğ›½2 (0.309) son significativos, pero el coeficiente para el
capital pÃºblico (ğ›½4 = âˆ’0.007) es insignificante y muy pequeÃ±o. El mÃ©todo Within, que considera
efectos fijos por secciÃ³n transversal y periodo, ajusta los coeficientes y muestra que el capital pÃºblico
tiene un coeficiente insignificante (ğ›½4 = âˆ’0.004). Los mÃ©todos de efectos aleatorios (WALHUS,
AMEMIYA, SWAR, IMLE) presentan componentes de varianza adicionales para capturar la
variabilidad entre entidades y periodos. Estos mÃ©todos muestran coeficientes de capital pÃºblico (ğ›½4 )
insignificantes y negativos en todos los casos, sugiriendo que el capital pÃºblico no tiene un impacto
significativo en la producciÃ³n en este conjunto de datos. AdemÃ¡s, estos mÃ©todos no presentan
estimaciones negativas de los componentes de varianza, lo que indica una estimaciÃ³n robusta de los
componentes de error en el modelo.

TEST OF HYPOTHESES WITH PANEL DATA (BALTAGI CAP 4)
4.1. TESTS DE POOLABILIDAD DE LOS DATOS
En el anÃ¡lisis de datos de panel, surge la pregunta de si es apropiado o no agrupar (pool) los datos.
Agrupar los datos implica asumir que los parÃ¡metros de un modelo de comportamiento son los mismos
a lo largo del tiempo y entre diferentes regiones. Es importante determinar esto para obtener
estimaciones precisas y vÃ¡lidas en nuestro modelo.
Pruebas de Poolabilidad: Se deben realizar pruebas para determinar si es apropiado agrupar los datos.
Estas pruebas examinan si los parÃ¡metros de las ecuaciones de comportamiento varÃ­an entre regiones o
a lo largo del tiempo, o sea identifican si se pueden usar modelos mÃ¡s simples y agregados o si es
necesario considerar la heterogeneidad en los parÃ¡metros entre diferentes unidades o a lo largo del
tiempo
1. Modelo Restringido (Agrupado): Representa una ecuaciÃ³n de comportamiento con los mismos
parÃ¡metros a lo largo del tiempo y entre regiones: ğ‘¦ = ğ‘ğ›¿ + ğ‘¢, donde ğ‘ y ğ‘¢ son concatenaciones de las
matrices y vectores individuales de las regiones.
2. Modelo No Restringido: La misma ecuaciÃ³n de comportamiento, pero con parÃ¡metros diferentes a
lo largo del tiempo o entre regiones: ğ‘¦ğ‘– = ğ‘ğ‘– ğ›¿ğ‘– + ğ‘¢ğ‘– , dÃ³nde ğ‘¦ğ‘– es el vector de observaciones, ğ‘ğ‘– es una
matriz de variables explicativas, âˆ†ğ‘– es un vector de parÃ¡metros especÃ­ficos para cada regiÃ³n, y ğ‘¢ğ‘– es el
vector de errores.
HipÃ³tesis Nula de las pruebas (ğ‘¯ğŸ ): Los parÃ¡metros son iguales para todas las regiones (ğ›¿ğ‘– = ğ›¿) para
todo ğ‘–).
4.1.1 TEST DE POOLABILIDAD BAJO LA ASUNCIÃ“N ğ’– âˆ¼ ğ‘µ(ğŸ, ğˆğŸ ğ‘°ğ‘µğ‘» )
Bajo esta asunciÃ³n, el estimador insesgado de varianza mÃ­nima para ğ›¿ en la ecuaciÃ³n (4.2) es el
estimador de mÃ­nimos cuadrados ordinarios (OLS) que coincide con el estimador de mÃ¡xima
verosimilitud (MLE):
ğ›¿ğ‘‚ğ¿ğ‘† = ğ›¿ğ‘šğ‘™ğ‘’ = (ğ‘ â€² ğ‘)âˆ’1 ğ‘â€²ğ‘¦
El modelo restringido considera que los datos pueden ser agrupados: ğ‘¦ = ğ‘ğ›¿ğ‘‚ğ¿ğ‘† + ğ‘’, y el residuo se
define como ğ‘’ = ğ‘€ğ‘¦, donde ğ‘€ es una matriz de proyecciÃ³n.
El modelo no restringido considera que cada regiÃ³n ğ‘– tiene su propio modelo: ğ‘¦ğ‘– = ğ‘ğ‘– ğ›¿ğ‘– + ğ‘’ğ‘– ,, y los
residuos de cada regiÃ³n se definirÃ­an como ğ‘’ğ‘– = ğ‘€ğ‘– ğ‘¢ğ‘–
Test de Chow Extendido: Dividiendo las formas cuadrÃ¡ticas por sus respectivos grados de libertad y
tomando su relaciÃ³n, obtenemos el siguiente estadÃ­stico de prueba:

Bajo ğ»0 , ğ¹ğ‘œğ‘ğ‘  se distribuye como una ğ¹((ğ‘ âˆ’ 1)ğ¾ âˆ— , ğ‘(ğ‘‡ âˆ’ ğ¾ âˆ— )). La regiÃ³n crÃ­tica para esta prueba es:

CuestiÃ³n 1: Â¿Es el test de Chow el correcto si ğ’–~ğ‘µ(ğŸ, âˆ‘)?
Respuesta: No, el test de Chow dado no es el correcto en este caso. Se necesita un test de Chow
generalizado.
CuestiÃ³n 2: Â¿El estadÃ­stico de Chow sigue una distribuciÃ³n F bajo ğ’–~ğ‘µ(ğŸ, âˆ‘)?
Respuesta: Toyoda (1974) mostrÃ³ que el estadÃ­stico de Chow tiene una distribuciÃ³n F aproximada
cuando hay heterocedasticidad, pero la precisiÃ³n depende de las verdaderas varianzas.

ConclusiÃ³n: Si se asume ğ‘¢~ğ‘(0, ğœ 2 ğ¼ğ‘ğ‘‡ ) y se desea agrupar los datos, se recomienda usar el test de
Chow. Sin embargo, en caso de heterocedasticidad o ğ‘¢~ğ‘(0, âˆ‘) es mÃ¡s adecuado usar un test de Chow
generalizado.
4.1.2 TEST DE POOLABILIDAD BAJO LA ASUNCIÃ“N GENERAL ğ’– âˆ¼ ğ‘µ(ğŸ, â„¦)
El test de poolabilidad bajo la asunciÃ³n general de que ğ‘¢ sigue una distribuciÃ³n normal multivariada
ğ‘(0, ğ›º) se utiliza para determinar si es vÃ¡lido agrupar los datos en un solo modelo o si deben ser tratados
por separado. Este test transforma el modelo de tal manera que las perturbaciones transformadas tienen
varianza homocedÃ¡stica, permitiendo asÃ­ la aplicaciÃ³n del test de Chow.
El modelo restringido se transforma para que las perturbaciones tengan varianza homocedÃ¡stica:
1

Î©âˆ’2 ğ‘¦ = ğ‘¦Ìƒ. El modelo restringido transformado es ğ‘¦Ìƒ = ğ‘ğ›¿ + ğ‘¢Ìƒ,
1

Luego, en el modelo no restringido cada regiÃ³n ğ‘– tiene su propio modelo transformado Î©âˆ’2 ğ‘¦ğ‘– = ğ‘¦Ìƒğ‘– . El
modelo no restringido transformado es ğ‘¦ğ‘– = ğ‘ğ‘– ğ›¿ğ‘– + ğ‘¢Ìƒğ‘–
EstadÃ­stico de Prueba: Podemos probar ğ»0 : ğ›¿ğ‘– = ğ›¿ para cada ğ‘– = 1,2, â€¦ , ğ‘, usando el estadÃ­stico de
Chow en los modelos transformados:

Donde ğ‘’ y ğ‘’ âˆ— son los residuos de los modelos transformados restringido y no restringido
respectivamente.
Aplicabilidad del Test: Este test es aplicable siempre y cuando Î© sea conocido. Si Î© es desconocido,
Ì‚ , y se llama al estadÃ­stico resultante ğ¹Ì‚ğ‘œğ‘ğ‘ 
se reemplaza por un estimador consistente Î©
MotivaciÃ³n para la Poolabilidad: La poolabilidad de los datos permite aumentar la base de datos para
obtener estimaciones mÃ¡s precisas y confiables de los parÃ¡metros del modelo. El test de Chow ayuda a
determinar si es vÃ¡lido imponer la hipÃ³tesis ğ»0 . Imponer restricciones verdaderas o falsas puede reducir
la varianza del estimador agrupado pero puede introducir sesgo si estas restricciones son falsas.
Evidencia de Monte Carlo: Baltagi (1981a) encontrÃ³ que el test de Chow rechazaba frecuentemente la
hipÃ³tesis nula cuando era verdadera en un modelo de componentes de error. Esto se debÃ­a a que el test
de Chow es aplicable solo bajo la asunciÃ³n de homocedasticidad, lo cual se viola bajo un modelo de
efectos aleatorios con grandes componentes de varianza. El test de Roy-Zellner, aplicable en caso ğ‘¢ âˆ¼
ğ‘(0, ğ›º), mostrÃ³ menores frecuencias de error tipo I comparado con el test de Chow.
Alternativas y Comparaciones: Las alternativas al test de Chow incluyen los criterios de error
cuadrÃ¡tico medio (MSE) desarrollados por Toro-Vizcarrondo y Wallace (1968), que muestran
frecuencias de error tipo I mÃ¡s bajas y ofrecen una mayor precisiÃ³n en la estimaciÃ³n de los parÃ¡metros.
El test de Roy-Zellner es otra alternativa robusta, especialmente Ãºtil en presencia de heterocedasticidad,
ya que presenta menores frecuencias de error tipo I comparado con el test de Chow. AdemÃ¡s, las
extensiones de McElroy (1977) de los criterios MSE mejoran la precisiÃ³n del test para perturbaciones
no esfÃ©ricas, proporcionando resultados mÃ¡s confiables en situaciones con estructuras de varianza mÃ¡s
complejas.
4.1.3 EJEMPLOS
Ejemplo 1: EcuaciÃ³n de InversiÃ³n de Grunfeld
1. Prueba de Chow para poolabilidad entre empresas: Se obtiene un estadÃ­stico F observado:
27.75, distribuido como ğ¹(27,170) bajo ğ»0 : ğ›¿ğ‘– = ğ›¿ para ğ‘– = 1, â€¦ , ğ‘. El resultado es que se
rechaza la poolabilidad entre empresas para todos los coeficientes.
2. Prueba de poolabilidad solo de las pendientes, permitiendo interceptos variables: Se usa un
modelo restringido basado en una regresiÃ³n Within con dummies de empresa. Se obtiene un

estadÃ­stico F observado de 5.78 bajo la hipÃ³tesis nula, y se rechaza la poolabilidad de las
pendientes entre empresas.
3. Prueba de poolabilidad en el tiempo: Se obtiene un estadÃ­stico F observado: 1.12, y el resultado
es que no se rechaza la poolabilidad en el tiempo.
4. Prueba de Roy-Zellner para poolabilidad entre empresas, permitiendo un modelo de
componentes de error unidireccional: Se obtiene un estadÃ­stico F observado de 4.35, y el
resultado es que se rechaza la poolabilidad entre empresas.
5. Prueba de Roy-Zellner para poolabilidad en el tiempo, permitiendo un modelo de componentes
de error unidireccional: Se obtiene un estadÃ­stico F observado de 2.72, y el resultado es que se
rechaza la poolabilidad en el tiempo.
Ejemplo 2: Demanda de Gasolina
1. Prueba de Chow para poolabilidad entre paÃ­ses: Se obtiene un estadÃ­stico F observado de 129.38,
y se rechaza la poolabilidad entre paÃ­ses.
2. Prueba de estabilidad solo de los coeficientes de pendiente: Se obtiene un estadÃ­stico F
observado: 27.33, y el resultado es que se rechaza la estabilidad de los coeficientes de pendiente
entre paÃ­ses.
3. Prueba de Chow para poolabilidad en el tiempo: Se obtiene un estadÃ­stico F observado de 0.276,
y el resultado es que no se rechaza la poolabilidad en el tiempo.
4. Prueba de Roy-Zellner para poolabilidad entre paÃ­ses, permitiendo un modelo de componentes
de error unidireccional: Se obtiene un estadÃ­stico F observado de 21.64, y el resultado es que se
rechaza la poolabilidad entre paÃ­ses.
5. Prueba de Roy-Zellner para poolabilidad en el tiempo: Se obtiene un estadÃ­stico F observado de
1.66, y el resultado es que se rechaza la poolabilidad en el tiempo al 5%.
4.1.4 OTHER TESTS FOR POOLABILITY
Ziemer y Wetzstein (1983): Comparan estimadores agrupados (ğ›¿ğ‘‚ğ¿ğ‘† ) con no agrupados (ğ›¿ğ‘–,ğ‘‚ğ¿ğ‘† ) segÃºn
el rendimiento en el riesgo de pronÃ³stico.Usan un modelo de demanda de recreaciÃ³n en Ã¡reas silvestres,
y encuentran que el estimador de regla de Stein tiene mejor rendimiento en el riesgo de pronÃ³stico.
El estimador de Stein para ğ›¿ğ‘– es: ğ›¿ğ‘–âˆ— = ğ›¿ğ‘‚ğ¿ğ‘† + (1 âˆ’ ğ¹

ğ‘

ğ‘œğ‘ğ‘ 

) (ğ›¿ğ‘–,ğ‘‚ğ¿ğ‘† âˆ’ ğ›¿ğ‘‚ğ¿ğ‘† )

Maddala (1991): Argumenta que los estimadores de contracciÃ³n son mejores que los estimadores
agrupados o individuales.
Brown, Durbin y Evans (1975): Desarrollan pruebas de suma acumulada y suma acumulada de
cuadrados para cambio estructural basadas en residuos recursivos en regresiones de series temporales.
Luego, Han y Park (1989) extienden estas pruebas al caso de datos de panel, y no encuentran evidencia
de cambio estructural en el comercio exterior de bienes manufacturados de EE.UU. durante 1958-76.
Baltagi, Hidalgo y Li (1996): Desarrollan una prueba no paramÃ©trica para la agrupabilidad que es
robusta ante la especificaciÃ³n incorrecta de la forma funcional.
ğ‘¦ğ‘–ğ‘¡ = ğ‘”ğ‘¡ (ğ‘¥ğ‘–ğ‘¡ ) + ğœ–ğ‘–ğ‘¡ , dÃ³nde ğ‘”ğ‘¡ (. ) puede variar con el tiempo. La prueba es consistente y asintÃ³ticamente
normal, y aplican la prueba a una ecuaciÃ³n de ingresos usando datos del PSID.
4.2. PRUEBAS DE EFECTOS INDIVIDUALES Y TEMPORALES
4.2.1. LA PRUEBA BREUSCH-PAGAN
El propÃ³sito de esta prueba es evaluar la hipÃ³tesis nula ğ»0 : ğœğœ‡2 = ğœğœ†2 = 0 (la presencia de efectos
individuales y temporales) en un modelo de error aleatorio de dos vÃ­as.
Modelo y FunciÃ³n de Verosimilitud: En un modelo de panel de efectos aleatorios de dos vÃ­as, estamos
interesados en saber si las variaciones individuales ğœğœ‡2 y las variaciones temporales ğœğœ†2 son
significativamente diferentes de cero. Si ambos efectos son cero, entonces no hay variabilidad

significativa ni entre individuos ni a lo largo del tiempo, lo que simplificarÃ­a considerablemente el
modelo.
La funciÃ³n de verosimilitud bajo normalidad de las perturbaciones se expresa como:

DerivaciÃ³n del Test LM: Para construir el estadÃ­stico LM (Lagrange Multiplier), seguimos estos pasos:
1. Derivar el vector de puntaje (score): La derivada de la funciÃ³n de verosimilitud respecto a ğœƒ,
evaluada en el estimador de mÃ¡xima verosimilitud restringido bajo ğ»0 , se usa para calcular el
vector de puntaje.
2. Calcular la matriz de informaciÃ³n ğ‘±(ğœ½): Utilizamos esta matriz para evaluar la varianza del
estimador bajo ğ»0
El estadÃ­stico LM se calcula como:

Donde ğ· es el vector de puntaje y ğ½âˆ’1 es la inversa de la matriz de informaciÃ³n. Bajo ğ»0 , ğ¿ğ‘€ sigue una
distribuciÃ³n ğœ’22 .
Componentes del Test LM
ğ‘³ğ‘´ğŸ : Prueba la hipÃ³tesis nula ğ»ğ‘0 : ğœğœ‡2 = 0 (efectos individuales son cero), aquÃ­ ğ¿ğ‘€1 seguirÃ­a una
distribuciÃ³n ğœ’12 , y este componente se calcula como:

ğ‘³ğ‘´ğŸ : Prueba la hipÃ³tesis nula ğ»ğ‘0 : ğœğœ†2 = 0 (efectos temporales son cero). Este componente seguirÃ­a una
distribuciÃ³n ğœ’12 y se calcula como:

InterpretaciÃ³n:
â€¢
â€¢
â€¢

Si ğ‘³ğ‘´ es significativo: Rechazamos ğ»0 , indicando que al menos una de las varianzas (ğœğœ‡2 o ğœğœ†2 )
es significativamente diferente de cero. Esto sugiere que existen efectos individuales o efectos
temporales (o ambos) en el modelo.
Si ğ‘³ğ‘´ğŸ es significativo: Rechazamos ğ»ğ‘0 , indicando que los efectos individuales ğœğœ‡2 son
significativos.
Si ğ‘³ğ‘´ğŸ es significativo: Rechazamos ğ»ğ‘0 , indicando que los efectos temporales ğœğœ†2 son
significativos.

Ventajas: Requiere solo residuos de MCO y es fÃ¡cil de calcular, y es popular debido a su simplicidad y
efectividad en estudios de Monte Carlo.
Limitaciones: Puede haber problemas de rendimiento para valores pequeÃ±os de ğœğœ‡2 o ğœğœ†2 cerca de cero,
donde es mÃ¡s probable obtener estimaciones negativas de los componentes de varianza.
4.2.2 PRUEBAS DE KING Y WU, HONDA Y MULTIPLICADOR DE LAGRANGE
ESTANDARIZADO

Esstas pruebas se usan para evaluar la presencia de efectos individuales y efectos temporales en un
modelo de componentes de error de dos vÃ­as. Por ello, la hipÃ³tesis nula es probar la ausencia de varianzas
significativas en: (1) Efectos individuales, (2) Efectos temporales, (3) Ambos:
ğ»ğ‘0 : ğœğœ‡2 = 0
ğ»ğ‘0 : ğœğœ†2 = 0
ğ»ğ‘0 : ğœğœ‡2 = ğœğœ†2 = 0
Prueba de Honda: Honda (1985) sugiere una prueba de mÃ¡xima potencia uniforme para ğ»ğ‘0 basada
en el estadÃ­stico:

Este estadÃ­stico es robusto a la no normalidad y es el cuadrado del estadÃ­stico LM1 de Breusch y Pagan.
Prueba de Multiplicador de Lagrange Estandarizado (SLM): Propuesta por Moulton y Randolph
(1989), esta prueba ajusta el estadÃ­stico LM para mejorar la aproximaciÃ³n asintÃ³tica en muestras
grandes. Se centra y escala el estadÃ­stico LM para obtener el SLM:

Pruebas de King y Wu: King y Wu (1997) proponen una prueba de potencia mÃ¡xima media local
(LMMP) para ğ»ğ‘0 , coincidiendo con la prueba de Honda,

CombinaciÃ³n de Efectos Individuales y Temporales: Para ğ»0ğ‘ , Honda sugiere una prueba combinada:

King y Wu proponen una versiÃ³n LMMP:

InterpretaciÃ³n: Estas pruebas ajustadas proporcionan una mejor aproximaciÃ³n crÃ­tica y son mÃ¡s
robustas en presencia de no normalidad y otros problemas en los datos.
â€¢
â€¢

Si ğ‘¯ğŸ , ğ‘ºğ‘³ğ‘´, o ğ‘²ğ‘¾ son significativos: Rechazamos la hipÃ³tesis nula correspondiente,
indicando que hay efectos individuales, efectos temporales, o ambos en el modelo.
Si no son significativos: No podemos rechazar la hipÃ³tesis nula, sugiriendo que no hay
evidencia suficiente de efectos individuales o temporales significativos.

4.2.3. PRUEBAS DE GOURIEROUX, HOLLY AND MONFORT
Estas pruebas se usan para evaluar la presencia conjunta de efectos individuales y efectos temporales en
un modelo de componentes de error de dos vÃ­as, especialmente cuando uno o ambos componentes de
varianza son pequeÃ±os o cercanos a cero.
HipÃ³tesis Nula: ğ»ğ‘0 : ğœğœ‡2 = ğœğœ†2 = 0 , que prueba la ausencia de varianzas significativas en los efectos
individuales y temporales.
2 combinando dos estadÃ­sticos, ğ´ y ğµ, que estÃ¡n basados
Prueba GHM: Se construye el estadÃ­stico ğœ’ğ‘š
en la varianza de los efectos individuales y temporales, respectivamente:

â€¢
â€¢
â€¢

2 se calcula como la suma de los cuadrados de ğ´ y ğµ.
Si ambos ğ´ y ğµ son positivos, ğœ’ğ‘š
2 se calcula como el cuadrado del valor positivo.
Si solo uno de ellos es positivo, ğœ’ğ‘š
2 se establece en cero.
Si ambos son no positivos, ğœ’ğ‘š

DistribuciÃ³n del EstadÃ­stico ğŒğŸğ’ : Bajo la hipÃ³tesis nula de que no hay varianza en los efectos
2 sigue una distribuciÃ³n mixta compuesta por
individuales ni en los efectos temporales (ğ»ğ‘0 ), ğœ’ğ‘š
distribuciones ponderadas, dÃ³nde 1/4 del tiempo es ğœ’ 2 (0), 1/2 del tiempo es ğœ’ 2 (1) y 1/4 es ğœ’ 2 (2)
Esta mezcla de distribuciones permite que la prueba GHM maneje casos en los que las varianzas de los
efectos son muy pequeÃ±as o cercanas a cero, proporcionando una interpretaciÃ³n mÃ¡s robusta y confiable
en estos escenarios.
Ventajas de la Prueba GHM: A diferencia de las pruebas de Honda y KW, la prueba GHM es inmune
a valores negativos de ğ´ y ğµ, y es mucho mÃ¡s flexible, pues maneja situaciones donde uno o ambos
componentes de varianza son pequeÃ±os o cercanos a cero, ofreciendo una mejor interpretaciÃ³n y
confiabilidad en estos casos.
InterpretaciÃ³n:
â€¢
â€¢

Si ğŒğŸğ’ es significativo: Rechazamos ğ»ğ‘0 , indicando que hay efectos individuales y/o temporales
significativos en el modelo.
Si ğŒğŸğ’ no es significativo: No podemos rechazar ğ»ğ‘0 , sugiriendo que no hay evidencia
suficiente de efectos individuales o temporales significativos.

4.2.4. PRUEBAS LM CONDICIONALES
Hay un problema a la hora de usar la prueba ğ»0 para ğ»ğ‘0 : ğœğœ‡2 = 0, pues se asume que los efectos
especÃ­ficos de tiempo no existen, lo cual puede llevar a decisiones incorrectas si la varianza de los
efectos temporales es grande. Por ello, se crea la prueba para efectos individuales condicionales
Prueba para Efectos Individuales Condicionales (ğ‘¯ğ’…ğŸ : ğˆğŸğ = ğŸ)
El objetivo de esta prueba es testear efectos individuales permitiendo la existencia de efectos especÃ­ficos
de tiempo (ğˆğŸğ€ > ğŸ). El estadÃ­stico de prueba es:

Bajo ğ»ğ‘‘0 , ğ¿ğ‘€ğœ‡ sigue una distribuciÃ³n ğ‘(0,1), y si ğœÌ‚ğœ†2 â†’ 0 entonces ğœÌ‚22 â†’ ğœÌ‚ğœˆ y ğ¿ğ‘€ğœ‡ se aproximarÃ­a a
la prueba unilateral de Honda.
Prueba para Efectos Temporales Condicionales ğ‘¯ğ’†ğŸ : ğˆğŸğ€ = ğŸ
Esta prueba se creÃ³ para testear efectos temporales permitiendo la existencia de efectos especÃ­ficos de
individuos ğœğœ‡2 > 0. El estadÃ­stico de prueba sigue una distribuciÃ³n ğ‘(0,1) bajo la hipÃ³tesis nula, y es:

Ambas pruebas permiten testar efectos individuales o temporales considerando la existencia del otro
tipo de efecto, lo cual evita decisiones incorrectas debido a la omisiÃ³n de uno de los componentes de
varianza, y se usan en contextos donde se necesita verificar la significancia de efectos individuales y
temporales, proporcionando un enfoque mÃ¡s robusto comparado con pruebas unilaterales que pueden
subestimar la complejidad del modelo.
4.2.5. ANOVA F Y PRUEBAS DE RAZÃ“N DE VEROSIMILITUD

ANOVA F-Test: Su objetivo es evaluar la significancia de los efectos fijos en el modelo de componentes
de error de una vÃ­a. Esta prueba determina si las variables explicativas tienen un impacto significativo
sobre la variable dependiente.
Su estadÃ­stico de prueba sigue una distribuciÃ³n ğ¹ central con ğ‘ âˆ’ ğ‘Ÿ y ğ‘ğ‘‡ âˆ’ (ğ‘˜ + ğ‘ âˆ’ ğ‘Ÿ) grados de
libertad, es:

DÃ³nde ğ· es la matriz de proyecciÃ³n, ğ‘€ y las matrices de proyecciÃ³n ajustadas, ğ‘ es el nÃºmero de
parÃ¡metros en el modelo, ğ‘Ÿ es el rango de la matriz de diseÃ±o ajustada, y ğ‘ğ‘‡ es el nÃºmero total de
observaciones Los componentes esenciales del estadÃ­stico (ğ·, ğ‘€, ğº) aseguran que la prueba sea vÃ¡lida
bajo la estructura del modelo especificado.
Pruebas de RazÃ³n de Verosimilitud (LR): Se usan para comparar valores de verosimilitud mÃ¡xima
restringidos y no restringidos para evaluar hipÃ³tesis especÃ­ficas sobre los componentes de varianza del
modelo. Su estadÃ­stico de prueba es:

DÃ³nde ğ‘™(ğ‘Ÿğ‘’ğ‘ ) es el valor de verosimilitud mÃ¡xima restringido (bajo la hipÃ³tesis nula), y ğ‘™(ğ‘¢ğ‘›ğ‘Ÿğ‘’ğ‘ ) es el
valor de verosimilitud mÃ¡xima no restringido.
4.2.6. RESULTADOS DE MONTE CARLO PARA PRUEBAS DE EFECTOS INDIVIDUALES Y
TEMPORALES
Baltagi et al. (1992b) llevaron a cabo experimentos Monte Carlo para comparar el rendimiento de varias
pruebas en un modelo de componentes de error de dos vÃ­as. Los resultados clave son los siguientes:
â€¢

â€¢

â€¢

â€¢
â€¢

Pruebas para ğ‘¯ğ’‚ğŸ : ğˆğŸğ = ğŸ: Todas las pruebas usuales para ğ»0ğ‘ funcionan mal cuando ğœğœ†2 es
grande, especialmente la prueba BP, que rechaza en exceso la hipÃ³tesis nula. Pruebas como HO,
SLM, LR y F subestiman el tamaÃ±o nominal. Sin embargo, cuando ğœğœ‡2 es grande, todas las
pruebas rechazan bien la hipÃ³tesis nula. La potencia de todas las pruebas disminuye a medida
que aumenta ğœğœ†2
Pruebas para ğ‘¯ğ’…ğŸ : ğˆğŸğ = ğŸ (permitiendo ğˆğŸğ€ > ğŸ): Las pruebas LMÂµ, LR y F tienen un buen
rendimiento, con tamaÃ±os estimados cercanos al tamaÃ±o nominal y alta potencia para grandes
ğœğœ‡2 . La sobreespecificaciÃ³n del modelo (asumiendo ğœğœ†2 > 0 cuando en realidad ğœğœ†2 = 0) no
afecta negativamente la potencia de estas pruebas.
Prueba conjunta ğ‘¯ğ’„ğŸ : ğˆğŸğ = ğˆğŸğ€ = ğŸ: Las pruebas BP, HO, KW y LR subestiman
significativamente el tamaÃ±o nominal, mientras que las pruebas GHM y F tienen tamaÃ±os
estimados cercanos al tamaÃ±o nominal. Las pruebas GHM son inmunes a valores negativos de
A y B y funcionan bien en los experimentos de Monte Carlo.
Recomendaciones: Las pruebas F de ANOVA funcionan razonablemente bien en comparaciÃ³n
con las pruebas LR y LM, tanto para modelos de una vÃ­a como de dos vÃ­as, y son recomendadas.
Estimadores de Pretest: Baltagi, Bresson y Pirotte (2003b) evaluaron el rendimiento de los
estimadores de pretest en modelos de componentes de error de dos vÃ­as. El estimador de pretest,
basado en la aplicaciÃ³n de la prueba GHM seguida de las pruebas LM condicionales, mostrÃ³ un
buen rendimiento en tÃ©rminos de MSE relativo. Si el pretest no rechaza la nula, se reduce a
OLS; si la rechaza, se convierte en un estimador FGLS de una o dos vÃ­as.

4.2.7. EJEMPLO ILUSTRATIVO
Los resultados de los experimentos de Monte Carlo muestran que los estadÃ­sticos de prueba A y/o B
toman valores negativos grandes con bastante frecuencia en algunos diseÃ±os. Surge la pregunta de si es
posible que A y/o B tomen valores negativos grandes para datos reales. Para responder a esto, se aplican
las pruebas consideradas a la ecuaciÃ³n de inversiÃ³n de Grunfeld (1958).

Resultados de las Pruebas: La tabla 4.1 son los resultados de la prueba para el ejemplo de Grunfield,
y la 4.2 es la prueba de Multiplicador de Lagrange de Breusch y Pagan para estos datos

ExplicaciÃ³n de los Resultados
1. Pruebas para ğ‘¯ğŸğ’‚ : ğˆğŸğ = ğŸ: Todas las pruebas consideradas (BP, HO, KW, SLM, F, LR)
rechazan la hipÃ³tesis nula, lo que sugiere fuertemente la existencia de efectos especÃ­ficos de los
individuos en los datos.
2. Pruebas para ğ‘¯ğŸğ’ƒ : ğˆğŸğ€ = ğŸ: La prueba BP rechaza la hipÃ³tesis nula, pero otras pruebas (HO,
KW, SLM, F, LR) no la rechazan. Esto se debe a un valor negativo grande de B (-2.540),
indicando que puede no haber efectos especÃ­ficos de tiempo significativos.
3. Pruebas para ğ‘¯ğŸğ’„ : ğˆğŸğ = ğˆğŸğ€ = ğŸ: Todas las pruebas, excepto GHM, subestiman el tamaÃ±o
nominal. La prueba GHM y la prueba F no son significativamente diferentes del tamaÃ±o
nominal.
4. Pruebas para ğ‘¯ğŸğ’… : ğˆğŸğ = ğŸ/ğˆğŸğ€ > ğŸ: Las pruebas ğ¿ğ‘€Âµ, LR y F rechazan la hipÃ³tesis nula,
sugiriendo que puede haber efectos especÃ­ficos de los individuos cuando se permiten efectos
especÃ­ficos de tiempo.
5. Pruebas para ğ‘¯ğŸğ’† : ğˆğŸğ€ = ğŸğˆğŸğ > ğŸ: La prueba ğ¿ğ‘€ğœ† y la prueba F no rechazan la hipÃ³tesis nula,
sugiriendo que no hay efectos especÃ­ficos de tiempo cuando se permiten efectos especÃ­ficos de
los individuos.
En resumen, los datos de Grunfeld respaldan el uso de pruebas unilaterales en aplicaciones empÃ­ricas y
demuestran la importancia de considerar efectos especÃ­ficos de los individuos y del tiempo al realizar
anÃ¡lisis con modelos de componentes de error.
4.3. PRUEBA DE ESPECIFICIDAD DE HAUSMAN
La prueba de especificaciÃ³n de Hausman se utiliza para determinar si se deben usar modelos de efectos
fijos o aleatorios. EspecÃ­ficamente, evalÃºa si los efectos individuales no observados ğœ‡ğ‘– estÃ¡n
correlacionados con los regresores ğ‘‹ğ‘–ğ‘¡ . Si existe tal correlaciÃ³n, el modelo de efectos aleatorios no es
apropiado.
Modelos Involucrados:
1. Modelo de Efectos Fijos (Within Estimator): Se elimina la influencia de los efectos
individuales no observados ğœ‡ğ‘– mediante la transformaciÃ³n "within", que se basa en restar la
media de cada individuo a lo largo del tiempo: ğ‘¦Ìƒğ‘–ğ‘¡ = ğ‘¦ğ‘–ğ‘¡ âˆ’ ğ‘¦Ì…ğ‘– , ğ‘‹Ìƒğ‘–ğ‘¡ = ğ‘‹ğ‘–ğ‘¡ âˆ’ ğ‘‹ğ‘–
El estimador Within ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› es obtenido al aplicar MCO al modelo Transformado

dÃ³nde Q es la matriz de transformaciÃ³n que elimina las medias individuales.
2. Modelo de Efectos Aleatorios (GLS Estimator): Los efectos individuales ğœ‡ğ‘– se modelan como
parte del tÃ©rmino de error y se asume que no estÃ¡n correlacionados con los regresores.
Ì‚ ğ‘®ğ‘³ğ‘º es obtenido al aplicar el mÃ©todo de MÃ¡xima Verosimilitud Generalizada:
El estimador GLS ğœ·

dÃ³nde Î© es la matriz de covarianza de los errores.
HipÃ³tesis Nula de la Prueba de Hausman: ğ‘¯ğŸ : ğ‘¬(ğ’–ğ’Šğ’• /ğ‘¿ğ’Šğ’• ) = ğŸ. Esta hipÃ³tesis significa que no hay
correlaciÃ³n entre los efectos individuales no observados ğœ‡ğ‘– y los regresores ğ‘‹ğ‘–ğ‘¡ Bajo esta hipÃ³tesis, tanto
el estimador de efectos aleatorios ğ›½Ì‚ğºğ¿ğ‘† como el de efectos fijos ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› son consistentes, pero el
estimador de efectos aleatorios es mÃ¡s eficiente.
Procedimiento
1. ComparaciÃ³n de Estimadores: Se comparan ğ›½Ì‚ğºğ¿ğ‘† y ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› .
2. Diferencia de Estimadores: Se calcula ğ‘Ì‚1 = ğ›½Ì‚ğºğ¿ğ‘† âˆ’ ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘›
3. Varianza de la Diferencia: Se estima la varianza de la diferencia entre los estimadores.
ğ‘£ğ‘ğ‘Ÿ(ğ‘Ì‚1 ) = ğ‘£ğ‘ğ‘Ÿ(ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› ) âˆ’ ğ‘£ğ‘ğ‘Ÿ(ğ›½Ì‚ğºğ¿ğ‘† )
4. EstadÃ­stico de Prueba: Se construye el estadÃ­stico de prueba ğ‘š1 basado en ğ‘Ì‚1 y su varianza:

5. DistribuciÃ³n del EstadÃ­stico: Bajo la hipÃ³tesis nula, el estadÃ­stico de prueba sigue una
distribuciÃ³n ğœ’ 2 con ğ¾ grados de libertad, donde ğ¾ es la dimensiÃ³n del vector de pendientes ğ›½.
Alternativas y Generalizaciones
RegresiÃ³n Aumentada: La prueba de Hausman puede ser derivada de una regresiÃ³n aumentada, que
serÃ­a equivalente a probar si ğ›¾ = 0

Prueba de Arellano (1993): Arellano (1993) proporcionÃ³ una alternativa robusta a la prueba de
Hausman, que es resistente a la autocorrelaciÃ³n y heterocedasticidad de forma arbitraria. Sugiere
construir la siguiente regresiÃ³n, dÃ³nde ğ‘¦ğ‘–+ y ğ‘‹ğ‘–+ son transformaciones ortogonales hacia adelante y ğ‘¦Ì…ğ‘– ,
ğ‘‹Ì…ğ‘– son las medias sobre el tiempo.

La metodologÃ­a MCO en este modelo da ğ›½Ì‚ = ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› y ğ›¾Ì‚ = ğ›½Ì‚ğµğ‘’ğ‘¡ğ‘¤ğ‘’ğ‘’ğ‘› âˆ’ ğ›½Ì‚ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› .. La prueba de
Hausman puede obtenerse de esta regresiÃ³n artificial probando si ğ›¾ = 0 usando errores estÃ¡ndar robustos
Prueba Generalizada: Ahn y Low (1996) sugieren que la prueba de Hausman puede ser generalizada
para probar que cada ğ‘‹ğ‘–ğ‘¡ es no correlacionado con ğœ‡ğ‘– , calculando ğ‘ğ‘‡ Ã— ğ‘…2 de la regresiÃ³n de los residuos
â€²
âˆ—
â€²
â€²
GLS ( ğ‘¦ğ‘–ğ‘¡
âˆ’ ğ‘‹ğ‘–ğ‘¡âˆ— ğ›½Ì‚ğºğ¿ğ‘† ) en ğ‘‹Ìƒğ‘–ğ‘¡ y [ğ‘‹ğ‘–1
, â€¦ , ğ‘‹ğ‘–ğ‘‡
]
ConclusiÃ³n: La prueba de Hausman es esencial para determinar la idoneidad de usar modelos de efectos
fijos o aleatorios en panel data. Garantiza que el modelo seleccionado proporciona estimaciones
consistentes y eficientes, verificando la no correlaciÃ³n entre efectos no observados y los regresores.
4.3.1. EJEMPLO 1: ECUACIÃ“N DE INVERSIÃ“N DE GRUNFELD
El propÃ³sito es evaluar si los efectos individuales no observados estÃ¡n correlacionados con las variables
explicativas ğ‘‹ğ‘–ğ‘¡
MÃ©todo:
â€¢
â€¢

Estimaciones Within: Estima los coeficientes usando la transformaciÃ³n que elimina los efectos
individuales fijos.
Estimaciones Between: Estima los coeficientes usando la media de las variables a lo largo del
tiempo para cada individuo.

â€¢

Prueba de Hausman: Compara las diferencias entre las estimaciones de efectos aleatorios (RE)
y fijos (FE) para detectar posibles inconsistencias.

Para los datos de Grunfeld, las estimaciones Within son (ğ›½1, ğ›½2) = (0.1101238,0.310065) y las
Between son (0.1346461,0.03203147). El estadÃ­stico de prueba de Hausman ğ‘š3 es ğœ’2 = 2.131, no
significativo al 5%, lo que indica que no hay correlaciÃ³n entre los efectos individuales y ğ‘‹ğ‘–ğ‘¡ .
En Stata, se debe usar el contraste entre los estimadores
RE y FE para calcular correctamente el estadÃ­stico de
Hausman ğ‘š1, que es 2.33 (Ï‡2), no rechazando la
hipÃ³tesis nula, similar a m3. La Tabla 4.3 muestra este
resultado.
TambiÃ©n se puede calcular m2 (contraste entre SWAR
y Between). La Tabla 4.4 presenta este resultado.
La regresiÃ³n aumentada con estimaciones GLS
factibles de SWAR da ğ›½ = (0.135,0.032) y ğ›¾ =
(âˆ’0.025,0.278), con ğ¹ = 1.066 (ğ¹(2,195)), no
significativo, confirmando la no correlaciÃ³n de los
efectos individuales con ğ‘‹ğ‘–ğ‘¡ .
4.3.2. EJEMPLO 2: DEMANDA DE GASOLINA
El propÃ³sito es el mismo del ejemplo 1, y utilizan la misma metodologÃ­a. Para los datos sobre la gasolina
de Baltagi y Griffin (1983), las estimaciones de los Withines son (ğ›½1, ğ›½2, ğ›½3) =
(0,66128, âˆ’0,32130, âˆ’0,64015). Las estimaciones Between vienen dadas por (0,96737,-0,96329,0,79513).
El estadÃ­stico de prueba de Hausman resultante ğœ’ 2 es ğ‘š3 = 26.507, lo cual es significativo. Por lo
tanto, se rechaza la hipÃ³tesis nula de que no hay correlaciÃ³n entre los efectos individuales y ğ‘‹ğ‘–ğ‘¡ .
De manera similar, se puede calcular ğ‘š2 = 27.45, basado en el contraste entre el estimador GLS factible
SWAR y el estimador Between, y ğ‘š1 = 302.8, basado en el contraste entre el estimador GLS factible
SWAR y el estimador de efectos fijos, todos obtenidos usando Stata. Aunque m1 da un valor del
estadÃ­stico de Hausman drÃ¡sticamente diferente de m2 o m3, los tres estadÃ­sticos llevan a la misma
decisiÃ³n: se rechaza la hipÃ³tesis nula y el estimador RE no es consistente.
La regresiÃ³n aumentada, basada en la estimaciÃ³n iterativa de mÃ¡xima verosimilitud (MLE) de Î¸, produce
las siguientes estimaciones: ğ›½ğµğ‘’ğ‘¡ğ‘¤ğ‘’ğ‘’ğ‘› = (0.967, âˆ’0.963, âˆ’0.795 y ğ›¾ = ğ›½ğ‘Šğ‘–ğ‘¡â„ğ‘–ğ‘› âˆ’ ğ›½ğµğ‘’ğ‘¡ğ‘¤ğ‘’ğ‘’ğ‘› =
(âˆ’0.306,0.642,0.155), con un valor ğ¹ observado para ğ»0: ğ›¾ = 0 igual a 4.821, lo que lleva a rechazar
H0.
4.3.3. EJEMPLO 3: ACTIVIDAD DE HUELGA
Owusu-Gyapong (1986) analizÃ³ datos de panel sobre la actividad de huelga en 60 industrias
manufactureras canadienses entre 1967 y 1979 utilizando un modelo de componente de error de un solo
sentido. Se obtuvieron estimaciones mediante MCO, Within y GLS.
1. Prueba F para efectos especÃ­ficos de la industria: Con un valor F de 5.56, se rechazÃ³ la
hipÃ³tesis nula de cero efectos especÃ­ficos de la industria, prefiriÃ©ndose el estimador Within al
MCO.
2. Prueba LM de Breusch y Pagan: Con un valor Ï‡2 de 21.4, se rechazÃ³ la hipÃ³tesis nula de cero
efectos aleatorios, prefiriÃ©ndose el estimador GLS al MCO.
3. Prueba Hausman: Con un valor Ï‡2 de 3.84, no se encontrÃ³ significancia en la correlaciÃ³n entre
los efectos aleatorios y los regresores, por lo que el estimador GLS fue preferido al estimador
Within.

En conclusiÃ³n, Owusu-Gyapong (1986) eligiÃ³ GLS como el estimador preferido basÃ¡ndose en estas
pruebas.
4.3.4. EJEMPLO 4: COMPORTAMIENTO DE LA PRODUCCIÃ“N DE LAS SERRERÃAS
Cardellichio (1990) estudiÃ³ la producciÃ³n de 1147 aserraderos en Washington entre 1972 y 1984
utilizando un modelo de componente de error de un solo sentido. Se obtuvieron estimaciones mediante
MCO, Within y GLS.
1. Prueba F para la estabilidad de pendientes: No significativa al 5%, indicando estabilidad de
los parÃ¡metros de pendiente a lo largo del tiempo.
2. Prueba F para efectos de aserraderos: RechazÃ³ la hipÃ³tesis nula al 1%, sugiriendo la inclusiÃ³n
de efectos especÃ­ficos de aserraderos.
3. Prueba de Hausman: RechazÃ³ la hipÃ³tesis nula al 1%, indicando que la suposiciÃ³n de
ortogonalidad entre los regresores y los efectos de los aserraderos no es vÃ¡lida.
Cardellichio (1990) concluyÃ³ que las pendientes de regresiÃ³n son estables, se deben incluir las variables
dummy de los aserraderos y el estimador Within es preferible al MCO y al GLS.
4.3.5. EJEMPLO 5: PRIMA SALARIAL POR MATRIMONIO
Cornwell y Rupert (1997) estudiaron la prima salarial atribuida al matrimonio utilizando datos del NLSY
de 1971, 1976, 1978 y 1980.
1. Estimaciones Within vs. GLS: Las estimaciones Within de la prima por matrimonio son
menores que las obtenidas mediante GLS factible.
2. Prueba de Hausman: Rechaza la hipÃ³tesis nula, indicando que hay caracterÃ­sticas individuales
omitidas que estÃ¡n correlacionadas con el matrimonio y la tasa salarial.
En conclusiÃ³n, la prima por matrimonio es solo un desplazamiento del intercepto, no excede del 5% al
7%, y cuestionan que el matrimonio mejore la productividad a travÃ©s de la especializaciÃ³n.
4.3.6. EJEMPLO 6: UNIÃ“N MONETARIA Y COMERCIO
Glick y Rose (2002) investigaron si salir de una uniÃ³n monetaria reduce el comercio internacional,
utilizando datos de comercio bilateral entre 217 paÃ­ses desde 1948 hasta 1997. Estimaron un modelo de
gravedad ampliado y aplicaron mÃ©todos de MCO, efectos fijos (FE) y efectos aleatorios (RE),
prefiriendo el modelo FE segÃºn la prueba de Hausman. Encontraron que los paÃ­ses que se unieron a una
uniÃ³n monetaria duplicaron su comercio bilateral, mientras que aquellos que la abandonaron vieron su
comercio reducido a la mitad.
4.3.7. PRUEBA DE HAUSMAN PARA EL MODELO BIDIRECCIONAL
Para el modelo de componente de error bidireccional, la prueba de Hausman (1978) puede basarse en la
diferencia entre el estimador de efectos fijos y el estimador GLS de efectos aleatorios bidireccionales.
Sin embargo, las pruebas equivalentes para el modelo unidireccional no se extienden completamente al
bidireccional.
Kang (1985) mostrÃ³ que no hay equivalencia similar para la prueba de Hausman en el modelo
bidireccional debido a la existencia de dos estimadores Between: uno entre perÃ­odos de tiempo (Î²T) y
otro entre secciones transversales (Î²C). AdemÃ¡s, ğ›½ğºğ¿ğ‘† es una combinaciÃ³n ponderada de ğ›½ğ‘‡ , ğ›½ğ¶ y el
estimador Within (ğ›½ğ‘Š ). Kang clasifica cinco hipÃ³tesis comprobables basadas en estas diferencias:
1.
2.
3.
4.
5.

Probar ğ‘¬(ğ€ğ’• /ğ‘¿ğ’Šğ’• ) = ğŸ asumiendo ğœ‡ğ‘– fijos con ğ›½ğ‘Š âˆ’ ğ›½ğ‘‡ .
Probar ğ‘¬(ğ€ğ’• /ğ‘¿ğ’Šğ’• ) = ğŸ asumiendo ğœ‡ğ‘– aleatorios con ğ›½ğ‘‡ âˆ’ ğ›½ğºğ¿ğ‘† .
Probar ğ‘¬(ğğ’Š /ğ‘¿ğ’Šğ’• ) = ğŸ asumiendo ğœ†ğ‘¡ fijos con ğ›½ğ‘Š âˆ’ ğ›½ğ¶ .
Probar ğ‘¬(ğğ’Š /ğ‘¿ğ’Šğ’• ) = ğŸ asumiendo ğœ†ğ‘¡ aleatorios con ğ›½ğ¶ âˆ’ ğ›½ğºğ¿ğ‘† .
Comparar estimadores que asumen ğœ‡ğ‘– y ğœ† ğ‘‡ fijos versus aleatorios, tal que ğ¸(ğœ†ğ‘¡ /ğ‘‹ğ‘–ğ‘¡ ) = ğ¸(ğœ‡ğ‘–
/ğ‘‹ğ‘–ğ‘¡ ) = 0. Esta prueba se basa en ğ›½ğºğ¿ğ‘† âˆ’ ğ›½ğ‘Š .

DYNAMIC PANEL DATA MODELS (BALTAGI CAP 8)
8.1. INTRODUCCIÃ“N
Los modelos de datos de panel dinÃ¡micos son cruciales para entender las relaciones econÃ³micas a lo
largo del tiempo. Estos modelos permiten estudiar la dinÃ¡mica de ajuste mediante la inclusiÃ³n de una
variable dependiente rezagada en los regresores. La fÃ³rmula bÃ¡sica del modelo es:
â€²
ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ‘¦ğ‘–,ğ‘¡âˆ’1 + ğ‘¥ğ‘–ğ‘¡
ğ›½ + ğ‘¢ğ‘–ğ‘¡

donde ğ›¿ es un escalar, ğ‘¥â€²ğ‘–ğ‘¡ es un vector de regresores, y ğ‘¢ğ‘–ğ‘¡ sigue un modelo de componente de error:
ğ‘¢ğ‘–ğ‘¡ = ğœ‡ğ‘– + ğœˆğ‘–ğ‘¡
AquÃ­, ğœ‡ğ‘– son efectos individuales no observados y ğœˆğ‘–ğ‘¡ son errores aleatorios. La presencia de la variable
dependiente rezagada introduce autocorrelaciÃ³n y correlaciÃ³n con los efectos individuales, haciendo que
el estimador de MCO sea sesgado e inconsistente.
Problemas en la estimaciÃ³n: La inclusiÃ³n de una variable dependiente rezagada introduce problemas
de autocorrelaciÃ³n y correlaciÃ³n con los efectos individuales. Esto hace que el estimador de mÃ­nimos
cuadrados ordinarios (MCO) sea sesgado e inconsistente. El estimador de efectos fijos (FE) elimina los
efectos individuales mediante la transformaciÃ³n "within", pero la variable dependiente rezagada sigue
estando correlacionada con el tÃ©rmino de error transformado, lo que resulta en un sesgo de orden
ğ‘‚(1/ğ‘‡). Por su parte, el estimador de efectos aleatorios (GLS) tambiÃ©n es sesgado debido a la
correlaciÃ³n entre los efectos individuales y la variable dependiente rezagada.
Soluciones propuestas: Se sugiere las primeras diferencias como soluciÃ³n, ya que puede manejar mejor
la correlaciÃ³n con las variables predeterminadas. Anderson y Hsiao (1981) sugieren diferenciar el
modelo para eliminar ğœ‡ğ‘– y usar ğ›¥ğ‘¦ğ‘–ğ‘¡âˆ’2 o ğ‘¦ğ‘–ğ‘¡âˆ’2 como instrumentos para ğ›¥ğ‘¦ğ‘–ğ‘¡âˆ’1 , lo que lleva a
estimaciones consistentes, aunque no necesariamente eficientes.
El mÃ©todo de momentos generalizados (GMM) propuesto por Arellano y Bond (1991) proporciona un
procedimiento mÃ¡s eficiente para estimar modelos de panel dinÃ¡micos utilizando condiciones de
ortogonalidad entre los valores rezagados de ğ‘¦ğ‘–ğ‘¡ y las perturbaciones ğœˆğ‘–ğ‘¡ .
Avances y mÃ©todos alternativos: Los trabajos de Arellano y Bover (1995) y Blundell y Bond (1998)
extienden el mÃ©todo GMM para ofrecer soluciones mÃ¡s robustas.
8.2. EL ESTIMADOR DE ARELLANO Y BOND
Arellano y Bond (1991) propusieron un mÃ©todo eficiente para estimar modelos de datos de panel
dinÃ¡micos utilizando condiciones de ortogonalidad entre los valores rezagados de ğ‘¦ğ‘–ğ‘¡ y las
perturbaciones ğœˆğ‘–ğ‘¡ . Considere el siguiente modelo autorregresivo simple sin regresores adicionales:
ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ‘¦ğ‘–,ğ‘¡âˆ’1 + ğ‘¢ğ‘–ğ‘¡

ğ‘ğ‘ğ‘Ÿğ‘ ğ‘– = 1, â€¦ , ğ‘; ğ‘¡ = 1, â€¦ , ğ‘‡

donde ğ‘¢ğ‘–ğ‘¡ = ğœ‡ğ‘– + ğœˆğ‘– con ğœ‡ğ‘– âˆ¼ ğ¼ğ¼ğ·(0, ğœğœ‡2 ) y ğœˆğ‘–ğ‘¡ âˆ¼ ğ¼ğ¼ğ·(0, ğœğœˆ2 ), independientes entre sÃ­ y entre ellos. Para
obtener una estimaciÃ³n consistente de ğ›¿ cuando ğ‘ â†’ âˆ y ğ‘‡ es fijo, diferenciamos la ecuaciÃ³n para
eliminar los efectos individuales:

Esta diferenciaciÃ³n resulta en un tÃ©rmino de error que es un proceso MA (1) con una raÃ­z unitaria.
Utilizando instrumentos vÃ¡lidos como ğ‘¦1ğ‘– para ğ‘¡ = 3, ğ‘¦ğ‘–2 y ğ‘¦ğ‘–1 para ğ‘¡ = 4, y asÃ­ sucesivamente, se
pueden obtener estimaciones consistentes de ğ›¿.
ConstrucciÃ³n del Estimador Para el periodo ğ‘¡ = 3: ğ‘¦ğ‘–3 âˆ’ ğ‘¦ğ‘–2 = ğ›¿(ğ‘¦ğ‘–2 âˆ’ ğ‘¦ğ‘–1 ) + (ğœˆğ‘–3 âˆ’ ğœˆğ‘–2 ), dÃ³nde ğ‘¦ğ‘–1
es un instrumento vÃ¡lido porque no estÃ¡ correlacionado con (ğœˆğ‘–3 âˆ’ ğœˆğ‘–2 ). De manera similar, para ğ‘¡ = 4:
ğ‘¦ğ‘–4 âˆ’ ğ‘¦ğ‘–3 = ğ›¿(ğ‘¦ğ‘–3 âˆ’ ğ‘¦ğ‘–2 ) + (ğœˆğ‘–4 âˆ’ ğœˆğ‘–3 ), dÃ³nde los instrumentos vÃ¡lidos son ğ‘¦ğ‘–2 y ğ‘¦ğ‘–1 .

En base a este proceso, para el periodo ğ‘‡, el conjunto de instrumentos vÃ¡lidos se convierte en
(ğ‘¦ğ‘–1 , ğ‘¦ğ‘–2 , â€¦ , ğ‘¦ğ‘–,ğ‘‡âˆ’2 )
MÃ©todo de Momentos Generalizados (GMM): Para utilizar estos instrumentos de manera eficiente,
se construye una matriz de instrumentos ğ‘Šğ‘– que agrupa todos los valores rezagados de ğ‘¦. Utilizando las
condiciones de momento ğ¸(ğ‘Šğ‘–ğ‘‡ ğ›¥ğœˆğ‘– ) = 0, se obtienen estimaciones eficientes mediante mÃ©todos de
mÃ­nimos cuadrados generalizados (GLS). Premultiplicando la ecuaciÃ³n diferenciada por la matriz de
instrumentos y resolviendo, se obtiene un estimador preliminar consistente.
Este estimador se mejora utilizando un enfoque de GMM en dos pasos, que es mÃ¡s eficiente y aprovecha
todas las condiciones de momento disponibles. El estimador final de Arellano y Bond resulta en una
estimaciÃ³n Ã³ptima para ğ›¿, que es consistente y eficiente en grandes muestras.
En resumen, el estimador de Arellano y Bond mejora la eficiencia del mÃ©todo de Anderson y Hsiao
utilizando mÃ¡s condiciones de momento y proporcionando un procedimiento GMM mÃ¡s robusto. Es
ideal para paneles dinÃ¡micos donde ğ‘ es grande y ğ‘‡ es fijo, eliminando los efectos individuales y
manejando adecuadamente la correlaciÃ³n en los errores diferenciados.
8.2.1. PRUEBA PARA EFECTOS INDIVIDUALES EN MODELOS AUTORREGRESIVOS
Holtz-Eakin (1988) propone una prueba simple para detectar la presencia de efectos individuales en
modelos de datos de panel dinÃ¡micos. Utiliza un modelo autorregresivo simple sin regresores
adicionales:
ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ‘¦ğ‘–,ğ‘¡âˆ’1 + ğ‘¢ğ‘–ğ‘¡
donde ğ‘¢ğ‘–ğ‘¡ = ğœ‡ğ‘– + ğœˆğ‘– con ğœ‡ğ‘– âˆ¼ ğ¼ğ¼ğ·(0, ğœğœ‡2 ) y ğœˆğ‘–ğ‘¡ âˆ¼ ğ¼ğ¼ğ·(0, ğœğœˆ2 ), Supongamos que solo hay tres perÃ­odos
ğ‘‡ = 3, entonces este modelo se puede estimar usando los dos Ãºltimos perÃ­odos. Bajo la hipÃ³tesis nula
de no efectos individuales, se mantienen ciertas siguientes condiciones de ortogonalidad reformuladas:

1. La primera restricciÃ³n puede usarse para identificar ğ›¿ incluso si hay efectos individuales, ya que
ğ‘¦ğ‘–1 no estÃ¡ correlacionado con la diferencia de los errores en los perÃ­odos 3 y 2.
2. La segunda y tercera restricciones se usan para probar la hipÃ³tesis nula de no efectos
individuales. Si se cumplen, no hay correlaciÃ³n entre ğ‘¦ğ‘–,ğ‘¡ y los errores ğ‘¢ğ‘–,ğ‘¡ en diferentes
perÃ­odos, indicando que no hay efectos individuales.
Entonces, se usa la primera restricciÃ³n para identificar ğ›¿, y luego se evalÃºan las restricciones (2) y (3)
para evaluar si hay efectos individuales.
Para aplicar este modelo en la prÃ¡ctica, se forma un sistema de ecuaciones apiladas, que luego se puede
escribir como ğ’šâˆ— = ğ’€âˆ— ğœ¹ + ğ’–âˆ— , dÃ³nde ğ‘¦ âˆ— es el vector de diferencias de las variables dependientes, ğ‘Œ âˆ— es
el vector de diferencias de las variables independientes, y ğ‘¢âˆ— es el vector de diferencias de los tÃ©rminos
de error.
Holtz-Eakin estima este sistema de ecuaciones simultÃ¡neas utilizando variables instrumentales
diferentes para cada ecuaciÃ³n debido a la naturaleza dinÃ¡mica del modelo, y luego realiza mÃ­nimos
cuadrados generalizados (GLS) para obtener una estimaciÃ³n preliminar de ğ›¿ y evaluar las restricciones
de ortogonalidad adicionales para detectar la presencia de efectos individuales.
Prueba de efectos individuales: Para probar la presencia de efectos individuales, se sigue estos pasos:
1. Restricciones de ortogonalidad: Evaluar si las condiciones de ortogonalidad adicionales (2 y
3) son vÃ¡lidas, dado que la primera restricciÃ³n se utiliza para identificar ğ›¿.
2. CÃ¡lculo de SSQ: Calcular la suma ponderada de los cuadrados de los residuales transformados

3. CÃ¡lculo de L: Comparar SSQ bajo la hipÃ³tesis nula (SSQR) y la suma de cuadrados de los
residuales (SSW) que impone solo las restricciones necesarias para la versiÃ³n diferenciada.
4. Prueba ğŒğŸ : Verificar si la diferencia ğ¿ = ğ‘†ğ‘†ğ‘„ğ‘… âˆ’ ğ‘†ğ‘†ğ‘Š sigue una distribuciÃ³n ğœ’ 2 con grados
de libertad iguales al nÃºmero de restricciones sobreidentificadas.
En conclusiÃ³n, el test de Holtz-Eakin es una herramienta poderosa para detectar efectos individuales en
modelos dinÃ¡micos de panel, permitiendo identificar y controlar la heterogeneidad individual en la
estimaciÃ³n de estos modelos.
8.2.2. MODELOS CON VARIABLES EXÃ“GENAS
En los modelos dinÃ¡micos de datos de panel, se pueden incluir variables exÃ³genas ğ‘¥ğ‘–ğ‘¡ que, aunque se
correlacionen con los efectos individuales ğœ‡ğ‘– , no se correlacionan con los errores ğœˆğ‘–ğ‘¡ . Esta situaciÃ³n es
comÃºn en econometrÃ­a y se representa en la siguiente ecuaciÃ³n:
â€²
ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ‘¦(ğ‘–,ğ‘¡âˆ’1) + ğ‘¥ğ‘–ğ‘¡
ğ›½ + ğ‘¢ğ‘–ğ‘¡

donde ğ‘¢ğ‘–ğ‘¡ = ğœ‡ğ‘– + ğœˆğ‘–ğ‘¡ . El desafÃ­o radica en manejar las correlaciones entre las variables exÃ³genas y los
efectos individuales al mismo tiempo que se mantienen las propiedades deseadas de los errores.
Transformaciones y Restricciones de Ortogonalidad: Para eliminar los efectos individuales y obtener
estimaciones consistentes, se utiliza una transformaciÃ³n de primeras diferencias (FD). Esta
transformaciÃ³n elimina los efectos individuales al restar las observaciones consecutivas de la variable
dependiente y los regresores:
â€²
ğ›¥ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ›¥ğ‘¦ğ‘–,ğ‘¡âˆ’1 + ğ›¥ğ‘¥ğ‘–ğ‘¡
ğ›½ + ğ›¥ğœˆğ‘–ğ‘¡

En este contexto, las primeras diferencias de las variables ğ‘¥ğ‘–ğ‘¡ son instrumentos vÃ¡lidos para la ecuaciÃ³n
diferenciada, siempre y cuando sean estrictamente exÃ³genas. La exogeneidad estricta significa que las
ğ‘¥ğ‘–ğ‘¡ no estÃ¡n correlacionadas con los errores en ningÃºn periodo.
Proceso de InstrumentaciÃ³n:
Para manejar correctamente las primeras diferencias y las correlaciones de los errores, se construye una
matriz de instrumentos (ğ‘Š). Esta matriz contiene todas las variables ğ‘¥ğ‘–ğ‘¡ adecuadas que no se
correlacionan con los errores diferenciados. Si ğ‘¥ğ‘–ğ‘¡ son estrictamente exÃ³genas, todas las observaciones
de ğ‘¥ğ‘–ğ‘¡ se pueden usar como instrumentos. En los casos donde ğ‘¥ğ‘–ğ‘¡ son variables predeterminadas (que
pueden estar correlacionadas con errores pasados, pero no con errores futuros), solo las observaciones
previas de ğ‘¥ğ‘–ğ‘¡ son vÃ¡lidas como instrumentos en cada perÃ­odo.
EstimaciÃ³n de ParÃ¡metros: Con la matriz de instrumentos adecuada, se puede proceder a estimar los
parÃ¡metros del modelo utilizando el mÃ©todo de momentos generalizados (GMM). Este mÃ©todo se basa
en las propiedades de ortogonalidad de los instrumentos y los errores diferenciados para obtener
estimaciones consistentes y eficientes de los coeficientes del modelo.
En tÃ©rminos prÃ¡cticos, esto implica:
1. Definir las primeras diferencias: Transformar los datos restando observaciones consecutivas.
2. Construir la matriz de instrumentos: Incluir todas las observaciones relevantes de las
variables exÃ³genas que no se correlacionan con los errores.
3. Aplicar GMM: Utilizar las propiedades de ortogonalidad para estimar los parÃ¡metros del
modelo dinÃ¡mico.
ValidaciÃ³n y Pruebas: Para validar la consistencia del estimador GMM, Arellano y Bond (1991)
proponen una prueba para la ausencia de correlaciÃ³n serial de segundo orden en los errores
diferenciados. AdemÃ¡s, el test de Sargan verifica la validez de las restricciones de sobre identificaciÃ³n,
asegurando que los instrumentos son adecuados y suficientes para el modelo.
En conclusiÃ³n, los modelos con variables exÃ³genas en datos de panel dinÃ¡micos requieren una cuidadosa
consideraciÃ³n de las correlaciones entre los regresores y los efectos individuales. El uso de la

transformaciÃ³n de primeras diferencias y la correcta instrumentaciÃ³n mediante GMM permiten obtener
estimaciones consistentes y eficientes, asegurando que los modelos reflejen adecuadamente las
relaciones econÃ³micas dinÃ¡mica
8.3. EL ESTIMADOR DE ARELLANO Y BOVER
Arellano y Bover (1995) desarrollan un marco unificado para estimadores de variables instrumentales
(IV) eficientes en modelos de datos de panel dinÃ¡micos. Su enfoque se basa en el modelo de Hausman
y Taylor (1981) que incluye tanto variables que varÃ­an con el tiempo como variables invariables en el
tiempo. El modelo general es:

donde ğ‘¦ğ‘–ğ‘¡ es la variable dependiente, ğ‘¥ğ‘–ğ‘¡ son las variables que varÃ­an en el tiempo, mientras que ğ‘ğ‘– son
las invariables en el tiempo, ğœ‡ğ‘– son los efectos individuales no observados y ğœˆğ‘–ğ‘¡ los errores aleatorios
TransformaciÃ³n y Matriz de Instrumentos: Para manejar los efectos individuales y la heterogeneidad,
Arellano y Bover transforman el sistema de ecuaciones utilizando una matriz no singular ğ». Esta matriz
estÃ¡ diseÃ±ada para que los primeros ğ‘‡ âˆ’ 1 errores transformados no contengan los efectos individuales
ğœ‡ğ‘– , permitiendo que todas las variables exÃ³genas sean instrumentos vÃ¡lidos.
La clave estÃ¡ en la construcciÃ³n de la matriz de instrumentos ğ‘Š. En el caso del modelo de Hausman y
Taylor, las variables exÃ³genas ğ‘‹1 y ğ‘1 se utilizan como instrumentos. La matriz de instrumentos ğ‘€ğ‘– se
configura para garantizar la ortogonalidad entre los instrumentos y los errores transformados.
Estimador GMM: El estimador GMM (MÃ©todo de Momentos Generalizados) se obtiene al aplicar la
transformaciÃ³n y los instrumentos en las ecuaciones del modelo. La fÃ³rmula del estimador GMM se
expresa como:

donde ğ›º es la matriz de covarianza de los errores transformados, y ğœ‚Ì‚ es el estimador de los coeficientes
del modelo.
Caso DinÃ¡mico: Cuando se introduce una variable dependiente rezagada, el modelo se ajusta para
incluir ğ‘¦ğ‘–ğ‘¡âˆ’1 en la ecuaciÃ³n. Se redefine la matriz de instrumentos para incluir las observaciones
rezagadas adicionales que son vÃ¡lidas como instrumentos. Si los errores ğœˆğ‘–ğ‘¡ no estÃ¡n correlacionados
serialmente, se pueden incorporar restricciones de ortogonalidad adicionales, lo que permite usar valores
pasados de ğ‘¦ como instrumentos adicionales.
Robustez y Pruebas: Arellano y Bover tambiÃ©n proponen pruebas para verificar la ausencia de
correlaciÃ³n serial en los errores, asÃ­ como la validez de los instrumentos utilizados mediante la prueba
de Sargan. Estas pruebas aseguran que los instrumentos sean adecuados y que el estimador GMM sea
consistente y eficiente.
Asimismo, el estimador de Arellano y Bover se aplica en varios estudios empÃ­ricos, como en los modelos
de empleo y decisiones de inversiÃ³n, determinando la importancia de variables como la Q de Tobin,
considerando su posible endogeneidad. Este enfoque unificado y flexible permite abordar problemas
complejos en econometrÃ­a con modelos dinÃ¡micos de panel, proporcionando estimaciones robustas y
fiables.
8.4. CONDICIONES DE MOMENTO DE AHN Y SCHMIDT
Ahn y Schmidt (1995) identifican condiciones de momento adicionales que no son aprovechadas por
estimadores de variables instrumentales (IV) anteriores en modelos de datos de panel dinÃ¡micos. Estas
condiciones surgen a partir de las suposiciones estÃ¡ndar del modelo dinÃ¡mico y se pueden utilizar en un
marco de GMM (MÃ©todo de Momentos Generalizados).
Para ilustrarlo, consideremos un modelo dinÃ¡mico simple sin regresores: ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ‘¦ğ‘–,ğ‘¡âˆ’1 + ğ‘¢ğ‘–ğ‘¡

Donde ğ‘¢ğ‘–ğ‘¡ = ğœ‡ğ‘– + ğœˆğ‘–ğ‘¡ , y las suposiciones estÃ¡ndar son: (1) ğœˆğ‘–ğ‘¡ es no correlacionado con ğ‘¦ğ‘–0 ; (2) ğœˆğ‘–ğ‘¡ es
no correlacionado con ğœ‡ğ‘– ; (3) ğœˆğ‘–ğ‘¡ no estÃ¡n correlacionados entre sÃ­
Condiciones de Momento Tradicionales: Bajo estas suposiciones, se obtienen las siguientes
condiciones de momento tradicionales: ğ‘¬(ğ’šğ’Šğ’” âˆ†ğ’–ğ’Šğ’• ) = ğŸ ğ’‘ğ’‚ğ’“ğ’‚ ğ’• = ğŸ, â€¦ ğ‘», ğ’” = ğŸ, â€¦ , ğ’• âˆ’ ğŸ, que son las
restricciones utilizadas por Arellano y Bond (1991). Sin embargo, Ahn y Schmidt encuentran
condiciones de momento adicionales que no estÃ¡n implÃ­citas en las restricciones tradicionales.
Condiciones de Momento Adicionales: AdemÃ¡s de las restricciones tradicionales, Ahn y Schmidt
identifican condiciones adicionales: ğ‘¬(ğ’–ğ’Šğ‘» âˆ†ğ’–ğ’Šğ’• ) = ğŸ ğ’‘ğ’‚ğ’“ğ’‚ ğ’• = ğŸ, â€¦ , ğ‘» âˆ’ ğŸ, estas nuevas condiciones
implican que ğ‘¢ğ‘–ğ‘‡ no estÃ¡ correlacionado con los errores diferenciados anteriores. Combinando estas
condiciones con las tradicionales, obtenemos un conjunto completo de condiciones de momento.
AplicaciÃ³n en el Estimador GMM: Para utilizar estas condiciones en la estimaciÃ³n GMM,
consideramos el modelo dinÃ¡mico en forma diferenciada junto con la Ãºltima observaciÃ³n en niveles:
âˆ†ğ‘¦ğ‘–ğ‘¡ = ğ›¿âˆ†ğ‘¦ğ‘–,ğ‘¡âˆ’1 + âˆ†ğ‘¢ğ‘–ğ‘¡ ğ‘ğ‘ğ‘Ÿğ‘ ğ‘¡ = 2,3, . . , ğ‘‡
ğ‘¦ğ‘–ğ‘‡ = ğ›¿ğ‘¦ğ‘–,ğ‘‡1 + ğ‘¢ğ‘–ğ‘‡
Aunque no hay instrumentos observables legÃ­timos para la ecuaciÃ³n en niveles, la ecuaciÃ³n sigue siendo
Ãºtil debido a las restricciones de covarianza adicionales. Las condiciones de momento combinadas
permiten una estimaciÃ³n mÃ¡s eficiente usando GMM.
Robustez y Aplicaciones: Las condiciones de momento de Ahn y Schmidt son robustas bajo
suposiciones mÃ¡s dÃ©biles que las tradicionales. Por ejemplo, permiten que el estimador GMM basado
en estas condiciones sea asintÃ³ticamente equivalente al estimador de mÃ­nima distancia Ã³ptimo de
Chamberlain, alcanzando el lÃ­mite de eficiencia semiparamÃ©trica. AdemÃ¡s, Ahn y Schmidt exploran
restricciones adicionales bajo suposiciones de homocedasticidad y estacionariedad.
Modelos con Variables ExÃ³genas: En el modelo dinÃ¡mico de Hausman y Taylor (1981), Ahn y Schmidt
muestran cÃ³mo usar eficientemente variables exÃ³genas como instrumentos, aprovechando mÃ¡s
condiciones de ortogonalidad que son relevantes en la versiÃ³n dinÃ¡mica del modelo.
ConclusiÃ³n: El trabajo de Ahn y Schmidt (1995) proporciona un marco robusto para mejorar la
eficiencia de los estimadores en modelos de datos de panel dinÃ¡micos al identificar y utilizar condiciones
de momento adicionales. Estas condiciones permiten una estimaciÃ³n mÃ¡s precisa y eficiente mediante
GMM, incluso bajo suposiciones mÃ¡s dÃ©biles que las tradicionales. La metodologÃ­a desarrollada es
particularmente Ãºtil para modelos dinÃ¡micos con variables exÃ³genas, proporcionando un enfoque
generalizado y eficiente para la estimaciÃ³n de parÃ¡metros en estos contextos.
8.5. EL ESTIMADOR DE SISTEMA GMM DE BLUNDELL Y BOND
Blundell y Bond (1998) revisitan la importancia de explotar la condiciÃ³n inicial para generar estimadores
eficientes en el modelo de datos de panel dinÃ¡mico cuando ğ‘‡ es pequeÃ±o. Consideran un modelo de
panel autorregresivo simple sin regresores exÃ³genos:
ğ‘¦ğ‘–ğ‘¡ = ğ›¿ğ‘¦ğ‘–,ğ‘¡âˆ’1 + ğœ‡ğ‘– + ğœˆğ‘–ğ‘¡
con ğ¸(ğœ‡ğ‘– ) = 0, ğ¸(ğœˆğ‘–ğ‘¡ ) = 0, y ğ¸(ğœ‡ğ‘– ğœˆğ‘–ğ‘¡ ) = 0. Blundell y Bond se enfocan en el caso donde ğ‘‡ = 3, lo que
genera una Ãºnica condiciÃ³n de ortogonalidad dada por ğ¸(ğ‘¦ğ‘–1 ğ›¥ğœˆğ‘–3 ) = 0. En este escenario, ğ›¿ estÃ¡
justificada por una identificaciÃ³n exacta.
Problemas con los Instrumentos DÃ©biles: Para obtener el estimador IV de primera etapa, se corre una
regresiÃ³n de âˆ†ğ‘¦ğ‘–2 sobre ğ‘¦ğ‘–1 . Esta regresiÃ³n puede derivarse de (8.38) evaluada en ğ‘¡ = 2, restando ğ‘¦ğ‘–1 de
ambos lados:

Dado que se espera ğ¸(ğ‘¦ğ‘–1 ğœ‡ğ‘– ) > 0, entonces (ğ›¿ âˆ’ 1) estarÃ¡ sesgado hacia arriba. Blundell y Bond
encuentran que el sesgo y la precisiÃ³n pobre del estimador GMM en diferencias primeras se deben a
problemas de instrumentos dÃ©biles, caracterizados por el parÃ¡metro de concentraciÃ³n ğœ.
Mejorando la Eficiencia con el Estimador de Sistema GMM: Al imponer una restricciÃ³n adicional
de estacionariedad suave en el proceso de condiciones iniciales, es posible utilizar un estimador GMM
de sistema. Este estimador utiliza diferencias rezagadas de ğ‘¦ğ‘–ğ‘¡ como instrumentos para las ecuaciones
en niveles y niveles rezagados de ğ‘¦ğ‘–ğ‘¡ como instrumentos para las ecuaciones en diferencias primeras.
Esta combinaciÃ³n de ecuaciones en niveles y diferencias mejora significativamente la eficiencia del
estimador, especialmente cuando ğ›¿ se aproxima a 1 y ğœğœ‡2 /ğœğ‘¢2 aumenta.
Resultados EmpÃ­ricos y Simulaciones: Blundell y Bond revisan los coeficientes de capital y trabajo
en una funciÃ³n de producciÃ³n Cobb-Douglas usando datos de empresas manufactureras de EE. UU.
Durante 8 aÃ±os. El estimador GMM estÃ¡ndar muestra una baja estimaciÃ³n del coeficiente de capital y
baja precisiÃ³n en todos los coeficientes estimados. Sin embargo, el estimador GMM de sistema
proporciona estimaciones razonables y mÃ¡s precisas.
Importancia de la Estacionariedad en las Condiciones Iniciales: Hahn (1999) examinÃ³ el papel de
la condiciÃ³n inicial impuesta por el estimador de Blundell y Bond, encontrando que la ganancia en
eficiencia puede ser sustancial cuando se incorpora la estacionariedad. Bond y Windmeijer (2002)
proponen un estimador lineal simple para el caso donde las condiciones iniciales satisfacen la
estacionariedad de covarianza, mostrando que el estimador de Blundell y Bond es eficiente bajo esta
suposiciÃ³n.
ConclusiÃ³n: El estimador GMM de sistema de Blundell y Bond proporciona una mejora significativa
en la precisiÃ³n y reducciÃ³n del sesgo en comparaciÃ³n con el estimador GMM en diferencias primeras,
especialmente en casos de series persistentes y T pequeÃ±os. Este enfoque utiliza condiciones de
momento adicionales basadas en restricciones de estacionariedad, ofreciendo una soluciÃ³n robusta para
superar las limitaciones de instrumentos dÃ©biles en modelos de datos de panel dinÃ¡micos. La
metodologÃ­a de Blundell y Bond ha demostrado ser valiosa en estudios empÃ­ricos y simulaciones,
respaldando su utilidad en aplicaciones prÃ¡cticas de econometrÃ­a.
8.6. EL ESTIMADOR DE KEANE Y RUNKLE
El modelo de datos de panel con una variable dependiente rezagada y efectos aleatorios o cualquier otro
tipo de correlaciÃ³n serial que es invariante entre individuos se presenta como:
ğ‘¦ = ğ‘‹ğ›½ + ğ‘¢
donde ğ‘‹ contiene una variable dependiente rezagada. Consideramos el caso donde ğ¸(ğ‘¢ğ‘–ğ‘¡ /ğ‘‹ğ‘–ğ‘¡ ) â‰  0, y
existe un conjunto de instrumentos predeterminados ğ‘Š tal que ğ¸(ğ‘¢ğ‘–ğ‘¡ /ğ‘Šğ‘–ğ‘  ) = 0 para ğ‘  â‰¤ ğ‘¡, pero ğ¸(ğ‘¢ğ‘–ğ‘¡
/ğ‘Šğ‘–ğ‘  ) â‰  0 para ğ‘  > ğ‘¡. En otras palabras, ğ‘Š puede contener valores rezagados de ğ‘¦ğ‘–ğ‘¡ . Para este modelo,
el estimador de 2SLS proporcionarÃ¡ un estimador consistente para ğ›½.
Problemas con la Eficiencia en 2SLS: En el modelo de efectos aleatorios o cualquier otro tipo de
correlaciÃ³n serial, el estimador 2SLS no serÃ¡ eficiente. Por ello, Keane y Runkle (1992) sugieren un
algoritmo mÃ¡s eficiente que toma en cuenta esta estructura de varianza-covarianza mÃ¡s general para los
disturbios, basado en la idea de filtrado hacia adelante de la literatura de series de tiempo.
Procedimiento de EstimaciÃ³n: Primero, se obtiene una estimaciÃ³n consistente de âˆ‘âˆ’1
ğ‘‡ğ‘† â¬š y su
Ì‚
correspondiente descomposiciÃ³n de Cholesky ğ‘ƒğ‘‡ğ‘† Luego, se premultiplica el modelo por ğ‘„Ì‚ğ‘‡ğ‘† = (ğ¼ğ‘
âŠ— ğ‘ƒÌ‚ğ‘‡ğ‘† ) y se estima el modelo por 2SLS usando los instrumentos originales. El estimador es:

Uso de Diferencias Primeras: La diferenciaciÃ³n primera tambiÃ©n se usa en modelos de datos de panel
dinÃ¡micos para eliminar efectos especÃ­ficos individuales. Los errores diferenciados resultantes estÃ¡n
correlacionados serialmente de tipo MA (1) con raÃ­z unitaria si los errores originales ğœˆğ‘–ğ‘¡ son clÃ¡sicos.
En este caso, habrÃ¡ una ganancia en eficiencia al realizar el procedimiento KR en el modelo en
diferencias primeras.
HipÃ³tesis Importantes y Pruebas: Existen dos hipÃ³tesis importantes que son verificables:
1. HipÃ³tesis ğ‘¯ğ‘¨ : Dice que los instrumentos ğ‘Š son estrictamente exÃ³genos. Para probar ğ»ğ´ , KR
proponen una prueba basada en la diferencia entre 2SLS de efectos fijos (ğ¹ğ¸ âˆ’ 2ğ‘†ğ¿ğ‘†) y
2ğ‘†ğ¿ğ‘† en diferencias primeras (ğ¹ğ· âˆ’ 2ğ‘†ğ¿ğ‘†). La segunda hipÃ³tesis es ğ»ğµ : ğ¸(ğœ‡ğ‘– /ğ‘Šğ‘–ğ‘¡ ) = 0
2. Prueba de ğ‘¯ğ‘© : Si ğ»ğ´ es rechazado, los instrumentos son predeterminados y la prueba de
Hausman-Taylor es inapropiada. Por ello, la prueba para ğ»ğµ se basa en la diferencia entre ğ¹ğ· âˆ’
2ğ‘†ğ¿ğ‘† y 2ğ‘†ğ¿ğ‘†. Si ğ»ğµ es verdadero, ambos estimadores son consistentes, pero si no, solo ğ¹ğ· âˆ’
2ğ‘†ğ¿ğ‘† permanece consistente.
AplicaciÃ³n EmpÃ­rica: Keane y Runkle aplican sus procedimientos de estimaciÃ³n y prueba a un modelo
de consumo de ciclo de vida con expectativas racionales. Usando datos de 627 hogares encuestados
entre 1972 y 1982 por el Panel de Estudio sobre DinÃ¡mica de Ingresos de Michigan (PSID), rechazan la
exogeneidad fuerte de los instrumentos, lo que significa que el estimador Within es inconsistente y la
prueba estÃ¡ndar de Hausman no es adecuada. Concluyen que las estimaciones de KR-2SLS no rechazan
el modelo de ciclo de vida simple, pero usando las estimaciones Within inconsistentes para la inferencia
se obtendrÃ­an conclusiones incorrectas contra el modelo de ciclo de vida.
ConclusiÃ³n: El estimador de Keane y Runkle proporciona una soluciÃ³n eficiente para tratar con la
correlaciÃ³n serial general en datos de panel dinÃ¡micos, utilizando la idea de filtrado hacia adelante y
preservando el uso de instrumentos predeterminados. Las pruebas desarrolladas por KR son Ãºtiles para
verificar la exogeneidad de los instrumentos y la correlaciÃ³n entre los efectos individuales y los
instrumentos. En aplicaciones empÃ­ricas, este mÃ©todo ha demostrado ser mÃ¡s preciso y consistente,
evitando conclusiones incorrectas que podrÃ­an derivarse de estimaciones inconsistentes.
8.7. DESARROLLO FUTURO EN MODELOS DINÃMICOS DE DATA PANEL
La literatura sobre modelos dinÃ¡micos de datos de panel ha crecido significativamente, reflejando la
naturaleza dinÃ¡mica de muchos modelos econÃ³micos. Esta secciÃ³n resume algunos de los desarrollos
recientes mÃ¡s destacados.
â€¢

â€¢

â€¢

â€¢

Condiciones de Momentos Adicionales: Ahn y Schmidt (1995) identificaron condiciones de
momentos adicionales para modelos dinÃ¡micos de datos de panel que no habÃ­an sido
aprovechadas por estimadores IV anteriores. En 1997, propusieron un estimador GMM
linealizado que es tan eficiente como el GMM no lineal, proporcionando ademÃ¡s pruebas de
validez para estas restricciones no lineales.
EstimaciÃ³n AsintÃ³tica Eficiente: Hahn (1997) demostrÃ³ que el estimador GMM basado en un
conjunto creciente de instrumentos, a medida que aumenta el tamaÃ±o de la muestra, alcanza la
eficiencia semiparamÃ©trica del modelo. TambiÃ©n explorÃ³ el uso de series de Fourier o
polinomios como instrumentos eficientes.
IV Ã“ptimo y ComparaciÃ³n con ML: Wansbeek y Bekker (1996) encontraron que el estimador
de variables instrumentales (IV) Ã³ptimo es menos eficiente que el estimador de mÃ¡xima
verosimilitud (ML) en regiones probables del parÃ¡metro autorregresivo Î´. Sugieren que agregar
restricciones de momentos no lineales, como las propuestas por Ahn y Schmidt, puede reducir
esta pÃ©rdida de eficiencia.
Sesgo y Eficiencia en GMM: Ziliak (1997) investigÃ³ el equilibrio entre sesgo y eficiencia en
estimadores GMM para modelos dinÃ¡micos de datos de panel. Sus experimentos de Monte
Carlo indicaron que usar demasiadas condiciones de momento puede introducir sesgo severo,
recomendando el uso de instrumentos subÃ³ptimos para mantener un equilibrio adecuado entre
sesgo y eficiencia.

â€¢

â€¢

â€¢

Condiciones Redundantes: Ahn y Schmidt (1999) abordaron la identificaciÃ³n de condiciones
de momentos redundantes en modelos con variables estrictamente exÃ³genas. Encontraron que
ciertos momentos no mejoran la eficiencia y, por lo tanto, pueden ser ignorados sin pÃ©rdida de
eficiencia asintÃ³tica.
Estimadores LIML y GMM: Alonso-Borrego y Arellano (1999) y Alvarez y Arellano (2003)
exploraron las propiedades asintÃ³ticas de los estimadores LIML y GMM. Encontraron que
LIML es preferible a GMM cuando los instrumentos son dÃ©biles, mostrando menor sesgo.
AdemÃ¡s, cuando ğ‘‡ < ğ‘, el sesgo asintÃ³tico de LIML es menor que el de GMM y FE.
Modelos con Coeficientes HeterogÃ©neos: Wansbeek y Knapp (1999) propusieron mÃ©todos
para tratar con modelos dinÃ¡micos de panel que tienen coeficientes heterogÃ©neos en la variable
dependiente rezagada y la tendencia temporal. Mostraron que la doble diferenciaciÃ³n puede
eliminar efectos especÃ­ficos de paÃ­ses y coeficientes heterogÃ©neos, sugiriendo LIML como una
alternativa viable a GMM.

ConclusiÃ³n: Los desarrollos recientes en modelos dinÃ¡micos de datos de panel incluyen la
identificaciÃ³n y uso de condiciones de momentos adicionales, la adaptaciÃ³n de metodologÃ­as GMM y
LIML, y el desarrollo de criterios robustos para la selecciÃ³n de modelos y momentos. Estos avances han
mejorado significativamente la precisiÃ³n de las estimaciones en estudios empÃ­ricos y proporcionado
nuevas herramientas para abordar los desafÃ­os inherentes a los datos de panel dinÃ¡micos
8.8. EJEMPLO EMPÃRICO: DEMANDA DINÃMICA DE CIGARRILLOS
Baltagi y Levin (1992) estimaron un modelo de demanda dinÃ¡mica para cigarrillos utilizando datos de
panel de 46 estados de EE.UU. actualizados desde 1963 hasta 1992. La ecuaciÃ³n estimada es:

donde ğ¶ğ‘–ğ‘¡ es la venta per cÃ¡pita real de cigarrillos, ğ‘ƒğ‘–ğ‘¡ es el precio minorista promedio de un paquete de
cigarrillos en tÃ©rminos reales, ğ‘Œğ‘–ğ‘¡ es el ingreso disponible real per cÃ¡pita, y ğ‘ƒğ‘›ğ‘–ğ‘¡ es el precio mÃ­nimo real
de los cigarrillos en cualquier estado vecino, representando un efecto de contrabando casual. El tÃ©rmino
de perturbaciÃ³n ğ‘¢ğ‘–ğ‘¡ sigue un modelo de componentes de error bidimensional:
ğ‘¢ğ‘–ğ‘¡ = ğœ‡ğ‘– + ğœ†ğ‘¡ + ğœˆğ‘–ğ‘¡
donde ğœ‡ğ‘– son efectos especÃ­ficos del estado y ğœ†ğ‘¡ son efectos especÃ­ficos del aÃ±o, incluyendo
intervenciones polÃ­ticas y advertencias de salud.
Tabla 8.1: La Tabla 8.1 muestra los resultados de diversas estimaciones agrupadas de la ecuaciÃ³n de
demanda de cigarrillos para el periodo 1963-1992.

â€¢

â€¢

â€¢

OLS: Ignora los efectos de estado y
tiempo, arrojando una elasticidad de
precio a corto plazo baja (-0.09) y
una elasticidad de precio a largo
plazo alta (-2.98).
Within: Incluye efectos fijos de
estado y tiempo, proporcionando
una elasticidad de precio a corto
plazo mÃ¡s alta (-0.30) y una
elasticidad de precio a largo plazo
mÃ¡s baja (-1.79).
2SLS:
Utiliza
variables
instrumentales para abordar la
endogeneidad, con una elasticidad de precio a corto plazo de -0.205.

â€¢
â€¢
â€¢
â€¢

2SLS-KR: Introduce un mÃ©todo mÃ¡s eficiente basado en la filtraciÃ³n hacia adelante, con una
elasticidad de precio a corto plazo de -0.311.
Within-2SLS: Combina efectos fijos con 2SLS, obteniendo una elasticidad de precio a corto
plazo de -0.496.
FD-2SLS: Aplica diferenciaciÃ³n primera con 2SLS, resultando en una elasticidad de precio a
corto plazo de -0.348, luego FD-2SLS-KR es similar a FD-2SLS pero con filtraciÃ³n hacia
adelante, obteniendo una elasticidad de precio a corto plazo de -0.348.
GMM-one-step: Estimador GMM de un paso con una elasticidad de precio a corto plazo de 0.377, luego GMM-two-step es el estimador GMM de dos pasos con una elasticidad de precio
a corto plazo de -0.379.

Tabla 8.2: La Tabla 8.2 muestra los resultados del estimador GMM en dos pasos segÃºn Arellano y Bond
para la demanda de cigarrillos.
â€¢
â€¢

â€¢

â€¢

El modelo dinÃ¡mico de panel de datos de
Arellano-Bond utiliza 1288 observaciones de
46 estados a lo largo de 28 aÃ±os.
Los coeficientes estimados para el consumo
rezagado (ln ğ¶ğ‘–,ğ‘¡âˆ’1 ) y el precio propio
(ln ğ‘ƒğ‘–ğ‘¡ ) son significativos y coherentes con
las expectativas teÃ³ricas.
Las pruebas de sobreidentificaciÃ³n de Sargan
no rechazan la nulidad, lo que puede indicar
una falta de poder en la prueba dada la
estructura de los datos (ğ‘ = 46, ğ‘‡ = 28).
La prueba de correlaciÃ³n serial de primer
orden rechaza la nulidad, pero no se rechaza
para la correlaciÃ³n de segundo orden, que es
el resultado esperado en un modelo de
diferencias primeras con perturbaciones no
transformadas
originalmente
no
correlacionadas.

ConclusiÃ³n: El anÃ¡lisis de la demanda dinÃ¡mica de cigarrillos en 46 estados de EE. UU. de 1963 a 1992
revela que los mÃ©todos de estimaciÃ³n que consideran los efectos especÃ­ficos del estado y del tiempo, asÃ­
como la endogeneidad del consumo rezagado, producen resultados mÃ¡s precisos y coherentes. Los
modelos que utilizan mÃ©todos como Within, 2SLS y GMM ajustados muestran una mayor elasticidadprecio a corto plazo y menores coeficientes de consumo rezagado en comparaciÃ³n con OLS. Las pruebas
de sobreidentificaciÃ³n y de correlaciÃ³n serial validan la robustez de estos modelos. En particular, el
estimador FD-2SLS-KR y los mÃ©todos GMM destacan por proporcionar estimaciones mÃ¡s confiables,
sugiriendo la relevancia de utilizar tÃ©cnicas avanzadas para manejar la dinÃ¡mica y la heterogeneidad en
los datos de panel.
8.9. OTRAS LECTURAS
La exploraciÃ³n de modelos dinÃ¡micos de panel ha llevado al desarrollo de mÃ©todos avanzados para
manejar la autocorrelaciÃ³n, la heterogeneidad individual y los instrumentos dÃ©biles. Los trabajos
mencionados proporcionan herramientas cruciales para la estimaciÃ³n eficiente y robusta de parÃ¡metros,
destacando la importancia de la correcta especificaciÃ³n de los modelos y la validaciÃ³n de hipÃ³tesis en
estudios empÃ­ricos.

NONSTATIONARY PANELS (BALTAGI CAP 12)
12.1 INTRODUCCIÃ“N
El creciente uso de datos de distintos paÃ­ses en econometrÃ­a de datos de panel ha permitido estudiar
importantes fenÃ³menos econÃ³micos, como r la paridad del poder adquisitivo, la convergencia del
crecimiento y los efectos de derrame internacional de I+D. Esta secciÃ³n destaca el enfoque en las
propiedades asintÃ³ticas de macro paneles con un gran nÃºmero de paÃ­ses (N) y una larga serie temporal
(T). Se mencionan dos corrientes principales:
1. Regresiones HeterogÃ©neas: Este enfoque rechaza la homogeneidad de los parÃ¡metros de
regresiÃ³n, favoreciendo regresiones especÃ­ficas para cada paÃ­s. Se critica el uso de estimadores
agrupados estÃ¡ndar debido al sesgo potencial que pueden introducir.
2. Procedimientos de Series Temporales en Paneles: Este enfoque se centra en la no
estacionariedad, regresiones espurias y cointegraciÃ³n. Argumenta que la no estacionariedad es
mÃ¡s relevante en macro paneles. Se mencionan tÃ©cnicas de estimaciÃ³n modificadas que abordan
la endogeneidad y la heterocedasticidad.
Propiedades AsintÃ³ticas: En paneles no estacionarios, muchos estadÃ­sticos de prueba y estimadores
tienen distribuciones lÃ­mite normales, a diferencia de las series temporales individuales. Esto facilita la
realizaciÃ³n de pruebas de raÃ­z unitaria y cointegraciÃ³n, evitando problemas de regresiÃ³n espuria y
proporcionando estimaciones consistentes cuando ğ‘ y ğ‘‡ tienden al infinito
MÃ©todos recientes: En los Ãºltimos aÃ±os, se han aplicado numerosos mÃ©todos de series temporales a
datos de panel, destacando las pruebas de raÃ­z unitaria, pruebas de cointegraciÃ³n y la estimaciÃ³n de
relaciones a largo plazo. Estos mÃ©todos han mejorado la capacidad de anÃ¡lisis y precisiÃ³n en la
estimaciÃ³n de relaciones econÃ³micas de largo plazo, permitiendo una mejor comprensiÃ³n de los
fenÃ³menos econÃ³micos complejos a travÃ©s de un enfoque de datos de panel
Principales crÃ­ticas a los usos de los mÃ©todos de datos de panel:
â€¢
â€¢
â€¢
â€¢

Maddala et al. (2000): Argumentan que las pruebas de raÃ­z unitaria en datos de panel no
resuelven adecuadamente la PPP, ya que los resultados son mixtos y dependen del grupo de
paÃ­ses, el perÃ­odo de estudio y el tipo de prueba utilizada.
Maddala (1999): Las pruebas de raÃ­z unitaria en panel no abordan eficazmente la convergencia
del crecimiento entre paÃ­ses, aunque han impulsado investigaciones en modelos dinÃ¡micos de
datos de panel.
Quah (1996): SeÃ±ala que los paneles tradicionales no pueden responder si los paÃ­ses pobres
alcanzan a los ricos, sugiriendo modelos de dinÃ¡mica de ingresos en su lugar.
Smith (2000): Advierte contra la aplicaciÃ³n mecÃ¡nica de pruebas de raÃ­z unitaria o
cointegraciÃ³n en paneles, enfatizando que las hipÃ³tesis deben ser relevantes en el contexto
especÃ­fico.

Asimismo, las pruebas existentes dentro de los modelos asumen independencia transversal, lo cual es
restrictivo, ya que las series temporales macroeconÃ³micas muestran una correlaciÃ³n significativa entre
paÃ­ses. Por ello, se han propuesto modelos de factores dinÃ¡micos y pruebas alternativas para abordar la
dependencia transversal.
12.2 PRUEBAS DE RAÃCES UNITARIAS EN PANEL ASUMIENDO INDEPENDENCIA
TRANSVERSAL
Las pruebas de raÃ­ces unitarias en series temporales y paneles se han vuelto comunes en la investigaciÃ³n
economÃ©trica. Las pruebas de raÃ­ces unitarias en paneles, aunque recientes, han sido desarrolladas por
varios autores como Levin, Lin y Chu (2002), Im et al. (2003), y otros.
Las aproximaciones para los lÃ­mites asintÃ³ticos en estudios de panel se pueden abordar de varias
maneras, y cada una tiene sus propias caracterÃ­sticas y aplicaciones. Se pueden clasificar en tres
enfoques principales:

1. LÃ­mites Secuenciales: En esta aproximaciÃ³n, primero se fija un Ã­ndice, por ejemplo, el nÃºmero
de unidades transversales ğ‘. Luego, se permite que el otro Ã­ndice, la longitud de la serie
temporal ğ‘‡, aumente hasta el infinito. DespuÃ©s, se deja que ğ‘ tienda al infinito.
Ventajas: Son fÃ¡ciles de derivar y Ãºtiles para obtener resultados asintÃ³ticos rÃ¡pidamente.
Desventajas: Pueden ser engaÃ±osos en algunos casos, ya que los resultados obtenidos por esta
vÃ­a no siempre representan adecuadamente la realidad asintÃ³tica.
2. Trayectorias Diagonales: AquÃ­, ambos Ã­ndices ğ‘ y ğ‘‡ tienden al infinito simultÃ¡neamente,
siguiendo una trayectoria especÃ­fica en la matriz bidimensional. La trayectoria estÃ¡ determinada
por una relaciÃ³n funcional creciente ğ‘‡ = ğ‘‡(ğ‘)
Ventajas: Este enfoque considera el crecimiento simultÃ¡neo de ğ‘ y ğ‘‡, proporcionando una
perspectiva mÃ¡s equilibrada.
Desventajas: Los resultados dependen de la relaciÃ³n funcional especÃ­fica y la trayectoria
asumida puede no ser adecuada para todas las situaciones.
3. LÃ­mites Conjuntos: En este enfoque, tanto ğ‘ como ğ‘‡ tienden al infinito al mismo tiempo sin
imponer una trayectoria especÃ­fica.
Ventajas: Es mÃ¡s robusto y generalmente proporciona resultados mÃ¡s realistas.
Desventajas: Es mÃ¡s difÃ­cil de derivar y requiere condiciones estrictas, como la existencia de
momentos superiores para la uniformidad en los argumentos de convergencia.
Phillips y Moon (1999, 2000) aplican la teorÃ­a asintÃ³tica de mÃºltiples Ã­ndices a lÃ­mites conjuntos donde
ğ‘‡ y ğ‘ tienden al infinito y ğ‘‡/ğ‘ â†’ âˆ Esto es Ãºtil cuando la muestra de la serie temporal es grande en
comparaciÃ³n con la muestra de corte transversal. No obstante, este enfoque tambiÃ©n puede aplicarse a
situaciones donde ğ‘‡/ğ‘ â†’ 0, aunque los resultados lÃ­mite obtenidos serÃ¡n diferentes.
12.2.1 PRUEBA DE LEVIN, LIN Y CHU (LLC)
La prueba de LLC busca mejorar el poder de detecciÃ³n de raÃ­ces unitarias en series temporales en
paneles, especialmente en muestras pequeÃ±as. Argumentan que las pruebas de raÃ­ces unitarias
individuales tienen un poder limitado frente a hipÃ³tesis alternativas con desviaciones del equilibrio
persistentes. Asimismo, esta prueba es mÃ¡s poderosa que realizar pruebas individuales para cada secciÃ³n
transversal.
HipÃ³tesis:
â€¢
â€¢

HipÃ³tesis nula (ğ»0 ): Cada serie temporal individual contiene una raÃ­z unitaria.
HipÃ³tesis alternativa (ğ»1 ): Cada serie temporal es estacionaria.

Procedimiento de la Prueba
1. Regresiones ADF Individuales: Se realizan regresiones Augmented Dickey-Fuller (ADF) para
cada secciÃ³n transversal. AquÃ­, el orden de rezago ğ‘ğ‘– varÃ­a entre individuos y se debe seleccionar
ğ‘ğ‘šğ‘ğ‘¥ y ajustar segÃºn los t-estadÃ­sticos.
2. EstimaciÃ³n de la Varianza a Largo Plazo: Se estima la varianza a largo plazo bajo la hipÃ³tesis
nula de raÃ­z unitaria, calculando la ratio de la desviaciÃ³n estÃ¡ndar a largo plazo a la desviaciÃ³n
estÃ¡ndar de la innovaciÃ³n.
3. EstadÃ­sticos de la Prueba del Panel: Se ejecuta una regresiÃ³n agrupada y se calcula el
âˆ—
âˆ—
estadÃ­stico t convencional para ğ»0 : ğœŒ = 0, ajustando el t-estadÃ­stico con los valores ğœ‡ğ‘šğ‘‡
y ğœğ‘šğ‘‡
proporcionados por LLC.
La prueba LLC es ideal para paneles de tamaÃ±o moderado (N entre 10 y 250 y T entre 25 y 250).
Limitaciones: La prueba depende crucialmente de la suposiciÃ³n de independencia entre secciones
transversales, no es aplicable si hay correlaciÃ³n transversal, y la suposiciÃ³n de que todas las secciones
transversales tienen o no una raÃ­z unitaria es restrictiva.
Importancia: Los simulacros de Monte Carlo muestran que la distribuciÃ³n normal es una buena
aproximaciÃ³n para la distribuciÃ³n empÃ­rica del estadÃ­stico de prueba, incluso en muestras relativamente

pequeÃ±as. Asimismo, la prueba de raÃ­ces unitarias en panel de LLC proporciona mejoras significativas
en el poder sobre las pruebas de raÃ­ces unitarias individuales.
ConclusiÃ³n: La prueba de LLC es una herramienta poderosa y ampliamente utilizada para detectar
raÃ­ces unitarias en paneles de datos, especialmente en muestras de tamaÃ±o moderado, aunque tiene
ciertas limitaciones que deben considerarse al aplicarla.
12.2.2 PRUEBA DE IM, PESARAN Y SHIN
La prueba de Im, Pesaran y Shin (IPS) fue propuesta como una alternativa a la prueba de LLC debido a
que esta Ãºltima es restrictiva al requerir que el coeficiente de raÃ­z unitaria (ğœŒ) sea homogÃ©neo entre todas
las unidades transversales. Esto puede ser problemÃ¡tico en aplicaciones donde se espera heterogeneidad,
como la convergencia del crecimiento entre paÃ­ses. La prueba IPS permite coeficientes heterogÃ©neos y
se basa en promediar los estadÃ­sticos de pruebas de raÃ­z unitaria individuales, y sus hipÃ³tesis son:
â€¢
â€¢

HipÃ³tesis nula (ğ‘¯ğŸ ): Cada serie en el panel contiene una raÃ­z unitaria, es decir, ğœŒğ‘– = 0 para
todos los ğ‘–.
HipÃ³tesis alternativa (ğ‘¯ğŸ ): Algunas, pero no todas, las series individuales son estacionarias,
es decir,

1. RealizaciÃ³n de Pruebas DFA Individuales: Se realizan pruebas DFA para cada secciÃ³n
transversal, donde el orden de rezago (ğœŒğ‘– ) puede variar entre individuos. El estadÃ­stico t
individual para cada secciÃ³n se obtiene al probar ğ»0 : ğœŒğ‘– = 0
2. CÃ¡lculo del EstadÃ­stico t-bar: Se calcula el promedio de los estadÃ­sticos t individuales de las
1
pruebas ADF: ğ‘ âˆ‘ğ‘
ğ‘–=1 ğ‘¡ğœŒğ‘–
3. EstandarizaciÃ³n del EstadÃ­stico t-bar: Se estandariza el estadÃ­stico t-bar utilizando valores
esperados y varianzas simuladas bajo la hipÃ³tesis nula para diferentes combinaciones de ğ‘‡ y ğœŒğ‘–

El estadÃ­stico estandarizado ğ‘ğ‘¡âˆ’ğ‘ğ‘ğ‘Ÿ
asintÃ³ticamente.

sigue una distribuciÃ³n normal estÃ¡ndar ğ‘(0,1)

Aplicaciones y Limitaciones: La prueba IPS es ideal cuando se espera heterogeneidad en los
coeficientes de las series temporales individuales. Permite que algunas series sean estacionarias mientras
que otras no, proporcionando una mayor flexibilidad y realismo en las aplicaciones prÃ¡cticas. Sin
embargo, requiere simulaciones para determinar valores crÃ­ticos y varianzas especÃ­ficas, y su
rendimiento depende de la correcta selecciÃ³n del orden de rezago en las regresiones ADF subyacentes.
Importancia y ValidaciÃ³n: Los experimentos de Monte Carlo realizados por Im, Pesaran y Shin
muestran que, si se selecciona un orden de rezago adecuado, el rendimiento en muestras pequeÃ±as de la
prueba t-bar es razonablemente satisfactorio y generalmente mejor que la prueba LLC. La prueba IPS
aborda mejor la heterogeneidad y permite una evaluaciÃ³n mÃ¡s realista de la estacionariedad en paneles
de datos complejos.
ConclusiÃ³n: La prueba IPS es una herramienta potente para detectar raÃ­ces unitarias en paneles de datos,
ofreciendo una alternativa mÃ¡s flexible y adecuada en situaciones donde la homogeneidad no es una
suposiciÃ³n vÃ¡lida. Esta metodologÃ­a mejora la precisiÃ³n y el realismo de las evaluaciones de
estacionariedad en estudios empÃ­ricos con datos de panel
12.2.3 PRUEBA DE BREITUNG
Las pruebas de LLC y IPS asumen que el nÃºmero de secciones transversales (ğ‘) debe ser pequeÃ±o en
relaciÃ³n con el nÃºmero de perÃ­odos (ğ‘‡). Sin embargo, Breitung (2000) aborda la pÃ©rdida de poder
significativa en estas pruebas cuando se incluyen tendencias especÃ­ficas de cada individuo debido a la

correcciÃ³n de sesgo. Por ello, propone una prueba que no emplea dicha correcciÃ³n, mejorando asÃ­ el
poder de la prueba.
Procedimiento de la prueba:
1. Regresiones DFA Individuales: Igual que en la prueba LLC, se realizan regresiones DFA
individuales para cada secciÃ³n transversal utilizando solo ğ›¥ğ‘¦ğ‘–ğ‘¡âˆ’ğ¿ para obtener los residuos ğ‘’ğ‘–ğ‘¡
y ğœˆğ‘–ğ‘¡âˆ’1
2. TransformaciÃ³n de los Residuos: Los residuos ğ‘’ğ‘–ğ‘¡ se transforman usando la ortogonalizaciÃ³n
hacia adelante de Arellano y Bover (1995).
3. RegresiÃ³n Agrupada: Se ejecuta una regresiÃ³n agrupada para obtener el estadÃ­stico t para
ğ»0 : ğœŒ = 0, que sigue una distribuciÃ³n normal estÃ¡ndar ğ‘(0,1) en el lÃ­mite sin necesidad de
cÃ¡lculos de kernel.
Aplicaciones y Limitaciones: La prueba de Breitung ofrece una alternativa poderosa a las pruebas de
LLC e IPS, especialmente Ãºtil en situaciones donde la inclusiÃ³n de tendencias individuales puede causar
pÃ©rdidas de poder en otras pruebas. La transformaciÃ³n de los residuos y la eliminaciÃ³n de la correcciÃ³n
de sesgo hacen que esta prueba sea mÃ¡s robusta y eficaz en diversas aplicaciones. McCoskey y Selden
(1998) aplicaron la prueba IPS para testar la raÃ­z unitaria en gastos de salud per cÃ¡pita y PIB para un
panel de 20 paÃ­ses de la OCDE, mientras que Wu (2000) aplicÃ³ la prueba IPS a los balances de cuenta
corriente de 10 paÃ­ses de la OCDE.
ConclusiÃ³n: La prueba de Breitung proporciona una metodologÃ­a mÃ¡s robusta y eficaz para detectar
raÃ­ces unitarias en paneles de datos, mejorando el poder de las pruebas en comparaciÃ³n con LLC e IPS.
Su enfoque, que evita la correcciÃ³n de sesgo, es particularmente Ãºtil en estudios empÃ­ricos donde las
tendencias individuales son relevantes
12.2.4 PRUEBAS DE COMBINACIÃ“N DE P-VALUES
Las pruebas de combinaciÃ³n de p-values, propuestas por Maddala y Wu (1999) y Choi (2001), buscan
combinar los p-values de pruebas de raÃ­ces unitarias individuales para cada secciÃ³n transversal en
paneles de datos. Esta metodologÃ­a ofrece una alternativa a las pruebas LLC e IPS, permitiendo mÃ¡s
flexibilidad y poder de prueba.
Procedimiento de la Prueba
1. EstadÃ­stico de la Prueba Fisher: El estadÃ­stico de la prueba Fisher se define como:

AquÃ­ ğ‘ğ‘– es el p-value asintÃ³tico de la prueba de raÃ­z unitaria para la secciÃ³n transversal ğ‘–. Este
estadÃ­stico PPP sigue una distribuciÃ³n ğœ’ 2 con 2ğ‘ grados de libertad.
2. Pruebas Adicionales Propuestas por Choi:
Prueba Inversa Normal (Z): La prueba inversa normal transforma los p-values individuales
en puntajes z utilizando la funciÃ³n inversa de la distribuciÃ³n normal estÃ¡ndar y luego promedia
estos puntajes. Si el resultado promedio indica que muchos de los puntajes z son significativos,
se puede rechazar la hipÃ³tesis nula de que todas las series tienen raÃ­ces unitarias. Esta
transformaciÃ³n permite evaluar la significancia global de las pruebas individuales en una Ãºnica
medida.
Prueba Logit: La prueba logit convierte los p-values individuales en log-odds (la razÃ³n
logarÃ­tmica de las probabilidades) y luego promedia estos valores. Esta transformaciÃ³n maneja
mejor los p-values extremos y ofrece una manera robusta de combinar la informaciÃ³n de
mÃºltiples pruebas. Un promedio significativo de log-odds indicarÃ­a que muchas de las series no
tienen raÃ­ces unitarias.
Prueba Modificada de Fisher (Pm): La prueba modificada de Fisher combina los p-values
ajustando el estadÃ­stico de prueba para grandes paneles de datos, asegurando que el resultado
tenga una distribuciÃ³n normal estÃ¡ndar en grandes muestras. Esta combinaciÃ³n de p-values

permite una evaluaciÃ³n robusta y precisa de la hipÃ³tesis global de raÃ­ces unitarias, mejorando la
interpretaciÃ³n y aplicaciÃ³n en estudios empÃ­ricos.
Aplicaciones y Limitaciones: Las pruebas combinadas de p-values son ideales para paneles grandes y
permiten la heterogeneidad entre las series temporales individuales, permitiendo que algunas sean
estacionarias y otras no. AdemÃ¡s, no requieren un panel balanceado y permiten el uso de diferentes
longitudes de rezagos en las regresiones ADF individuales. Sin embargo, los p-values deben derivarse
mediante simulaciones de Monte Carlo, lo cual puede ser computacionalmente intensivo.
Importancia: Las pruebas combinadas de p-values tienen un rendimiento satisfactorio en muestras
pequeÃ±as y ofrecen un poder ajustado al tamaÃ±o superior en comparaciÃ³n con la prueba IPS. En
particular, la prueba Z muestra un desempeÃ±o sobresaliente en tÃ©rminos de poder y precisiÃ³n. Estas
pruebas han sido aplicadas a datos de tasas de cambio reales mensuales de EE.UU., encontrando
evidencia a favor de la hipÃ³tesis de paridad del poder adquisitivo (PPP), en contraste con la prueba IPS
ConclusiÃ³n: Las pruebas de combinaciÃ³n de p-values ofrecen una metodologÃ­a robusta y flexible para
la detecciÃ³n de raÃ­ces unitarias en paneles de datos, especialmente cuando se espera heterogeneidad
entre las series temporales individuales. Esta metodologÃ­a mejora significativamente la precisiÃ³n y el
realismo en la evaluaciÃ³n de la estacionariedad en estudios empÃ­ricos con datos de panel
12.2.5 PRUEBA LM BASADA EN RESIDUOS
Hadri (2000) desarrollÃ³ una prueba de Lagrange Multipliers (LM) basada en residuos para paneles de
datos, generalizando la prueba KPSS de series temporales a datos de panel. La hipÃ³tesis nula es que no
hay raÃ­z unitaria en ninguna serie del panel, mientras que la alternativa es que existe una raÃ­z unitaria en
al menos una serie del panel.
Procedimiento de la Prueba
1. Modelos Considerados:
Modelo con constante:
Modelo con constante y tendencia:
AquÃ­, ğ‘Ÿğ‘–ğ‘¡ es un paseo aleatorio y ğœ–ğ‘–ğ‘¡ âˆ¼ ğ¼ğ¼ğ‘(0, ğœğœ–2 ).
2. EstadÃ­stico LM: El estadÃ­stico LM se basa en los residuos obtenidos por MCO (MÃ­nimos Cuadrados
Ordinarios) de las regresiones anteriores, y se utiliza la suma parcial de los residuos para calcularlo
3. CÃ¡lculo del EstadÃ­stico Z: Se transforma el estadÃ­stico LM en un estadÃ­stico Z para obtener una
distribuciÃ³n estÃ¡ndar normal. Esto se hace ajustando los valores obtenidos para modelos con constante
y modelos con tendencia.
Aplicaciones y limitaciones: La prueba LM basada en residuos es Ãºtil para detectar la ausencia de raÃ­ces
unitarias de manera eficiente en paneles grandes, manteniendo el tamaÃ±o empÃ­rico cerca del nivel
nominal del 5% para N y T grandes. Sin embargo, la prueba puede ser sensible a la especificaciÃ³n de
tÃ©rminos determinÃ­sticos y su potencia disminuye significativamente cuando se incluyen tendencias
lineales en el modelo.
Importancia: Hadri (2000) mostrÃ³ mediante experimentos de Monte Carlo que la prueba LM tiene un
tamaÃ±o empÃ­rico cercano al nivel nominal del 5% para N y T suficientemente grandes. La prueba es
particularmente Ãºtil para validar la estacionariedad en paneles de datos, complementando otras pruebas
de raÃ­ces unitarias.
ConclusiÃ³n: La prueba LM basada en residuos de Hadri es una herramienta potente para detectar la
ausencia de raÃ­ces unitarias en paneles de datos, especialmente Ãºtil en estudios con paneles grandes y
complejos. Su robustez y eficiencia la convierten en una opciÃ³n valiosa para anÃ¡lisis de estacionariedad
en econometrÃ­a

12.3 PRUEBAS DE RAÃCES UNITARIAS EN PANEL PERMITIENDO DEPENDENCIA
TRANSVERSAL
La dependencia transversal es una caracterÃ­stica comÃºn en paneles de datos macroeconÃ³micos, donde
las series temporales de diferentes paÃ­ses o regiones pueden estar correlacionadas entre sÃ­. Pesaran
(2004) sugiere una prueba para detectar la dependencia transversal de los errores en modelos de panel,
lo cual es aplicable a paneles heterogÃ©neos y dinÃ¡micos con ğ‘‡ corto y ğ‘ grande
Prueba CD de Pesaran: Se basa en el promedio de los coeficientes de correlaciÃ³n empÃ­rica de los
residuos obtenidos de las regresiones individuales en el panel. Esta prueba permite detectar si existe
dependencia transversal significativa entre las series temporales de diferentes unidades del panel.
Para su procedimiento, se calcula el coeficiente de correlaciÃ³n entre los residuos de cada par de
secciones transversales y se promedia. Si el promedio de estos coeficientes es significativamente
diferente de cero, se rechaza la hipÃ³tesis nula de independencia transversal.
Modelos de factor dinÃ¡mico: AdemÃ¡s de la prueba CD, varios modelos de factor dinÃ¡mico han sido
propuestos para abordar la dependencia transversal:
1. Moon y Perron (2004): Proponen un modelo de factor comÃºn donde los errores tienen una estructura
de factor. Sugieren defactorizar los datos para construir una prueba de raÃ­z unitaria utilizando
estimaciones de componentes principales para identificar los factores.
2. Phillips y Sul (2003): Proponen un modelo de factor de tiempo comÃºn con parÃ¡metros idiosincrÃ¡ticos
que miden el impacto de los efectos comunes. Utilizan un procedimiento de ortogonalizaciÃ³n basado en
el mÃ©todo de momentos iterados y recomiendan una combinaciÃ³n de p-values de pruebas individuales
de raÃ­z unitaria.
3. Bai y Ng (2004): Proponen un modelo de factor dinÃ¡mico para separar la estacionariedad de los
factores y el componente idiosincrÃ¡tico, utilizando componentes principales estimados en diferencias
primeras de los datos.
4. Choi (2002): Usa un modelo de componentes de error donde las secciones transversales responden
homogÃ©neamente a un Ãºnico factor comÃºn. Sugiere descentrar los datos mediante GLS y combinar pvalues de pruebas ADF individuales.
Prueba CADF (Cross-Sectionally Augmented Dickey-Fuller) de Pesaran: Pesaran propone aÃ±adir
la media transversal rezagada y su primera diferencia en la regresiÃ³n ADF para eliminar la dependencia
transversal. La prueba CADF promedia los t-estadÃ­sticos CADF de cada unidad del panel y proporciona
valores crÃ­ticos especÃ­ficos para diferentes combinaciones de ğ‘ y ğ‘‡.
ConclusiÃ³n: Las pruebas de raÃ­z unitaria que permiten la dependencia transversal, como la prueba CD
y los modelos de factor dinÃ¡mico, abordan de manera efectiva la correlaciÃ³n entre series temporales de
diferentes unidades en un panel de datos. Estas metodologÃ­as ofrecen soluciones mÃ¡s precisas y robustas
para evaluar la estacionariedad en paneles grandes y complejos, mejorando la validez de los anÃ¡lisis
economÃ©tricos en estudios macroeconÃ³micos.
12.4 REGRESIÃ“N ESPURIA EN DATOS DE PANEL
La regresiÃ³n espuria ocurre cuando las variables no estacionarias parecen estar relacionadas cuando en
realidad no lo estÃ¡n, un problema identificado inicialmente en series temporales por Granger y Newbold
(1974). Entorf (1997) extendiÃ³ este estudio a datos de panel con efectos fijos, mientras que Kao (1999)
y Phillips y Moon (1999) derivaron las distribuciones asintÃ³ticas de los estimadores de mÃ­nimos
cuadrados ordinarios (OLS) y otros estadÃ­sticos convencionales en la regresiÃ³n espuria en datos de
panel.
Modelos y cointegraciÃ³n:

1. DefiniciÃ³n de ğœ·: En series temporales no estacionarias con matriz de varianza a LP ğœ, el
coeficiente ğ›½ puede interpretarse como un coeficiente de regresiÃ³n a largo plazo. Si la matriz
de varianza a largo plazo ğœ tiene rango deficiente, ğ›½ es un coeficiente de cointegraciÃ³n porque
ğ‘¦ğ‘¡ âˆ’ ğ›½ğ‘‹ğ‘¡ serÃ­a estacionario.
2. ExtensiÃ³n a Paneles:: Phillips y Moon (1999) extienden este concepto a regresiones de panel
con datos no estacionarios, permitiendo heterogeneidad entre individuos con matrices de
covarianza heterogÃ©neas.
Casos de Modelos de Panel: Phillips y Moon (1999) consideraron cuatro casos, donde el estimador
agrupado serÃ¡ consistente y tendrÃ¡ una distribuciÃ³n normal en el lÃ­mite.
1. RegresiÃ³n espuria de panel: No hay cointegraciÃ³n en series temporales.
2. CointegraciÃ³n heterogÃ©nea de panel: Cada individuo tiene su propia relaciÃ³n de
cointegraciÃ³n.
3. CointegraciÃ³n homogÃ©nea de panel: Los individuos tienen la misma relaciÃ³n de
cointegraciÃ³n.
4. CointegraciÃ³n casi homogÃ©nea de panel: Los individuos tienen relaciones de cointegraciÃ³n
ligeramente diferentes.
Resultados y Estimaciones: En regresiones espurias de panel, el estimador de mÃ­nimos cuadrados es
âˆšğ‘-consistente y tiene una distribuciÃ³n normal en el lÃ­mite, y Phillips y Moon (1999) demostraron que
la regresiÃ³n de secciÃ³n cruzada con datos promediados en el tiempo tambiÃ©n es âˆšğ‘-consistente para ğ›½.
Detrending y Estimaciones: Phillips y Moon (2000) mostraron que el detrending mediante OLS es mÃ¡s
eficiente asintÃ³ticamente que el detrending mediante GLS para estimar el coeficiente ğ›½, luego ellos
tambiÃ©n investigaron las propiedades asintÃ³ticas del estimador de mÃ¡xima verosimilitud gaussiano
(MLE) en modelos de regresiÃ³n dinÃ¡micos con tendencias determinÃ­sticas y estocÃ¡sticas, encontrando
consistencia en el modelo homogÃ©neo de tendencia.
ConclusiÃ³n: La regresiÃ³n espuria en paneles de datos puede ser consistente y tener una distribuciÃ³n
normal en el lÃ­mite, diferente de las regresiones espurias de series temporales puras. Diversos modelos
y tÃ©cnicas, como OLS, GLS y estimaciones de componentes principales, se utilizan para abordar la
heterogeneidad y la dependencia transversal en los datos de panel. Las investigaciones de Phillips y
Moon proporcionan un marco fundamental para el estudio de teorÃ­as de lÃ­mite secuencial y conjunto en
datos de panel no estacionarios.
12.5 PRUEBAS DE COINTEGRACIÃ“N PANEL
Las pruebas de cointegraciÃ³n en paneles buscan ofrecer mayor potencia que las pruebas individuales de
series temporales, que tienen bajo poder con series cortas. En estudios como la paridad del poder
adquisitivo y la convergencia en el crecimiento, agrupar datos de paÃ­ses similares (G7, OCDE,
Eurozona) aÃ±ade variaciÃ³n transversal, aumentando asÃ­ el poder de estas pruebas.
12.5.1 Pruebas DF y ADF basadas en residuales (Pruebas de Kao)
Kao (1999) propuso pruebas de raÃ­z unitaria tipo Dickey-Fuller (DF) y Augmented Dickey-Fuller (ADF)
para los residuales en un modelo de regresiÃ³n de panel. El objetivo de estas pruebas es verificar la
hipÃ³tesis nula de no cointegraciÃ³n en datos de panel, mejorando la potencia y precisiÃ³n respecto a las
pruebas individuales de series temporales.
Procedimiento de la Prueba: Su metodologÃ­a se basa en utilizar residuos de efectos fijos para calcular
pruebas de tipo DF y ADF.
1. Modelo de RegresiÃ³n: Se considera un modelo de regresiÃ³n de panel con efectos fijos.

â€²
2. EstimaciÃ³n de Residuos: Se calculan los residuos de efectos fijos: ğ‘’ğ‘–ğ‘¡ = ğ‘¦ğ‘–ğ‘¡ âˆ’ ğ‘¥ğ‘–ğ‘¡
ğ›½, y el
modelo de prueba se define como ğ‘’ğ‘–ğ‘¡ = ğœŒğ‘’ğ‘–ğ‘¡âˆ’1 + ğœˆğ‘–ğ‘¡ , donde la hipÃ³tesis nula serÃ¡: ğ»0 : ğœŒ = 1
3. CÃ¡lculo del Estimador OLS de ğ† y el EstadÃ­stico t: Se estima ğœŒ mediante MCO y se calcula
el estadÃ­stico t correspondiente.
4. Pruebas tipo DF: Se realizan dos tipos de prueba DF:
a. DFÏ y DFt: Consideran la exogeneidad fuerte de regresores y errores.
b. DFÏ y DFt**: Consideran la cointegraciÃ³n con relaciÃ³n endÃ³gena entre regresores y
errores.
5. Prueba ADF: Se extiende el modelo de prueba incluyendo rezagos de las diferencias de los
ğ‘
residuos: ğ‘’ğ‘–ğ‘¡ = ğœŒğ‘’ğ‘–ğ‘¡âˆ’1 + âˆ‘ğ‘—=1 ğœ—ğ‘— ğ›¥ğ‘’ğ‘–ğ‘¡âˆ’ğ‘— + ğœˆğ‘–ğ‘¡. Luego, el estadÃ­stico DFA se ajusta para probar
la no cointegraciÃ³n.

Resultados y DistribuciÃ³n AsintÃ³tica: Los estadÃ­sticos ğ·ğ¹ğœŒ, ğ·ğ¹ğ‘¡, ğ·ğ¹ğœŒâˆ— , ğ·ğ¹ğ‘¡ âˆ— y DFA convergen a
una distribuciÃ³n normal estÃ¡ndar ğ‘(0,1) mediante teorÃ­a de lÃ­mite secuencial. Esto permite realizar
inferencias robustas sobre la cointegraciÃ³n en paneles de datos.
Importancia y ValidaciÃ³n: Las pruebas de Kao son esenciales para verificar la presencia de relaciones
de cointegraciÃ³n en paneles de datos. Proporcionan una mejora significativa en tÃ©rminos de poder y
precisiÃ³n en comparaciÃ³n con las pruebas individuales de series temporales, siendo especialmente Ãºtiles
en estudios economÃ©tricos con datos de panel.
ConclusiÃ³n: Las pruebas DF y ADF basadas en residuales de Kao son herramientas poderosas para
evaluar la hipÃ³tesis de no cointegraciÃ³n en datos de panel. Estas pruebas ofrecen una metodologÃ­a
robusta y eficiente, mejorando la validez y fiabilidad de los anÃ¡lisis economÃ©tricos en paneles de datos
12.5.2 PRUEBA LM BASADA EN RESIDUOS
McCoskey y Kao (1998) desarrollaron una prueba basada en residuales para evaluar la hipÃ³tesis nula de
cointegraciÃ³n en paneles de datos, en lugar de la de no cointegraciÃ³n en paneles de datos, por lo que
extienden la prueba LM y la prueba LBI de la literatura de series temporales. Esta prueba es Ãºtil para
validar la cointegraciÃ³n en datos de panel.
Procedimiento de la Prueba:
1. Modelo de RegresiÃ³n: La hipÃ³tesis nula de cointegraciÃ³n se define como ğœƒ = 0, donde ğœƒ es el
coeficiente de la variable de error.
2. EstimaciÃ³n Eficiente: Se utilizan estimadores como FM-OLS (Fully Modified Ordinary Least
Squares) y DOLS (Dynamic Ordinary Least Squares) para obtener estimaciones eficientes de
las variables cointegradas.
3. CÃ¡lculo del estadÃ­stico LM: El estadÃ­stico LM se basa en los residuos obtenidos de las
regresiones anteriores. Se define como el proceso de suma parcial de los residuales ğ‘†ğ‘–ğ‘¡ =
âˆ‘ğ‘¡ğ‘—=1 ğ‘’ğ‘–ğ‘— y la varianza de los residuales ğœğ‘’2
4. DistribuciÃ³n asintÃ³tica: El resultado asintÃ³tico del estadÃ­stico LM es una distribuciÃ³n normal
estÃ¡ndar ğ‘(0,1). Los momentos ğœ‡ğœˆ y ğœğœˆ2 se obtienen mediante simulaciones de Monte Carlo
para asegurar la robustez del estadÃ­stico ante heterocedasticidad.
Importancia y ValidaciÃ³n: La prueba LM basada en residuales es robusta y eficaz para detectar la
cointegraciÃ³n en paneles de datos. Permite la validaciÃ³n de la cointegraciÃ³n al mantener un tamaÃ±o
empÃ­rico cercano al nivel nominal del 5% para paneles grandes. Los resultados muestran que esta prueba
es eficiente y puede complementar otras pruebas de cointegraciÃ³n en estudios economÃ©tricos con datos
de panel.
ConclusiÃ³n: La prueba LM basada en residuales de McCoskey y Kao es una herramienta potente para
validar la cointegraciÃ³n en paneles de datos, proporcionando una metodologÃ­a robusta y eficiente. Esta
prueba mejora la precisiÃ³n y confiabilidad en la evaluaciÃ³n de la cointegraciÃ³n en estudios empÃ­ricos.

12.5.3 PRUEBA PEDRONI
La prueba de Pedroni (1999) estÃ¡ diseÃ±ada para probar la hipÃ³tesis nula de no cointegraciÃ³n en datos de
panel, permitiendo una considerable heterogeneidad entre las secciones transversales. Pedroni clasifica
las pruebas en dos categorÃ­as principales: pruebas basadas en el promediado de estadÃ­sticos de
cointegraciÃ³n de series temporales y pruebas de ratio de varianza de panel.
ClasificaciÃ³n de las Pruebas:
1. Primera CategorÃ­a: Promedio de estadÃ­sticos de cointegraciÃ³n de series temporales: Esta
categorÃ­a promedia los estadÃ­sticos de cointegraciÃ³n de las series temporales a travÃ©s de las
secciones transversales. La prueba se basa en los mÃ©todos desarrollados por Phillips y Ouliaris
(1990). AquÃ­, los residuos estimados de cada secciÃ³n transversal se utilizan para construir los
estadÃ­sticos de prueba, considerando las varianzas a largo plazo y contemporÃ¡neas de los
residuos.
Ejemplo de estadÃ­stico: Uno de los estadÃ­sticos se define como la media de las razones entre las
varianzas contemporÃ¡neas y las varianzas a largo plazo de los residuos, proporcionando una
medida robusta de cointegraciÃ³n en presencia de heterogeneidad.
2. Segunda CategorÃ­a: EstadÃ­sticas de Ratio de Varianza de Panel: Pedroni define cuatro
estadÃ­sticas diferentes dentro de esta categorÃ­a, que comparan las varianzas de los residuos
estimados. Estas pruebas evalÃºan la cointegraciÃ³n en el contexto de la heterogeneidad permitida
entre las secciones transversales, asegurando que las relaciones cointegradas sean robustas a las
diferencias individuales.
Ejemplo de estadÃ­stico: Una de las estadÃ­sticas es la ratio de la varianza de los residuos a corto
plazo frente a la varianza de los residuos a largo plazo, evaluando si las series se mueven
conjuntamente a largo plazo pese a la variabilidad a corto plazo.
DistribuciÃ³n AsintÃ³tica: Las pruebas de Pedroni tienen una distribuciÃ³n asintÃ³tica normal estÃ¡ndar
bajo la hipÃ³tesis nula de no cointegraciÃ³n. Esto permite la aplicaciÃ³n de estas pruebas en grandes paneles
de datos con mÃºltiples secciones transversales, mejorando la capacidad de inferencia sobre la
cointegraciÃ³n en estudios empÃ­ricos.
IntuiciÃ³n de la prueba: La convergencia en la distribuciÃ³n se basa en la convergencia individual de los
tÃ©rminos del numerador y denominador en las estadÃ­sticas de prueba. Si suficientes secciones
transversales muestran desviaciones significativas de los valores esperados bajo la hipÃ³tesis nula, la
prueba rechazarÃ¡ la hipÃ³tesis nula, indicando la presencia de cointegraciÃ³n.
Importancia y ValidaciÃ³n: Las pruebas de Pedroni permiten una considerable heterogeneidad en las
relaciones de cointegraciÃ³n, proporcionando una metodologÃ­a robusta para analizar la cointegraciÃ³n en
datos de panel. Estas pruebas son esenciales para estudios macroeconÃ³micos y financieros donde las
relaciones a largo plazo entre variables pueden variar significativamente entre diferentes paÃ­ses o
regiones.
ConclusiÃ³n: Las pruebas de Pedroni ofrecen una metodologÃ­a robusta y flexible para detectar la
cointegraciÃ³n en paneles de datos, permitiendo la heterogeneidad entre las secciones transversales. Esta
capacidad de manejar diferencias individuales mejora significativamente la validez y precisiÃ³n de los
anÃ¡lisis economÃ©tricos en estudios empÃ­ricos con datos de panel
12.5.4 PRUEBA DE COINTEGRACIÃ“N BASADA EN LA VEROSIMILITUD
Su objetivo es probar el rango de cointegraciÃ³n en modelos de panel heterogÃ©neos. Para ello, su mÃ©todo
se basa en usar el promedio de los estadÃ­sticos de traza individuales de Johansen, y sus resultados son
que se requiere una gran dimensiÃ³n de series temporales para evitar distorsiones de tamaÃ±o.
12.5.5 PROPIEDADES EN MUESTRAS FINITAS:
El anÃ¡lisis de propiedades en muestras finitas se centra en evaluar el rendimiento y la validez de
diferentes pruebas de cointegraciÃ³n cuando se aplican a conjuntos de datos de tamaÃ±o limitado. Este

estudio es crucial para entender cÃ³mo los resultados de estas pruebas pueden variar y quÃ© tan confiables
son bajo condiciones de muestra finita.
Comparaciones de TamaÃ±o y Poder de Pruebas de CointegraciÃ³n
1. Pruebas ADF Promedio y Pedroni: Estas pruebas han demostrado ser efectivas en tÃ©rminos
de poder, lo que significa que tienen una buena capacidad para detectar cointegraciÃ³n cuando
realmente estÃ¡ presente en los datos.
Son utilizadas para verificar la presencia de relaciones a largo plazo entre variables en paneles
de datos, siendo robustas a la heterogeneidad entre las secciones transversales.
3. Pruebas Basadas en la HipÃ³tesis Nula de CointegraciÃ³n (LM de McCoskey y Kao): Estas
pruebas son eficaces para determinar si las series de datos subyacentes estÃ¡n cointegradas bajo
la hipÃ³tesis nula. Son particularmente Ãºtiles cuando la hipÃ³tesis de cointegraciÃ³n es mÃ¡s lÃ³gica
que la de no cointegraciÃ³n.
Aunque tienen un buen desempeÃ±o en ciertos contextos, su principal fortaleza radica en evaluar
la cointegraciÃ³n como hipÃ³tesis nula.
Relevancia:
â€¢
â€¢

ResoluciÃ³n de Problemas de Bajo Poder en Pruebas Individuales: Las pruebas de
cointegraciÃ³n en panel, como las mencionadas anteriormente, abordan eficazmente el problema
del bajo poder que se observa en las pruebas de cointegraciÃ³n aplicadas a series individuales.
Utilidad de las Pruebas LM: Estas pruebas son particularmente Ãºtiles cuando se trabaja con
datos donde la hipÃ³tesis de cointegraciÃ³n es mÃ¡s probable. Ayudan a validar la presencia de
relaciones a largo plazo entre las variables estudiadas.

ConclusiÃ³n: El estudio de las propiedades en muestras finitas resalta la importancia de seleccionar la
prueba adecuada segÃºn el contexto del estudio y la naturaleza de los datos. Las pruebas de ADF
promedio y las pruebas de Pedroni son recomendables por su buen desempeÃ±o en poder, mientras que
las pruebas LM son valiosas para validar la hipÃ³tesis de cointegraciÃ³n.
12.6 ESTIMACIÃ“N E INFERENCIA EN MODELOS DE COINTEGRACIÃ“N DE PANEL
Los modelos de cointegraciÃ³n en panel se utilizan para estudiar relaciones econÃ³micas a largo plazo,
tÃ­picas en datos macroeconÃ³micos y financieros. Las propiedades asintÃ³ticas de los estimadores de
coeficientes de regresiÃ³n en estos modelos difieren de los modelos de cointegraciÃ³n de series
temporales.
Principales MÃ©todos de EstimaciÃ³n
1. Estimador OLS: El estimador OLS presenta un sesgo considerable en muestras finitas y no es
consistente en paneles, en contraste con su uso en series temporales individuales.
2. Estimador FM (Fully Modified OLS): Propuesto por Phillips y Moon (1999) y extendido por
Pedroni (2000), este mÃ©todo generaliza el trabajo de Phillips y Hansen (1990). Aunque es
asintÃ³ticamente normal, no siempre mejora los resultados obtenidos con OLS.
3. Estimador DOLS (Dynamic OLS): Propuesto por Kao y Chiang (2000), este estimador es mÃ¡s
prometedor que OLS o FM para regresiones cointegradas en paneles. Utiliza datos ajustados
para corregir sesgos y obtener una distribuciÃ³n normal en el lÃ­mite.
ComparaciÃ³n de mÃ©todos: Kao y Chiang (2000) sugieren que el DOLS es superior al OLS y FM en
regresiones cointegradas de panel, mientras que Chen, McCoskey y Kao (1999): Analizaron las
propiedades de muestra finita del OLS y los estimadores corregidos por sesgo, concluyendo que FM y
DOLS son alternativas mÃ¡s prometedoras.
Conclusiones: Es fundamental corregir los sesgos en estimaciones OLS para mejorar la precisiÃ³n, y el
DOLS es recomendado sobre OLS y FM en muchos casos. Asimismo, la independencia transversal es
una suposiciÃ³n clave, y las tÃ©cnicas deben considerar la posibilidad de raÃ­ces unitarias cercanas en lugar
de exactas.

Recomendaciones: Considerar el sesgo en estimaciones OLS y corregirlo con mÃ©todos como FM y
DOLS, y tener cuidado al interpretar resultados empÃ­ricos de mÃ©todos recientes de cointegraciÃ³n en
panel que asumen raÃ­ces unitarias exactas, ya que las raÃ­ces unitarias cercanas tambiÃ©n son plausibles.
12.7 EMPIRICAL EXAMPLE: PARIDAD DEL PODER ADQUISITIVO
Banerjee et al. (2005) revisan la literatura empÃ­rica sobre la validez de la paridad de poder adquisitivo
(PPP). La versiÃ³n fuerte de la PPP prueba si el tipo de cambio real es estacionario. Generalmente, se
encuentra que la PPP se mantiene cuando se prueba en datos de panel, pero no cuando se prueba
individualmente por paÃ­s. Esta discrepancia puede deberse al sobreajuste presente cuando las relaciones
de cointegraciÃ³n vinculan a los paÃ­ses del panel.
Hallazgos de Banerjee et al. (2005):
Se encuentra que los tests de raÃ­z unitaria de panel son mÃ¡s poderosos que los tests univariados, y la
existencia de relaciones de cointegraciÃ³n entre los paÃ­ses del panel puede causar un tamaÃ±o empÃ­rico
mayor que el nominal, lo que lleva al rechazo de la hipÃ³tesis nula de una raÃ­z unitaria con demasiada
frecuencia.
Asimismo, usando datos trimestrales de tipos de cambio reales para el perÃ­odo 1975:1â€“2002:4 para 18
paÃ­ses de la OCDE, encontraron que la hipÃ³tesis nula de una raÃ­z unitaria no se rechazÃ³ para la mayorÃ­a
de los paÃ­ses cuando se probÃ³ individualmente, excepto para Francia y Corea cuando Alemania es el
numerario, y ajustando los valores crÃ­ticos para la presencia de cointegraciÃ³n entre paÃ­ses, las rechazos
disminuyen significativamente.
Tabla 12.1: Prueba de RaÃ­z Unitaria en Panel para Tipos de Cambio Reales
Resumen de la Prueba:
â€¢
â€¢
â€¢
â€¢
â€¢

Muestra: 1975Q1-2002Q4
Series: Tipos de cambio reales de
18 paÃ­ses de la OCDE con
Alemania como numerario
Variables exÃ³genas: Efectos
individuales
SelecciÃ³n
automÃ¡tica
de
retrasos: Basado en SIC, de 0 a 8
SelecciÃ³n de ancho de banda de
Newey-West usando kernel de
Bartlett

InterpretaciÃ³n de Resultados
â€¢
â€¢

Los resultados confirman que todas las pruebas de raÃ­z unitaria de panel, incluyendo efectos
individuales, rechazan la hipÃ³tesis nula de una raÃ­z unitaria comÃºn.
La prueba de Hadri, que invierte la hipÃ³tesis nula, rechaza la hipÃ³tesis de que no hay raÃ­z unitaria
en favor de una raÃ­z unitaria comÃºn en el panel.

Conclusiones
â€¢
â€¢
â€¢

Es necesario tener precauciÃ³n al usar mÃ©todos de panel para probar raÃ­ces unitarias en series
temporales macroeconÃ³micas.
Las pruebas deben considerar la posibilidad de cointegraciÃ³n entre las unidades del panel.
Banerjee et al. (2004) sugieren extraer las tendencias comunes de cada unidad usando el mÃ©todo
de mÃ¡xima verosimilitud de Johansen y probar la cointegraciÃ³n entre estas tendencias antes de
aplicar mÃ©todos de cointegraciÃ³n en panel.

BASIC LINEAR UNOBSERVED EFFECTS PANEL DATA MODELS (WOOLRIDGE CAP 10)
10.1 MOTIVATION: OMITTED VARIABLES PROBLEM
Se pueden usar los datos de panel, al menos bajo ciertos supuestos, para obtener estimadores consistentes
en presencia de variables omitidas. Las variables omitidas son aquellas que no se incluyen en el modelo
pero que afectan la variable dependiente. Estas variables pueden causar sesgo en las estimaciones si
estÃ¡n correlacionadas con las variables explicativas observadas.
Las variables omitidas pueden influir en los resultados de nuestro modelo. En un modelo lineal, si ğ‘¦ es
la variable dependiente, ğ‘¥ son las variables explicativas observables y ğ‘ representa las variables
omitidas, tenemos la siguiente funciÃ³n de regresiÃ³n poblacional:
ğ¸(ğ‘¦|ğ‘¥, ğ‘) = ğ›½0 + ğ‘¥ğ›½ + ğ‘
AquÃ­, ğ›½ son los coeficientes a estimar. Si no podemos controlar ğ‘ (la variable omitida), las estimaciones
de ğ›½ serÃ¡n sesgadas. Esto significa que las conclusiones sobre la relaciÃ³n entre ğ‘¥ e ğ‘¦ pueden ser
incorrectas.
Para obtener estimaciones consistentes y no sesgadas de ğ›½, es crucial mantener ğ‘ constante. Sin
informaciÃ³n adicional que permita controlar ğ‘, no podemos estar seguros de que nuestras estimaciones
sean correctas. Los datos de panel permiten controlar estos efectos no observados mediante la inclusiÃ³n
de efectos fijos o aleatorios, lo que mejora la precisiÃ³n y validez de las estimaciones.
Bajo supuestos adicionales, hay formas de abordar el problema ğ¶ğ‘œğ‘£(ğ‘¥, ğ‘) â‰  0. Hemos cubierto al menos
tres posibilidades en el contexto del anÃ¡lisis de secciÃ³n transversal.
1. PodrÃ­amos ser capaces de encontrar una variable proxy adecuada para ğ‘, en cuyo caso podemos
estimar una ecuaciÃ³n por OLS donde el proxy estÃ¡ conectado para ğ‘.
2. Podemos encontrar instrumentos para los elementos de ğ‘¥ que estÃ¡n correlacionados con ğ‘ y usar
un mÃ©todo de variables instrumentales, como 2SLS.
3. Podemos ser capaces de encontrar indicadores de ğ¶ que luego se pueden utilizar en el
procedimiento de variables instrumentales de indicadores mÃºltiples.
Si podemos observar las mismas unidades de secciÃ³n transversal en diferentes puntos en el tiempo, es
decir, si podemos recopilar un conjunto de datos de panel, entonces surgen otras posibilidades.
Una variable no observada y constante en el tiempo se denomina efecto no observado en el anÃ¡lisis de
datos de panel.
Si asumiÃ©ramos ğ¸(ğ‘¥ğ‘¡â€² ğ‘) = 0, podrÃ­amos aplicar OLS agrupados. Si ğ‘ se correlaciona con cualquier
elemento de ğ‘¥ğ‘¡ , entonces el OLS agrupado estÃ¡ sesgado y es inconsistente.
Con dos aÃ±os de datos podemos hacer una ecuaciÃ³n de diferencia a travÃ©s de los dos perÃ­odos de tiempo
para eliminar la constante de tiempo inobservable, ğ‘.
Â¿Bajo quÃ© supuestos serÃ¡ consistente el estimador OLS de la siguiente ecuaciÃ³n?
âˆ†ğ‘¦ = âˆ†ğ‘¥ğ›½ + âˆ†ğ‘¢
La condiciÃ³n clave para que OLS estime consistentemente ğ›½ son las condiciones de ortogonalidad:
ğ¸(âˆ†ğ‘¥âˆ†ğ‘¢) = 0, y la condiciÃ³n de rango ğ¸(âˆ†ğ‘¥ â€² âˆ†ğ‘¥) = ğ¾
Si una variable en ğ‘¥ğ‘¡ es constante a lo largo del tiempo para cada miembro de la poblaciÃ³n, entonces âˆ†ğ‘¥
serÃ¡ cero, lo que viola la condiciÃ³n de rango necesaria para estimar consistentemente ğ›½ğ‘— . Esto se debe a
que no podemos distinguir el efecto de una variable constante del efecto de ğ‘. Por lo tanto, solo podemos
estimar consistentemente ğ›½ğ‘— si hay variaciÃ³n en ğ‘¥ğ‘¡ğ‘— a lo largo del tiempo.

Un panel equilibrado es aquel en el que todas las unidades de secciÃ³n transversal se observan en los
mismos perÃ­odos de tiempo. En cambio, un panel desequilibrado, donde los perÃ­odos de observaciÃ³n
varÃ­an entre las unidades, requiere un tratamiento cuidadoso para evitar problemas de selecciÃ³n de
muestras.
En estudios de grandes regiones geogrÃ¡ficas, la suposiciÃ³n de muestreo aleatorio en la dimensiÃ³n
transversal puede ser inapropiada. Sin embargo, si el tamaÃ±o de la poblaciÃ³n (\(N\)) es grande en
comparaciÃ³n con el tiempo ğ‘‡, y se puede asumir independencia entre las secciones transversales, el
anÃ¡lisis asintÃ³tico es adecuado. Cuando ğ‘‡ es del mismo orden que ğ‘, se necesita un anÃ¡lisis que haga
suposiciones explÃ­citas sobre la dependencia temporal. Si ğ‘‡ es mucho mayor que ğ‘, el enfoque se
convierte en un anÃ¡lisis de series temporales mÃºltiples, manteniendo ğ‘ fijo mientras ğ‘‡ tiende a infinito.
En resumen, para estimar consistentemente los coeficientes en datos de panel, es crucial tener variaciÃ³n
en las variables explicativas a lo largo del tiempo y manejar adecuadamente la estructura del panel, ya
sea equilibrado o desequilibrado.
10.2 SUPUESTOS SOBRE LOS EFECTOS NO OBSERVADOS Y LAS VARIABLES
EXPLICATIVAS
Antes de analizar los mÃ©todos de estimaciÃ³n de datos de panel, es Ãºtil discutir la naturaleza de los efectos
no observados y ciertas caracterÃ­sticas de las variables explicativas observadas.
10.2.1 Â¿EFECTOS ALEATORIOS O FIJOS?
El modelo bÃ¡sico de efectos no observados (UEM) puede incluir variables que cambian a lo largo del
tiempo pero no entre unidades, que cambian entre unidades pero no a lo largo del tiempo, y que cambian
tanto a lo largo del tiempo como entre unidades. El efecto no observado ğ‘ğ‘– puede ser llamado
componente no observado, variable latente o heterogeneidad no observada. Si ğ‘– representa individuos,
ğ‘ğ‘– se denomina efecto o heterogeneidad individual; tÃ©rminos similares se aplican a familias, empresas,
ciudades y otras unidades. Los ğ‘¢ğ‘–ğ‘¡ son los errores idiosincrÃ¡ticos que varÃ­an tanto a lo largo del tiempo
como entre unidades.
En trabajos metodolÃ³gicos y aplicaciones, se discute si ğ‘ğ‘– debe tratarse como un efecto aleatorio o fijo.
Originalmente, esto se basaba en si ğ‘ğ‘– es una variable aleatoria o un parÃ¡metro a estimar. En los modelos
tradicionales de datos de panel, ğ‘ğ‘– es un "efecto aleatorio" si es una variable aleatoria y un "efecto fijo"
si es un parÃ¡metro para cada observaciÃ³n ğ‘–. Sin embargo, para aplicaciones de datos de panel
microeconÃ³micos, es mÃ¡s adecuado tratar ğ‘ğ‘– como selecciones aleatorias de la poblaciÃ³n, junto con ğ‘£ğ‘–ğ‘¡
y ğ‘¥ğ‘–ğ‘¡ . El punto clave es si ğ‘ğ‘– estÃ¡ correlacionado con las variables explicativas observadas ğ‘¥ğ‘–ğ‘¡ .
Mundlak (1978) argumentÃ³ que "efecto aleatorio" es sinÃ³nimo de correlaciÃ³n cero entre las variables
explicativas observadas y el efecto no observado (ğ¶ğ‘œğ‘£(ğ‘¥ğ‘–ğ‘¡ , ğ‘ğ‘– ) = 0, ğ‘¡ = 1,2, â€¦ , ğ‘‡. En trabajos aplicados,
cuando se refiere a ğ‘ğ‘– como un "efecto aleatorio individual", se asume que no estÃ¡ correlacionado con
ğ‘¥ğ‘–ğ‘¡ .
En aplicaciones microeconÃ³micas, el tÃ©rmino "efecto fijo" no implica necesariamente que ğ‘ğ‘– sea tratado
como no aleatorio; mÃ¡s bien, indica que se permite una correlaciÃ³n arbitraria entre el efecto no
observado ğ‘ğ‘– y las variables explicativas observadas ğ‘¥ğ‘–ğ‘¡ . Por lo tanto, si ğ‘ğ‘– se denomina "efecto fijo
individual" o "efecto fijo de la empresa", en tÃ©rminos prÃ¡cticos significa que se permite que ğ‘ğ‘– estÃ©
correlacionado con ğ‘¥ğ‘–ğ‘¡ .
En resumen, la diferencia entre efectos aleatorios y fijos radica en la correlaciÃ³n entre ğ‘ğ‘– y ğ‘¥ğ‘–ğ‘¡ . Los
efectos aleatorios asumen que no hay correlaciÃ³n, mientras que los efectos fijos permiten esta
correlaciÃ³n, proporcionando una estimaciÃ³n mÃ¡s robusta cuando la correlaciÃ³n es probable.
10.2.2 SUPUESTOS
EXPLICATIVAS

DE

EXOGENEIDAD

ESTRICTA

SOBRE

LAS

VARIABLES

En los modelos tradicionales de datos de panel, se asume que las variables explicativas (\(x_{it}\)) son
fijas y no aleatorias para evitar la correlaciÃ³n con los errores. Este supuesto ayuda a evitar el feedback
entre ğ‘¦ğ‘–ğ‘¡ y ğ‘¥ğ‘–ğ‘¡ para ğ‘  > ğ‘¡.
Para realizar inferencias y asegurar la eficiencia de las estimaciones, se necesita expresar el supuesto de
exogeneidad estricta en tÃ©rminos de expectativas condicionales. Este supuesto indica que, dado el
conjunto completo de variables explicativas y el efecto no observado (\(c_i\)), las expectativas de la
variable dependiente \(y_{it}\) se expresan como:
ğ¸(ğ‘¦ğ‘–ğ‘¡ |ğ‘¥ğ‘–1 , ğ‘¥ğ‘–2 , â€¦ , ğ‘¥ğ‘–ğ‘‡ , ğ‘ğ‘– ) = ğ‘¥ğ‘–ğ‘¡ ğ›½ + ğ‘ğ‘–
Esto implica que, una vez controladas las variables explicativas y ğ‘ğ‘– , las variables explicativas no tienen
ningÃºn efecto parcial sobre ğ‘¦ğ‘–ğ‘¡ para ğ‘  â‰  ğ‘¡.
Si se cumple el supuesto de exogeneidad estricta, las variables explicativas (ğ‘¥ğ‘–ğ‘¡ ) son estrictamente
exÃ³genas condicionales al efecto no observado (ğ‘ğ‘– ). Este supuesto es crucial porque asegura que no hay
correlaciÃ³n entre (ğ‘¥ğ‘–ğ‘¡ ) y los errores idiosincrÃ¡ticos (ğ‘¢ğ‘–ğ‘¡ )
Un ejemplo puede ayudar a entender esto: supongamos que ğ‘¦ğ‘–ğ‘¡ es la producciÃ³n de soja en una granja,
y ğ‘¥ğ‘–ğ‘¡ incluye capital, trabajo, materiales y otros insumos observables. El efecto no observado (ğ‘ğ‘– ) podrÃ­a
ser la capacidad de gestiÃ³n de la familia dueÃ±a de la granja. Si los insumos utilizados en otros aÃ±os no
afectan la producciÃ³n actual, el supuesto de exogeneidad estricta es razonable.
El supuesto de exogeneidad estricta implica que: ğ¸(ğ‘¢ğ‘–ğ‘¡ |ğ‘¥ğ‘–1 , ğ‘¥ğ‘–2 , â€¦ , ğ‘¥ğ‘–ğ‘‡ ) = 0
Esto asegura que las variables explicativas no estÃ©n correlacionadas con los errores en ningÃºn perÃ­odo,
lo cual es mÃ¡s fuerte que asumir una correlaciÃ³n contemporÃ¡nea cero: ğ¸(ğ‘¥ğ‘–ğ‘¡ ğ‘¢ğ‘–ğ‘¡ ) = 0, âˆ€ğ‘¡
Este supuesto permite que ğ‘ğ‘– y ğ‘¥ğ‘–ğ‘¡ estÃ©n correlacionados, pero no que ğ‘¥ğ‘–ğ‘¡ y ğ‘¢ğ‘–ğ‘¡ lo estÃ©n. Para la
consistencia de los estimadores de datos de panel, generalmente basta con el supuesto de correlaciÃ³n
cero.
En resumen, el supuesto de exogeneidad estricta es fundamental para asegurar que las estimaciones de
los modelos de datos de panel sean consistentes y eficientes, controlando adecuadamente la correlaciÃ³n
entre las variables explicativas y los errores.
10.2.3 Algunos Ejemplos de Modelos de Datos de Panel con Efectos No Observados
Ejemplo 10.1: EvaluaciÃ³n de Programas: Un modelo estÃ¡ndar para estimar los efectos de la formaciÃ³n
laboral en los salarios posteriores se representa como:
ğ‘™ğ‘œğ‘”(ğ‘¤ğ‘ğ‘”ğ‘’ğ‘–ğ‘¡ ) = ğœƒğ‘¡ + ğ‘§ğ‘–ğ‘¡ ğ›¾ + ğ›¿1 ğ‘ğ‘Ÿğ‘œğ‘”ğ‘–ğ‘¡ + ğ‘ğ‘– + ğ‘¢ğ‘–ğ‘¡
Este modelo se utiliza en estudios microeconÃ³micos para evaluar el impacto de programas sobre salarios
usando datos de panel. AquÃ­, ğ‘¦ğ‘–ğ‘¡ representa un intercepto variable en el tiempo, mientras que ğ‘§ğ‘–ğ‘¡ son
caracterÃ­sticas observables que pueden estar correlacionadas con la participaciÃ³n en el programa. Los
datos suelen recopilarse antes y despuÃ©s del programa, permitiendo evaluar el efecto del mismo. El
efecto individual ğ‘ğ‘– captura habilidades no observadas y aborda el problema de auto-selecciÃ³n. La
exogeneidad estricta de las variables explicativas, como ğ‘ğ‘Ÿğ‘œğ‘”ğ‘–ğ‘¡ , es crucial para evitar la correlaciÃ³n
entre los errores y la participaciÃ³n futura en el programa.
Ejemplo 10.2: Modelo de Retardo Distribuido: Hausman, Hall y Griliches (1984) desarrollaron
modelos no lineales de retardo distribuido para estudiar la relaciÃ³n entre las patentes y los gastos de
I+D. Un modelo lineal es:
ğ‘ğ‘ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘–ğ‘¡ = ğœƒğ‘¡ + ğ‘§ğ‘–ğ‘¡ ğ›¾ + ğ›¿0 ğ‘…ğ·ğ‘–ğ‘¡ + ğ›¿1 ğ‘…ğ·ğ‘–,ğ‘¡âˆ’1 + â‹¯ + ğ›¿5 ğ‘…ğ·ğ‘–,ğ‘¡âˆ’5 + ğ‘ğ‘– + ğ‘¢ğ‘–ğ‘¡
AquÃ­, ğ‘…ğ·ğ‘–ğ‘¡ es el gasto en I+D y ğ‘§ğ‘–ğ‘¡ incluye variables como el tamaÃ±o de la empresa. El tÃ©rmino ğ‘ğ‘–
captura la heterogeneidad de la empresa, que puede correlacionarse con los gastos actuales y futuros en
I+D. Este modelo permite analizar el efecto persistente de I+D en las patentes. Si los gastos en I+D estÃ¡n

correlacionados con ğ‘ğ‘– o si los choques en patentes influyen en el gasto futuro en I+D, la exogeneidad
estricta puede fallar, afectando la validez del modelo.
Ejemplo 10.3: Variable Dependiente con Retardo: Un modelo dinÃ¡mico para la determinaciÃ³n de
salarios con heterogeneidad no observada es:
ğ‘™ğ‘œğ‘”(ğ‘¤ğ‘ğ‘”ğ‘’ğ‘–ğ‘¡ ) = ğ›½1 ğ‘™ğ‘œğ‘”(ğ‘¤ğ‘ğ‘”ğ‘’ğ‘–,ğ‘¡âˆ’1 ) + ğ‘ğ‘– + ğ‘¢ğ‘–ğ‘¡
AquÃ­, el interÃ©s se centra en la persistencia de los salarios, controlando la heterogeneidad no observada
(ğ‘ğ‘– ). Supongamos que ğ‘¦ğ‘–ğ‘¡ es la productividad individual, la cual puede influir en los salarios futuros.
Bajo la suposiciÃ³n de que ğ‘¢ğ‘–ğ‘¡ no estÃ¡ correlacionado con ğ‘¥ğ‘–ğ‘¡ y sus rezagos, este modelo busca capturar
la dinÃ¡mica de los salarios. Sin embargo, si ğ‘¢ğ‘–ğ‘¡ estÃ¡ correlacionado con ğ‘¥ğ‘–,ğ‘¡âˆ’1 o futuras variables
explicativas, la exogeneidad estricta falla, haciendo inaplicable el supuesto para MCO agrupado.
10.3: ESTIMACIÃ“N DE MODELOS DE EFECTOS NO OBSERVADOS MEDIANTE
POOLED OLS
Modelo y Suposiciones: La estimaciÃ³n por Pooled OLS puede proporcionar un estimador consistente
de ğ›½ en el modelo ğ‘¦ğ‘–ğ‘¡ = ğ‘¥ğ‘–ğ‘¡ ğ›½ + ğ‘£ğ‘–ğ‘¡ , donde ğ‘£ğ‘–ğ‘¡ = ğ›¼ğ‘– + ğ‘¢ğ‘–ğ‘¡ . AquÃ­, ğœğ‘–ğ‘¡ es la suma de los efectos no
â€²
observados y un error idiosincrÃ¡tico. La consistencia del estimador Pooled OLS requiere que ğ¸(ğ‘¥ğ‘–ğ‘¡
ğ‘£ğ‘–ğ‘¡
â€²
) = 0, es decir, no debe haber correlaciÃ³n entre ğ‘¥ğ‘–ğ‘¡ y ğœˆğ‘–ğ‘¡ . Esto implica dos condiciones: ğ¸(ğ‘¥ğ‘–ğ‘¡ ğ‘¢ğ‘–ğ‘¡ ) = 0 y
â€²
ğ¸(ğ‘¥ğ‘–ğ‘¡
ğ›¼ğ‘– ) = 0
â€²
SuposiciÃ³n Restrictiva: La condiciÃ³n ğ¸(ğ‘¥ğ‘–ğ‘¡
ğ›¼ğ‘– ) = 0 es mÃ¡s restrictiva y se debe cumplir si se ha
modelado correctamente ğ¸(ğ‘¦ğ‘–ğ‘¡ âˆ£ ğ‘¥ğ‘–ğ‘¡ , ğ›¼ğ‘– ). En modelos estÃ¡ticos y con retardos distribuidos finitos, a
veces se acepta esta suposiciÃ³n, aunque los modelos con variables dependientes rezagadas en ğ‘¥ğ‘–ğ‘¡ tienden
a violarla porque ğ‘¦ğ‘–,ğ‘¡âˆ’1 y ğ‘ğ‘– estÃ¡n correlacionados.
â€²
Errores Compuestos y CorrelaciÃ³n Serial:: Incluso si se cumple ğ¸(ğ‘¥ğ‘–ğ‘¡
ğ›¼ğ‘– ) = 0, los errores
compuestos ğœˆğ‘–ğ‘¡ estarÃ¡n correlacionados serialmente debido a la presencia de ğ‘ğ‘– en cada perÃ­odo. Por lo
tanto, la inferencia usando Pooled OLS requiere el uso de una matriz de varianza robusta y estadÃ­sticas
de prueba robustas. La correlaciÃ³n entre ğœˆğ‘–ğ‘¡ y ğœˆğ‘–ğ‘  no disminuye generalmente a medida que aumenta la
distancia entre ğ‘¡ y ğ‘ , lo que significa que los ğœˆğ‘–ğ‘¡ no son dÃ©bilmente dependientes a lo largo del tiempo.

Importancia de AsintÃ³ticos de Gran N y T Fijo: Es crucial poder aplicar asintÃ³ticos de gran ğ‘ y ğ‘‡
fijo cuando se utiliza Pooled OLS para asegurar inferencias vÃ¡lidas.
OrganizaciÃ³n de los Datos: Cada conjunto (ğ‘¦ğ‘– , ğ‘‹ğ‘– ) debe tener ğ‘‡ filas y ordenarse cronolÃ³gicamente.
El orden de las observaciones de la secciÃ³n transversal es irrelevante, lo importante es mantener el orden
temporal dentro de cada unidad para un anÃ¡lisis adecuado.
ConclusiÃ³n: El uso de Pooled OLS en modelos con efectos no observados requiere supuestos
especÃ­ficos sobre la falta de correlaciÃ³n entre los regresores y los efectos no observados. Aunque estas
suposiciones se cumplan, es esencial tener en cuenta la correlaciÃ³n serial de los errores compuestos y
ajustar las inferencias en consecuencia, enfatizando la importancia de tÃ©cnicas robustas y un enfoque
adecuado para anÃ¡lisis de series temporales y datos de panel.
10.4: MÃ‰TODOS DE EFECTOS ALEATORIOS
10.4.1 EstimaciÃ³n e Inferencia bajo las Suposiciones BÃ¡sicas de Efectos Aleatorios:
Suposiciones BÃ¡sicas: El anÃ¡lisis de efectos aleatorios en datos de panel incluye ğ‘ğ‘– en el tÃ©rmino de
error, y requiere mÃ¡s suposiciones que el mÃ©todo de OLS agrupados. La clave es la exogeneidad estricta
y la ortogonalidad entre ğ‘ğ‘– y ğ‘¥ğ‘–ğ‘¡ . Las suposiciones RE.1 establecen que:
ğ¸(ğ‘¢ğ‘–ğ‘¡ |ğ‘¥ğ‘– , ğ‘ğ‘– ) = 0
ğ¸(ğ‘ğ‘– |ğ‘¥ğ‘– ) = ğ¸(ğ‘ğ‘– )

Modelo y EstimaciÃ³n: La suposiciÃ³n RE.1 es mÃ¡s restrictiva que la necesaria para un anÃ¡lisis OLS
agrupado, pero es esencial para el enfoque de efectos aleatorios. Esta suposiciÃ³n implica que \(c_i\) no
estÃ¡ correlacionado con las variables explicativas. Usamos la matriz de varianza incondicional de los
errores compuestos para ajustar la correlaciÃ³n serial en los errores.
CondiciÃ³n de Rango para GLS: Para la consistencia del mÃ©todo de MÃ­nimos Cuadrados Generalizados
(GLS), se necesita una condiciÃ³n de rango:
â€²

ğ‘Ÿğ‘ğ‘›ğ‘˜ ğ¸(ğ‘‹ğ‘–â€² ğ›ºâˆ’1 ğ‘‹ğ‘– ) = ğ¾
Matriz de Varianza: La matriz de varianza incondicional de los errores compuestos se define como:
ğ›º = ğœğ‘¢2 ğ¼ğ‘‡ + ğœğ‘2 ğ½ğ‘‡
Esto permite que ğ›º dependa de dos parÃ¡metros principales, ğœğ‘¢2 y ğœğ‘2 , que capturan la varianza de los
errores idiosincrÃ¡ticos y la varianza de los efectos no observados, respectivamente.
ImplementaciÃ³n de FGLS: Para implementar el mÃ©todo de GLS factible (FGLS), asumimos que:
ğ¸(ğ‘¢ğ‘–ğ‘¡ ğ‘¢ğ‘–ğ‘  |ğ‘¥ğ‘– , ğ‘ğ‘– ) = ğœğ‘¢2 ğ¼ğ‘‡
ğ¸(ğ‘ğ‘–2 |ğ‘¥ğ‘– ) = ğœğ‘2
Esto nos permite definir una matriz de varianza para los errores compuestos y utilizarla para estimar los
coeficientes mediante FGLS:

EstimaciÃ³n de ParÃ¡metros: Para implementar el enfoque de efectos aleatorios, necesitamos estimar
los parÃ¡metros ğœğ‘¢2 y \ğœğ‘2 . Utilizamos los residuos obtenidos del estimador OLS agrupado para estimar
ğœğ‘¢2 y ğœğ‘2 :

Este procedimiento asegura que las estimaciones sean consistentes bajo las suposiciones RE.1-RE.3.
ConclusiÃ³n: El enfoque de efectos aleatorios requiere suposiciones estrictas sobre la exogeneidad y la
estructura de la varianza para obtener estimaciones vÃ¡lidas. Aunque implica restricciones adicionales en
comparaciÃ³n con OLS agrupado, proporciona estimaciones mÃ¡s eficientes y consistentes al considerar
la correlaciÃ³n serial en los errores compuestos. La implementaciÃ³n cuidadosa de FGLS y la adecuada
consideraciÃ³n de la estructura de los datos de panel son esenciales para lograr resultados fiables.
10.4.2 Estimador Robusto de la Matriz de Varianza
La suposiciÃ³n RE.3, aunque estricta, no causa inconsistencia en el estimador RE. Sin embargo, es Ãºtil
poder realizar inferencias estadÃ­sticas sin depender de esta suposiciÃ³n. La suposiciÃ³n RE.3 puede fallar
por varias razones, como la falta de estructura de efectos aleatorios en la matriz de varianza de los errores
compuestos.
Uso de Errores EstÃ¡ndar Robustos: Para abordar esta posible falla, se utilizan errores estÃ¡ndar
robustos que no dependen de la suposiciÃ³n RE.3. Esto se logra utilizando la matriz de varianza robusta
y calculando estadÃ­sticos de Wald robustos. La fÃ³rmula para los estadÃ­sticos de Wald robustos es:
ğ‘Š = (ğ‘…ğ‘ âˆ’ ğ‘Ÿ)â€² (ğ‘…â€² ğ‘‰ğ‘…â€² )âˆ’1 (ğ‘…ğ‘ âˆ’ ğ‘Ÿ)
donde ğ‘‰Ì‚ es el estimador de la matriz de varianza robusta. Si la suposiciÃ³n RE.3 estÃ¡ violada, esta forma
robusta asegura que los resultados de los estadÃ­sticos F y otros anÃ¡lisis sean vÃ¡lidos.
Beneficios de la Matriz de Varianza Robusta: La idea detrÃ¡s del uso de una matriz de varianza robusta
es aprovechar una tÃ©cnica bien establecida bajo las suposiciones RE.1-RE.3. Al hacer el anÃ¡lisis robusto,

se mejora la confiabilidad de las inferencias estadÃ­sticas, incluso si \(T\) es fijo y \(N\) es grande. Esto
asegura que las inferencias sean vÃ¡lidas y que los errores estÃ¡ndar y estadÃ­sticos robustos se mantengan
consistentes.
ImplementaciÃ³n PrÃ¡ctica: En la prÃ¡ctica, el uso de la matriz de varianza robusta facilita obtener errores
estÃ¡ndar robustos y estadÃ­sticos como \(t\) y \(F\). Esto es particularmente Ãºtil en aplicaciones donde la
suposiciÃ³n RE.3 puede no ser completamente vÃ¡lida. En la SecciÃ³n 10.7.2, se describe cÃ³mo obtener el
estimador RE a partir de una regresiÃ³n OLS agrupada, que proporciona una manera prÃ¡ctica de aplicar
estos mÃ©todos robustos.
ConclusiÃ³n: El uso de estimadores robustos de la matriz de varianza es esencial para asegurar
inferencias estadÃ­sticamente vÃ¡lidas en modelos de efectos aleatorios. Aunque la suposiciÃ³n RE.3 puede
ser restrictiva, los errores estÃ¡ndar robustos y los estadÃ­sticos de Wald permiten realizar anÃ¡lisis
confiables sin depender completamente de esta suposiciÃ³n. Esta prÃ¡ctica es crucial para mejorar la
precisiÃ³n y confiabilidad de los resultados en el anÃ¡lisis de datos de panel.
10.4.3 Un AnÃ¡lisis General de MÃ­nimos Cuadrados Generalizados Factibles (FGLS)
IntroducciÃ³n: El anÃ¡lisis de MÃ­nimos Cuadrados Generalizados Factibles (FGLS) es Ãºtil cuando los
errores idiosincrÃ¡ticos ğ‘¢ğ‘–ğ‘¡ son heterocedÃ¡sticos y estÃ¡n correlacionados en serie. En estas situaciones,
se puede utilizar un estimador mÃ¡s general de la matriz de varianza Î© en FGLS:
ğ‘

ğ›º = ğ‘ âˆ’1 âˆ‘ ğ‘£Ì‚ğ‘– ğ‘£Ì‚ğ‘– â€²
ğ‘–=1
donde ğ‘£Ì‚ğ‘– son los residuos OLS agrupados. Este estimador es consistente bajo las suposiciones RE.1 y
RE.2 y es asintÃ³ticamente eficiente, tomando la forma usual de la matriz de varianza.
ComparaciÃ³n con RE: Usar la ecuaciÃ³n (10.38) proporciona una estimaciÃ³n de Î© que es mÃ¡s general
que el anÃ¡lisis de efectos aleatorios tradicional (RE). Para muestras grandes, el estimador FGLS es tan
eficiente como el RE bajo RE.1-RE.3 y mÃ¡s eficiente si Î© no tiene la estructura de efectos aleatorios.
HistÃ³ricamente, se prefieren los mÃ©todos RE sobre FGLS general debido a que los errores compuestos
ğ‘£ğ‘–ğ‘¡ estaban asociados con efectos no observados.
Ventajas de FGLS: Si ğ‘ es mucho mayor que ğ‘‡, un anÃ¡lisis FGLS no restringido puede tener mejores
propiedades porque la estimaciÃ³n Î© tiene ğ‘‡(ğ‘‡ + 1)/2 elementos, proporcionando mayor flexibilidad.
Los efectos aleatorios solo necesitan dos parÃ¡metros de varianza para cualquier ğ‘‡. Con un ğ‘ muy
grande, la estimaciÃ³n general de Î© es una alternativa atractiva, especialmente si la estimaciÃ³n muestra
un patrÃ³n diferente al de los efectos aleatorios.
ImplementaciÃ³n y Aplicaciones: Como punto intermedio entre un anÃ¡lisis de efectos aleatorios
tradicional y un anÃ¡lisis FGLS completo, podrÃ­amos especificar una estructura particular para la matriz
de varianza del error idiosincrÃ¡tico ğ¸(ğ‘¢ğ‘¢â€² ). Esto permite capturar adecuadamente la heterocedasticidad
y la correlaciÃ³n serial en los errores, mejorando la eficiencia de las estimaciones y proporcionando
inferencias mÃ¡s robustas.
ConclusiÃ³n: El anÃ¡lisis FGLS proporciona una herramienta poderosa para manejar heterocedasticidad
y correlaciÃ³n serial en modelos de datos de panel. Aunque el mÃ©todo de efectos aleatorios es
tradicionalmente preferido, FGLS ofrece una mayor flexibilidad y eficiencia en muestras grandes. Esta
metodologÃ­a es especialmente Ãºtil cuando la estructura de varianza de los errores no sigue el patrÃ³n de
efectos aleatorios, permitiendo obtener estimaciones mÃ¡s precisas y confiables.
10.4.4 Prueba para la Presencia de un Efecto No Observado
IntroducciÃ³n: Para determinar si un modelo de efectos aleatorios es apropiado, debemos probar la
presencia de efectos no observados ğœğ‘2 . Si las suposiciones RE.1 a RE.3 se cumplen, pero el modelo no
contiene un efecto no observado, el estimador OLS agrupado es eficiente y sus estadÃ­sticas son
asintÃ³ticamente vÃ¡lidas. La ausencia de un efecto no observado equivale a la hipÃ³tesis nula ğ»0 : ğœğ‘2 = 0.

Prueba de CorrelaciÃ³n Serial: Para probar ğ»0 : ğœğ‘2 = 0, podemos usar la prueba de correlaciÃ³n serial
AR (1). Esta prueba es vÃ¡lida porque los errores ğ‘£ğ‘–ğ‘¡ no estÃ¡n correlacionados bajo ğ»0 y asumimos que
ğ‘¥ğ‘–ğ‘¡ es estrictamente exÃ³geno.
Estimador de ğˆğŸğ’„ : Una mejor prueba se basa en el estimador de ğœğ‘2 en la ecuaciÃ³n (10.37):

Desde esta ecuaciÃ³n, basamos una prueba de ğ»0 : ğœğ‘2 = 0 en la distribuciÃ³n asintÃ³tica nula del estimador
de ğœğ‘2 , escalado por âˆšğ‘.
EstadÃ­stico de Prueba: El estadÃ­stico de prueba se construye como:

InterpretaciÃ³n del EstadÃ­stico: Bajo la hipÃ³tesis nula de que \(v_{it}\) no estÃ¡n correlacionados en
serie, este estadÃ­stico tiene una distribuciÃ³n normal estÃ¡ndar asintÃ³tica. A diferencia del estadÃ­stico de
Breusch-Pagan, podemos rechazar \(H_0\) por estimaciones negativas de \(\sigma_c^2\), aunque son
raras. El estadÃ­stico puede detectar varios tipos de correlaciÃ³n en serie en \(v_{it}\), por lo que el rechazo
de la nula no implica necesariamente que la estructura de error de efectos aleatorios sea verdadera.
ConclusiÃ³n: La prueba para la presencia de un efecto no observado es crucial para determinar si un
modelo de efectos aleatorios es adecuado. Usar pruebas de correlaciÃ³n serial y basar los estadÃ­sticos en
estimadores robustos permite realizar inferencias confiables sobre la existencia de efectos no
observados. Este enfoque asegura que las conclusiones derivadas del modelo sean vÃ¡lidas y robustas.
10.5 MÃ‰TODOS DE EFECTOS FIJOS
10.5.1 Consistencia del estimador de efectos fijos (FE)
En el anÃ¡lisis de datos de panel, el objetivo de utilizar modelos de efectos fijos es permitir que ğ‘ğ‘– se
correlacione arbitrariamente con ğ‘¥ğ‘–ğ‘¡ . Un anÃ¡lisis de efectos fijos logra este propÃ³sito explÃ­citamente,
asegurando que los coeficientes estimados no estÃ©n sesgados por variables omitidas constantes en el
tiempo. El modelo se presenta como:
ğ‘¦ğ‘–ğ‘¡ = ğ‘¥ğ‘–ğ‘¡ ğ›½ + ğ‘ğ‘– + ğ‘¢ğ‘–ğ‘¡ ,

ğ‘¡ = 1, â€¦ , ğ‘‡

SuposiciÃ³n de Exogeneidad: La suposiciÃ³n clave para los modelos de efectos fijos (EF) es la
exogeneidad estricta de las variables explicativas condicionales a ğ‘ğ‘– :
ğ¸(ğ‘¢ğ‘–ğ‘¡ |ğ‘¥ğ‘– , ğ‘ğ‘– ) = 0,

ğ‘¡ = 1,2, â€¦ , ğ‘‡

Esto permite que ğ¸(ğ‘ğ‘– |ğ‘¥ğ‘– ) sea cualquier funciÃ³n de ğ‘¥ğ‘– . Al relajar esta suposiciÃ³n, podemos estimar de
manera consistente los efectos parciales de las variables omitidas constantes en el tiempo.
TransformaciÃ³n de Ecuaciones: Para eliminar ğ‘ğ‘– , transformamos las ecuaciones restando la media de
cada unidad en el tiempo: ğ‘¦Ìƒğ‘–ğ‘¡ = ğ‘¥Ìƒğ‘–ğ‘¡ ğ›½ + ğ‘¢Ìƒğ‘–ğ‘¡ , ğ‘¡ = 1,2, â€¦ , ğ‘‡
Donde ğ‘¦Ìƒğ‘–ğ‘¡ = ğ‘¦ğ‘–ğ‘¡ âˆ’ ğ‘¦Ì…ğ‘– , ğ‘¥Ìƒğ‘–ğ‘¡ = ğ‘¥ğ‘–ğ‘¡ âˆ’ ğ‘¥Ì…ğ‘– , y ğ‘¢ğ‘–ğ‘¡ = ğ‘¢ğ‘–ğ‘¡ âˆ’ ğ‘¢Ì…ğ‘– . Esta transformaciÃ³n elimina ğ‘ğ‘– , permitiendo
que la estimaciÃ³n de ğ›½ no estÃ© sesgada por factores no observados constantes en el tiempo.
EstimaciÃ³n de Efectos Fijos: El estimador de efectos fijos (FE), denotado por ğ›½ğ¹ğ¸ , se obtiene aplicando
MCO agrupado a la ecuaciÃ³n transformada:
ğ‘¦Ìƒğ‘–ğ‘¡ = ğ‘¥Ìƒğ‘–ğ‘¡ ğ›½ + ğ‘¢Ìƒğ‘–ğ‘¡ ,

ğ‘¡ = 1,2, â€¦ , ğ‘‡

La consistencia del estimador FE depende de que ğ‘¥ğ‘–ğ‘¡ varÃ­e en el tiempo. Si ğ‘¥ğ‘–ğ‘¡ contiene una variable
que no varÃ­a en el tiempo, la transformaciÃ³n resultarÃ¡ en ceros, lo que implica que esa variable no puede
ser estimada.

EspecificaciÃ³n General: El modelo general incluye variables constantes en el tiempo (ğ‘§ğ‘– ) y variables
que varÃ­an en el tiempo (ğ‘¤ğ‘–ğ‘¡ ):

Donde ğ‘‘ son variables dummy para cada perÃ­odo. Esta especificaciÃ³n permite evaluar el efecto de
variables que varÃ­an en el tiempo y controlar por las constantes en el tiempo.
ConclusiÃ³n: El modelo de efectos fijos es robusto frente a la correlaciÃ³n entre ğ‘ğ‘– y ğ‘¥ğ‘–ğ‘¡ , permitiendo
estimar los efectos parciales de variables omitidas constantes en el tiempo. La transformaciÃ³n de las
ecuaciones elimina ğ‘ğ‘– , asegurando estimaciones consistentes de ğ›½. Este enfoque es crucial en anÃ¡lisis
donde las variables no observadas pueden influir en los resultados, proporcionando un marco robusto
para inferencia en datos de panel.
10.5.2 Inferencia asintÃ³tica con efectos fijos
Para asegurar que el estimador de efectos fijos (EF) sea eficiente, se necesitan suposiciones adicionales
mÃ¡s allÃ¡ del supuesto EF.1. El siguiente supuesto, FE.3, garantiza la eficiencia del estimador de EF.
Supuesto FE.3: El supuesto FE.3 establece que:

Esto implica que la matriz de varianza incondicional del error compuesto ğ‘£ğ‘– = ğ‘ğ‘– ğ½ğ‘‡ + ğ‘¢ğ‘– tiene la forma
de efectos aleatorios.
Condiciones para la Eficiencia: Para que los MCO agrupados sean relativamente eficientes,
requerimos que ğ‘¢ğ‘–ğ‘¡ sea homocedÃ¡stico en ğ‘¡ y no correlacionado serialmente:

El primer requisito se cumple, pero el segundo no, ya que los errores estÃ¡n correlacionados
negativamente. Sin embargo, esto no causa mayores complicaciones.
Varianza AsintÃ³tica del Estimador FE: La varianza asintÃ³tica de ğ›½ğ¹ğ¸ se halla como:

EstimaciÃ³n de ğˆğŸğ’– : Para estimar ğœğ‘¢2 , definimos los residuos de los efectos fijos:
Luego, la estimaciÃ³n de ğœğ‘¢2 es:

Bajo los supuestos FE.1 a FE.3, ğœÌ‚ğ‘¢2 es un estimador imparcial de ğœğ‘¢2 condicional a ğ‘‹ (y, por lo tanto,
tambiÃ©n incondicional).
ConclusiÃ³n: Para asegurar la eficiencia del estimador de efectos fijos (FE), es necesario considerar
suposiciones adicionales como FE.3. Aunque los errores estÃ©n correlacionados negativamente, esto no
impide la estimaciÃ³n correcta de ğœğ‘¢2 . Las herramientas economÃ©tricas modernas facilitan la
implementaciÃ³n de estos estimadores, proporcionando resultados confiables y eficientes en el anÃ¡lisis
de datos de panel.
10.5.3 La regresiÃ³n de variable dummy
Los enfoques tradicionales para la estimaciÃ³n de efectos fijos consideran los ğ‘ğ‘– como parÃ¡metros que
deben estimarse junto con ğ›½. Una posibilidad es definir ğ‘ variables ficticias (dummies), una para cada
observaciÃ³n de la secciÃ³n transversal.

ImplementaciÃ³n de Variables Dummy: Para realizar esto, corremos la regresiÃ³n OLS agrupada:

AquÃ­, cada ğ‘‘1ğ‘– estima ğ‘ğ‘– . Se puede demostrar que el estimador de ğ›½ obtenido de esta regresiÃ³n es, de
hecho, el estimador de efectos fijos. Por esta razÃ³n, a veces se hace referencia a ğ›½ğ¹ğ¸ como el estimador
de variable ficticia.
Diferencia entre ğ’„Ì‚ğ’Š y ğœ·ğ‘­ğ‘¬ : Hay una diferencia importante entre ğ‘Ì‚ğ‘– y ğ›½ğ¹ğ¸ . Sabemos que ğ›½ğ¹ğ¸ es
consistente con ğ‘‡ fijo como ğ‘ â†’ âˆ. Esto no es el caso con ğ‘Ì‚ğ‘– . Cada vez que se agrega una nueva
observaciÃ³n de secciÃ³n transversal, se agrega otro ğ‘ğ‘– y la informaciÃ³n no se acumula en el ğ‘ğ‘– .
El software economÃ©trico que emplea efectos fijos generalmente suprime las "estimaciones" de los ğ‘ğ‘– .
EstimaciÃ³n de ğ’„ğ’Š : Se puede demostrar que cada ğ‘Ì‚ğ‘– se estima como:

ConclusiÃ³n: La regresiÃ³n de variables dummy es una tÃ©cnica efectiva para estimar efectos fijos en datos
de panel. Aunque el enfoque de variables dummy puede ser intuitivo y fÃ¡cil de implementar, la diferencia
clave entre ğ‘Ì‚ğ‘– y ğ›½ğ¹ğ¸ radica en su consistencia y acumulaciÃ³n de informaciÃ³n. Este mÃ©todo asegura que
los efectos fijos sean capturados adecuadamente, proporcionando estimaciones robustas y precisas en el
anÃ¡lisis de datos de panel.
10.5.4 CorrelaciÃ³n serial y estimador de matriz de varianza robusta
Aunque la heterocedasticidad en ğ‘¢ğ‘–ğ‘¡ es un problema potencial, la correlaciÃ³n serial puede ser mÃ¡s
importante en ciertas aplicaciones. Probar los errores idiosincrÃ¡ticos (ğ‘¢Ìƒğ‘–ğ‘¡ ) para la correlaciÃ³n serial es
complicado porque no podemos estimar ğ‘¢ğ‘–ğ‘¡ directamente debido a la desvalorizaciÃ³n temporal utilizada
en los efectos fijos (EF). Solo podemos estimar los errores desvalorizados en el tiempo (ğ‘¢Ìƒğ‘–ğ‘¡ ).
DeterminaciÃ³n de la CorrelaciÃ³n Serial: Cuando ğ‘‡ â‰¥ 3, podemos utilizar la ecuaciÃ³n (10.52) para
determinar si existe correlaciÃ³n serial en los errores. Ignorar el error de estimaciÃ³n en ğ›½ permite obtener
la distribuciÃ³n asintÃ³tica de cualquier estadÃ­stica de prueba basada en covarianzas y varianzas de
muestra.
MÃ©todos para Probar la CorrelaciÃ³n Serial: La prueba se complica porque los ğ‘¢Ìƒğ‘–ğ‘¡ estÃ¡n
correlacionados serialmente bajo la hipÃ³tesis nula. Dos mÃ©todos pueden ser utilizados:
1. Usar dos perÃ­odos de tiempo cualesquiera (por ejemplo, los dos Ãºltimos) para probar la ecuaciÃ³n
(10.52) usando una regresiÃ³n simple.
2. Ejecutar la regresiÃ³n OLS agrupada y usar el error estÃ¡ndar totalmente robusto para OLS
agrupado.
Si se encuentra correlaciÃ³n serial, es esencial ajustar el estimador de la matriz de varianza asintÃ³tica y
las estadÃ­sticas de prueba.
Estimador de Matriz de Varianza Robusta: El estimador de matriz de varianza robusta de ğ›½Ì‚ğ¹ğ¸ es:

Este estimador es vÃ¡lido en presencia de cualquier heterocedasticidad o correlaciÃ³n serial en \(u_{it}\).
ConclusiÃ³n: En el anÃ¡lisis de datos de panel, la correlaciÃ³n serial y la heterocedasticidad son problemas
importantes que deben ser abordados para obtener inferencias vÃ¡lidas. Utilizar un estimador de matriz
de varianza robusta permite ajustar estos problemas, proporcionando estimaciones consistentes y
eficientes. Este enfoque es crucial para asegurar la precisiÃ³n y confiabilidad de los resultados en modelos
de efectos fijos.
10.5.5 GLS de efectos fijos

En lugar de calcular una matriz de varianza robusta para el estimador de efectos fijos (EF), podemos
relajar el supuesto EF3 para permitir una matriz de covarianza condicional sin restricciones, aunque
constante.
Supuesto FGLS.3: El supuesto FGLS.3 establece que:

Bajo este supuesto, se tiene:

La cual tiene rango |Î›|. El rango deficiente en la expresiÃ³n anterior causa problemas para el enfoque
habitual de GLS porque la matriz de varianza no se puede invertir. Una forma de proceder es utilizar
una inversa generalizada.
ImplementaciÃ³n PrÃ¡ctica: Para ser mÃ¡s concretos, supongamos que eliminamos el perÃ­odo de tiempo
ğ‘‡, dejando las ecuaciones:

Estimador GLS de Efectos Fijos: El estimador GLS de efectos fijos (FEGLS) se obtiene como:

Bajo los supuestos FE.1 y FEGLS.2, el estimador FEGLS es consistente:

Cuando aÃ±adimos el supuesto FGLS.3, la varianza asintÃ³tica es fÃ¡cil de estimar:

Aplicaciones y Eficiencia: La suma de las estadÃ­sticas de residuos cuadrados de FGLS se puede utilizar
para probar mÃºltiples restricciones. El estimador FEGLS fue propuesto por Kiefer (1980) cuando los ğ‘ğ‘–
se tratan como parÃ¡metros. El estimador FEGLS no es asintÃ³ticamente menos eficiente que el estimador
FE bajo el supuesto FGLS.3.
En lugar de permitir que Î© sea una matriz sin restricciones, podemos imponer restricciones a Î› que
impliquen que Î© tiene una forma restringida.
ConclusiÃ³n: El uso de GLS de efectos fijos proporciona una alternativa eficiente al estimador de efectos
fijos tradicional, especialmente cuando se relajan ciertas suposiciones. Al permitir una matriz de
covarianza condicional sin restricciones, se puede mejorar la eficiencia de las estimaciones. Este
enfoque es Ãºtil para manejar problemas de heterocedasticidad y correlaciÃ³n serial en datos de panel,
asegurando resultados robustos y precisos.
10.5.6 Uso de la estimaciÃ³n de efectos fijos para el anÃ¡lisis de polÃ­ticas
La estimaciÃ³n de efectos fijos es especialmente Ãºtil para el anÃ¡lisis de polÃ­ticas y la evaluaciÃ³n de
programas. Para ilustrar esto, consideremos el siguiente modelo:

AquÃ­, ğœğ‘–ğ‘¡ puede o no contener un efecto no observado. ğ‘¤ğ‘–ğ‘¡ es la variable de polÃ­tica de interÃ©s, que podrÃ­a

ser continua o discreta. El vector ğ‘§ğ‘–ğ‘¡ incluye otros controles que podrÃ­an estar correlacionados con ğ‘¤ğ‘–ğ‘¡ ,
incluidas variables ficticias de perÃ­odo de tiempo.
Consistencia de los Efectos Fijos: Para que los efectos fijos sean consistentes, se requiere que ğ‘¤ğ‘–ğ‘¡ no
estÃ© correlacionado con las desviaciones de ğœğ‘–ğ‘¡ respecto del promedio a lo largo del perÃ­odo de tiempo.
Esto significa que una variable de polÃ­tica, como la participaciÃ³n en un programa, no debe relacionarse
sistemÃ¡ticamente con el componente persistente en el error ğœğ‘–ğ‘¡ medido por ğœÌ…ğ‘– .
Ventajas de los Efectos Fijos: Los efectos fijos son a menudo preferibles a los modelos de MCO
agrupados o efectos aleatorios para aplicaciones de polÃ­ticas. Esto se debe a que los efectos fijos
permiten controlar por factores no observados que son constantes en el tiempo, eliminando asÃ­ el sesgo
que podrÃ­a surgir de variables omitidas que afectan tanto a la polÃ­tica de interÃ©s como al resultado.
ConclusiÃ³n: La estimaciÃ³n de efectos fijos es una herramienta poderosa en el anÃ¡lisis de polÃ­ticas, ya
que permite controlar por factores no observados constantes en el tiempo y proporcionar estimaciones
consistentes y no sesgadas de los efectos de las polÃ­ticas. Esto es crucial para evaluar adecuadamente la
efectividad de programas y polÃ­ticas en diversas aplicaciones.
10.6 MÃ‰TODOS DE PRIMERA DIFERENCIACIÃ“N
10.6.1 Inferencia
En la secciÃ³n 10.1 se usÃ³ la diferenciaciÃ³n para eliminar el efecto inobservado ğ‘ğ‘– con ğ‘‡ = 2. Ahora
aplicamos esta tÃ©cnica al modelo general (10.41).
SuposiciÃ³n FD.1: La suposiciÃ³n FD.1 es la misma que la suposiciÃ³n FE.1, que asegura exogeneidad
estricta de las variables explicativas.
TransformaciÃ³n de Primera Diferencia: Para eliminar ğ‘ğ‘– , tomamos el rezago de la ecuaciÃ³n (10.41):
u
un perÃ­odo y restamos:

Esta transformaciÃ³n de primera diferencia elimina ğ‘ğ‘– . Perdemos el primer perÃ­odo para cada secciÃ³n
cruzada, dejando ğ‘‡ âˆ’ 1 perÃ­odos por cada ğ‘–.
Modelo Transformado: La ecuaciÃ³n (10.63) aclara que los elementos de ğ‘¥ğ‘–ğ‘¡ deben variar con el
tiempo; de lo contrario, âˆ†ğ‘¥ğ‘–ğ‘¡ tendrÃ¡ elementos que sean idÃ©nticamente cero para todo ğ‘¡ e ğ‘–. AdemÃ¡s, se
elimina el intercepto original, y los cambios en las variables dummy de tiempo âˆ†ğ‘¥ğ‘–ğ‘¡ incluyen dichas
variables:

EstimaciÃ³n: Los parÃ¡metros ğœƒ1 y ğ›¾1 no estÃ¡n identificados porque desaparecen en la ecuaciÃ³n
transformada. El estimador de primera diferencia (FD), ğ›½Ì‚ğ¹ğ· , es el estimador OLS agrupado de la
regresiÃ³n:

Bajo la suposiciÃ³n FD.1, la estimaciÃ³n OLS agrupada de las ecuaciones en primera diferencia serÃ¡
consistente porque:

CondiciÃ³n de Rango: La condiciÃ³n de rango para el estimador FD es:

SuposiciÃ³n FD.3: La suposiciÃ³n FD.3 es clave para la eficiencia del estimador de efectos fijos (FE),
asumiendo homocedasticidad y ausencia de correlaciÃ³n serial en ğ‘¢ğ‘–ğ‘¡ . Esto asegura que los errores
idiosincrÃ¡ticos sean serialmente no correlacionados:

Varianza AsintÃ³tica: Bajo FD.1-FD.3, la varianza asintÃ³tica de ğ›½Ì‚ğ¹ğ· es:

ConclusiÃ³n: El estimador de primera diferencia (FD) es preferido sobre el estimador de efectos fijos
(FE) porque es mÃ¡s fÃ¡cil de implementar sin software especializado. Bajo las suposiciones FD.1-FD.3,
el estimador FD es mÃ¡s eficiente y proporciona inferencias vÃ¡lidas al ajustar por variabilidad temporal
y eliminar efectos inobservados constantes en el tiempo. Las ecuaciones indican que los errores estÃ¡ndar
de la regresiÃ³n en primera diferencia son asintÃ³ticamente vÃ¡lidos, asegurando la precisiÃ³n y
confiabilidad en el anÃ¡lisis de datos de panel.
10.6.2 Matriz de Varianza Robusta
Si la suposiciÃ³n FD.3 es violada, entonces, como es habitual, podemos calcular una matriz de varianza
robusta. El estimador en la ecuaciÃ³n (7.26) aplicado en este contexto es:

Donde âˆ†ğ‘‹ denota la matriz ğ‘(ğ‘‡ âˆ’ 1) Ã— ğ¾ de primeras diferencias apiladas de ğ‘¥ğ‘–ğ‘¡ .
Ejemplo 10.6: EstimaciÃ³n FD de los Efectos de las Subvenciones para la CapacitaciÃ³n Laboral:
Ahora estimamos el efecto de las subvenciones para la capacitaciÃ³n laboral en \(\log(\text{scrap})\)
utilizando la diferenciaciÃ³n de primera. EspecÃ­ficamente, usamos OLS agrupado en primeras
diferencias:

En lugar de diferenciar las variables dummy de los aÃ±os y omitir el intercepto, simplemente incluimos
un intercepto y una variable dummy para 1989 para capturar los efectos de tiempo agregados. Si
estuviÃ©ramos especÃ­ficamente interesados en los efectos de los aÃ±os del modelo estructural (en niveles),
entonces deberÃ­amos diferenciar esas tambiÃ©n.
Resultados de la EstimaciÃ³n: La ecuaciÃ³n estimada es:

Donde los errores estÃ¡ndar habituales estÃ¡n entre parÃ©ntesis y los errores estÃ¡ndar robustos estÃ¡n entre
corchetes. Reportamos el ğ‘…2 aquÃ­ porque tiene una interpretaciÃ³n Ãºtil: mide la cantidad de variaciÃ³n en
el crecimiento de la tasa de scrap que es explicada por âˆ†ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¡ğ‘–,ğ‘¡âˆ’1 (y d89). Las estimaciones de ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¡
y ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¡ğ‘–,ğ‘¡âˆ’1 son bastante similares a las estimaciones de efectos fijos, aunque ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¡ es ahora
estadÃ­sticamente mÃ¡s significativo que ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¡ğ‘–,ğ‘¡âˆ’1 . La prueba F habitual para la significancia conjunta
de âˆ†ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¡ğ‘–,ğ‘¡âˆ’1 es 1.53 con un valor p = 0.222.
ConclusiÃ³n: El uso de una matriz de varianza robusta es esencial cuando la suposiciÃ³n de no correlaciÃ³n
serial es violada. En el ejemplo dado, se demuestra cÃ³mo aplicar OLS agrupado en primeras diferencias
y ajustar las inferencias utilizando una matriz de varianza robusta. Esto asegura que las estimaciones
sean precisas y confiables, incluso en presencia de heterocedasticidad y correlaciÃ³n serial.
10.6.3 Testeo para CorrelaciÃ³n Serial
Bajo la suposiciÃ³n FD.3, los errores ğ‘’ğ‘–ğ‘¡ deben ser serialmente no correlacionados. Podemos probar esta
suposiciÃ³n fÃ¡cilmente dado los residuos OLS agrupados de la regresiÃ³n (10.65). Dado que la suposiciÃ³n
de exogeneidad estricta se mantiene, podemos aplicar la forma simple de la prueba en la SecciÃ³n 7.8.
La regresiÃ³n se basa en ğ‘‡ âˆ’ 2 perÃ­odos de tiempo:

Procedimiento de Prueba: El estadÃ­stico de prueba es el estadÃ­stico t usual sobre ğœŒÌ‚. Con ğ‘‡ = 2, esta
prueba no estÃ¡ disponible ni es necesaria. Con ğ‘‡ = 3, la regresiÃ³n (10.71) es simplemente una regresiÃ³n
de secciÃ³n transversal porque perdemos los perÃ­odos de tiempo ğ‘¡ = 1 y 2.
AutocorrelaciÃ³n: Si los errores idiosincrÃ¡ticos {ğ‘¢ğ‘–ğ‘¡ : ğ‘¡ = 1, 2, â€¦ , ğ‘‡} no estÃ¡n correlacionados desde el
principio, {ğ‘’ğ‘–ğ‘¡ : ğ‘¡ = 2, 3, â€¦ , ğ‘‡} estarÃ¡n autocorrelacionados. De hecho, bajo la suposiciÃ³n FE.3, se
muestra fÃ¡cilmente que ğ¶ğ‘œğ‘Ÿğ‘Ÿ(ğ‘’ğ‘–ğ‘¡ , ğ‘’ğ‘–,ğ‘¡âˆ’1 ) = âˆ’0.5. En cualquier caso, encontrar una correlaciÃ³n serial
significativa en los ğ‘’ğ‘–ğ‘¡ justifica calcular la matriz de varianza robusta para el estimador FD.
Ejemplo 10.6 (ContinuaciÃ³n): EstimaciÃ³n de CorrelaciÃ³n Serial AR(1):
Probamos la correlaciÃ³n serial AR (1) en la ecuaciÃ³n de primeras diferencias al hacer regresiÃ³n de ğ‘’ğ‘–ğ‘¡
sobre ğ‘’ğ‘–,ğ‘¡âˆ’1 usando el aÃ±o 1989. Obtenemos ğœŒÌ‚ = 0.237 con un estadÃ­stico ğ‘¡ de 1.76. Hay evidencia
marginal de correlaciÃ³n serial positiva en las primeras diferencias âˆ†ğ‘¢ğ‘–ğ‘¡ . AdemÃ¡s, (ğœŒÌ‚ = 0.237) es muy
diferente de (ğœŒ = âˆ’0.5), lo que implica que los ğ‘¢ğ‘–ğ‘¡ son no correlacionados en el supuesto estÃ¡ndar de
efectos aleatorios y fijos.
Alternativas a la Matriz de Varianza Robusta: Una alternativa a calcular errores estÃ¡ndar robustos y
estadÃ­sticas de prueba es usar un anÃ¡lisis FGLS bajo la suposiciÃ³n de que ğ¸(ğ‘’ğ‘– ğ‘’ğ‘–â€² |ğ‘¥ğ‘– ) es una matriz
constante (ğ‘‡ âˆ’ 1) Ã— (ğ‘‡ âˆ’ 1). Omitimos los detalles, ya que son similares a los de FEGLS en la SecciÃ³n
10.5.5. Al igual que con FEGLS, podrÃ­amos imponer una estructura en ğ¸(ğ‘¢ğ‘– ğ‘¢ğ‘–â€™ ), como un modelo AR
(1) estable y homocedÃ¡stico, y luego derivar ğ¸(ğ‘’ğ‘– ğ‘’ğ‘–â€² ) en tÃ©rminos de un conjunto pequeÃ±o de parÃ¡metros.
ConclusiÃ³n: El testeo para correlaciÃ³n serial es crucial para validar las suposiciones de no correlaciÃ³n
en los errores de las primeras diferencias. Encontrar autocorrelaciÃ³n significativa justifica el uso de
matrices de varianza robusta o enfoques alternativos como FEGLS para asegurar inferencias vÃ¡lidas y
precisas en modelos de datos de panel.
10.6.4 AnÃ¡lisis de PolÃ­tica usando Primeras Diferencias
La diferenciaciÃ³n de primera de una ecuaciÃ³n estructural con un efecto no observado es un mÃ©todo
simple y efectivo para evaluar programas. Con datos de panel de dos aÃ±os y grupos de control y
tratamiento en dos momentos, podemos abordar muchas preguntas. Al aplicar la diferenciaciÃ³n de
primera, se deben diferenciar todas las variables en la ecuaciÃ³n estructural, incluidas las variables
binarias de participaciÃ³n en el programa. Las estimaciones se interpretan en la ecuaciÃ³n original,
permitiendo comparaciones en la secciÃ³n transversal en cualquier momento, donde una unidad recibe el
tratamiento y la otra no.
Caso Especial: Variable de PolÃ­tica Diferenciada: En un caso especial, no importa si la variable de
polÃ­tica es diferenciada. Supongamos que ğ‘‡ = 2, y ğ‘ğ‘Ÿğ‘œğ‘”(ğ‘–ğ‘¡) denota un indicador binario que se
establece en uno si la persona participÃ³ en el programa en el tiempo ğ‘¡. Para muchos programas, ğ‘ğ‘Ÿğ‘œğ‘”ğ‘–ğ‘¡ =
0 para todos ğ‘–: nadie participÃ³ en el programa en el perÃ­odo inicial. En el segundo perÃ­odo, ğ‘ğ‘Ÿğ‘œğ‘”ğ‘–2 es
uno para aquellos que participan en el programa y cero para aquellos que no lo hacen. En este caso,
âˆ†ğ‘ğ‘Ÿğ‘œğ‘”ğ‘– = ğ‘ğ‘Ÿğ‘œğ‘”ğ‘–2 , y la ecuaciÃ³n diferenciada de primera puede escribirse como:

Estimador DID: El efecto de la polÃ­tica se puede obtener al hacer una regresiÃ³n del cambio en ğ‘¦ sobre
el cambio en ğ‘§ y el indicador de polÃ­tica. Cuando âˆ†ğ‘§ğ‘–2 se omite, la estimaciÃ³n de ğ›¿1 en la ecuaciÃ³n
(10.72) es el estimador de diferencias en diferencias (DID) (ğ›¿1 = âˆ†ğ‘¦ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘¡ âˆ’ âˆ†ğ‘¦ğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘™ ). Esto es similar
al estimador DID de la SecciÃ³n 6.3 (ver ecuaciÃ³n 6.32), pero hay una diferencia importante: con datos
de panel, las diferencias en el tiempo son para las mismas unidades de secciÃ³n transversal.
Consideraciones Adicionales: Si algunas personas participaron en el programa en el primer perÃ­odo, o
si hay mÃ¡s de dos perÃ­odos involucrados, la ecuaciÃ³n (10.72) puede dar respuestas engaÃ±osas. En
general, la ecuaciÃ³n que se debe estimar es:

Donde el indicador de participaciÃ³n en el programa se diferencia junto con todo lo demÃ¡s, y los ğœ‰ğ‘¡ son
nuevos interceptos de perÃ­odo. El ejemplo 10.6 es un caso de este tipo.
ConclusiÃ³n: La diferenciaciÃ³n de primera es una herramienta poderosa para el anÃ¡lisis de polÃ­ticas,
permitiendo la evaluaciÃ³n de programas con datos de panel. Al diferenciar todas las variables, incluidas
las de participaciÃ³n en el programa, se obtienen estimaciones precisas y comparaciones vÃ¡lidas entre
unidades tratadas y de control. Es crucial considerar la estructura temporal y las caracterÃ­sticas del
programa para evitar interpretaciones engaÃ±osas y asegurar resultados robustos.
10.7 COMPARACIÃ“N DE ESTIMADORES
10.7.1 Efectos fijos vs. Primeras Diferencias
Cuando solo tenemos dos perÃ­odos de tiempo, la estimaciÃ³n de efectos fijos (FE) y primeras diferencias
(FD) producen estimaciones e inferencias idÃ©nticas. Cuando ğ‘‡ > 2, la elecciÃ³n entre FE y FD depende
de las suposiciones sobre los errores idiosincrÃ¡ticos, ğ‘¢ğ‘–ğ‘¡ . FE es mÃ¡s eficiente bajo la suposiciÃ³n FE.3
(los ğ‘¢ğ‘–ğ‘¡ ) no estÃ¡n correlacionados serialmente), mientras que FD es mÃ¡s eficiente cuando ğ‘¢ğ‘–ğ‘¡ sigue un
paseo aleatorio.
SuposiciÃ³n de Exogeneidad Estricta: Si las estimaciones de FE y FD difieren de maneras que no se
atribuyen al error de muestreo, el problema es la suposiciÃ³n de exogeneidad estricta. Si ğ‘¢ğ‘–ğ‘¡ estÃ¡
correlacionado con ğ‘¥ğ‘–ğ‘  para cualquier ğ‘ , FE y FD tienen lÃ­mites de probabilidad diferentes. Los
problemas estÃ¡ndar de endogeneidad tienen el mismo efecto.
Prueba de Hausman: Podemos probar las suposiciones subyacentes a la consistencia de FE y FD
usando una prueba de Hausman. Usar una forma robusta de la prueba de Hausman que no mantenga la
suposiciÃ³n FE.3 ni la suposiciÃ³n FD.3 bajo la hipÃ³tesis nula.
Si ğ‘‡ = 2, en la ecuaciÃ³n ğ›¥ğ‘¦ğ‘–ğ‘¡ = ğ›¥ğ‘¥ğ‘–ğ‘¡ ğ›½ + ğ›¥ğ‘¢ğ‘–ğ‘¡ , ni ğ‘¥ğ‘–1 ni ğ‘¥ğ‘–2 deberÃ­an ser significativos como variables
explicativas adicionales en la ecuaciÃ³n de diferencias primeras. Una prueba de exogeneidad estricta
usando efectos fijos, cuando ğ‘‡ > 2, se obtiene especificando la ecuaciÃ³n:

donde ğ‘¤ğ‘–ğ‘¡,ğ‘–+1 es un subconjunto de ğ‘¥ğ‘–ğ‘¡,ğ‘–+1 (que excluirÃ­a las variables ficticias de tiempo). Bajo
exogeneidad estricta, ğ›¿ = 0, y podemos realizar la prueba usando la estimaciÃ³n de efectos fijos.
AnÃ¡lisis de MCG: Bajo exogeneidad estricta, podemos usar un procedimiento de MCG en cualquiera
de las ecuaciones descontadas por tiempo o las ecuaciones de diferencias primeras. Im, Ahn, Schmidt y
Wooldridge (1999) muestran formalmente que los estimadores FEGLS y FDGLS son asintÃ³ticamente
equivalentes bajo FE.1 y FEGLS.3 y las condiciones de rango apropiadas.
ConclusiÃ³n: La elecciÃ³n entre FE y FD depende de las suposiciones sobre los errores idiosincrÃ¡ticos y
la estructura temporal de los datos. Ambos mÃ©todos pueden producir estimaciones consistentes, pero su
eficiencia varÃ­a segÃºn las suposiciones especÃ­ficas. La prueba de Hausman proporciona una herramienta
robusta para validar estas suposiciones y asegurar inferencias precisas en el anÃ¡lisis de datos de panel.
10.7.2 La relaciÃ³n entre los estimadores de efectos aleatorios y efectos fijos
Cuando las variables clave en ğ‘¥ğ‘¡ no varÃ­an mucho con el tiempo, los mÃ©todos de efectos fijos (FE) y de
primeras diferencias (FD) pueden ser imprecisos. Si un anÃ¡lisis de efectos aleatorios (RE) es apropiado
si ğ‘ğ‘– es ortogonal a ğ‘¥ğ‘–ğ‘¡ , sus varianzas son mucho menores que los estimadores FE o FD. Ahora
obtenemos una expresiÃ³n para el estimador de efectos aleatorios (RE) que nos permite compararlo con
el estimador de efectos fijos (FE).
ExpresiÃ³n de la Matriz de Varianza: Usando el hecho de que ğ‘—ğ‘‡â€² ğ‘—ğ‘‡ = ğ‘‡, podemos escribir Î© bajo la
estructura de efectos aleatorios como:

Donde se transforma la ecuaciÃ³n y se obtiene:

Por lo tanto, la estimaciÃ³n MCO de (10.74) es la estimaciÃ³n MCO agrupada de:

para todos ğ‘¡ e ğ‘–. Los errores en esta ecuaciÃ³n son no correlacionados en serie y homocedÃ¡sticos bajo la
suposiciÃ³n RE.3; por lo tanto, cumplen con las condiciones clave para el anÃ¡lisis MCO agrupado.
Estimador RE Factible: El estimador RE factible reemplaza el ğœ† desconocido por su estimador, ğœ†Ì‚, de
modo que ğ›½Ì‚ğ‘…ğ¸ puede ser calculado a partir de la regresiÃ³n MCO agrupada de:

ConclusiÃ³n: La relaciÃ³n entre los estimadores de efectos aleatorios (RE) y efectos fijos (FE) se basa en
la estructura de la varianza y las suposiciones sobre la correlaciÃ³n entre las variables explicativas y los
efectos inobservados. El uso de RE puede ser mÃ¡s eficiente cuando ğ‘ğ‘– es ortogonal a ğ‘¥ğ‘–ğ‘¡ , permitiendo
una varianza menor en las estimaciones. La transformaciÃ³n y ajuste en los modelos aseguran que los
errores sean homocedÃ¡sticos y no correlacionados, proporcionando estimaciones fiables y precisas en el
anÃ¡lisis de datos de panel.

10.7.3. La prueba de Hausman
La prueba de Hausman se utiliza con el fin de determinar si hay correlaciÃ³n entre los efectos no
observados (ci) y las variables explicativas (xit). La prueba compara los estimadores de efectos
aleatorios (RE) y efectos fijos (FE). Si los efectos fijos son consistentes cuando ci y xit estÃ¡n
correlacionados, pero los efectos aleatorios no lo son, una diferencia significativa entre ambos
estimadores sugiere que el supuesto de efectos aleatorios es incorrecto.
Condiciones para la prueba de Hausman: Exogeneidad Estricta (Se asume que se mantiene bajo la
hipÃ³tesis nula, lo que significa que la correlaciÃ³n entre ğ‘¥ğ‘–ğ‘  y ğ‘¢ğ‘–ğ‘¡ (para cualquier s y t) harÃ­a inconsistentes
tanto los estimadores FE como RE. TambiÃ©n, la prueba se implementa asumiendo que la SuposiciÃ³n
RE.3 se mantiene bajo la hipÃ³tesis nula, lo que implica que el estimador RE es mÃ¡s eficiente que el FE.
Sin embargo, la prueba de Hausman no puede detectar fallos en RE.3, lo que puede llevar a una
distribuciÃ³n asintÃ³tica no estÃ¡ndar.
EstadÃ­sticas t y F: Para un solo parÃ¡metro, se puede usar una versiÃ³n t de la prueba de Hausman,
mientras que para mÃºltiples parÃ¡metros, se puede usar una versiÃ³n F de la prueba de Hausman. Esto
implica extender el modelo e implementar la prueba usando anÃ¡lisis de regresiÃ³n estÃ¡ndar con OLS.
Alternativas y Robustez: Si la suposiciÃ³n RE.3 falla, se necesita una versiÃ³n robusta de la prueba de
Hausman. Una aproximaciÃ³n sencilla es usar una estadÃ­stica Wald robusta en el contexto de la
estimaciÃ³n con OLS agrupado.
Consideraciones PrÃ¡cticas: La prueba de Hausman puede rechazar las suposiciones RE con diferencias
pequeÃ±as pero significativas entre los estimadores RE y FE, o puede no rechazar cuando las diferencias
son grandes pero las varianzas estÃ¡ndar tambiÃ©n lo son. Esto puede llevar a errores de Tipo II (no
rechazar cuando es falso).
ConclusiÃ³n: La prueba de Hausman es una herramienta crucial para decidir entre modelos de efectos
aleatorios y efectos fijos, basada en la correlaciÃ³n entre los efectos no observados y los regresores. Sin
embargo, su aplicaciÃ³n requiere cuidadosas consideraciones sobre las suposiciones subyacentes y la
robustez de los resultados, particularmente en presencia de correlaciÃ³n serial y heterocedasticidad.

FROM EDUCATION TO DEMOCRACY? (ACEMOGLU ET.AL. 2005)
La educaciÃ³n se considera crucial para la democracia porque fomenta una cultura democrÃ¡tica y estÃ¡
asociada con mayor prosperidad, lo que a su vez se cree que impulsa el desarrollo polÃ­tico. Esta idea es
respaldada por la teorÃ­a de la modernizaciÃ³n de Lipset, que destaca la educaciÃ³n y el crecimiento
econÃ³mico como impulsores del desarrollo polÃ­tico y la democracia.
Lipset (1959 p.20) concluye que: Si bien un alto nivel de educaciÃ³n no es suficiente para la democracia,
la evidencia sugiere que se acerca a ser una condiciÃ³n necesaria.
Trabajos recientes de Barro (1999) y Przeworski et al. (2000) respaldan la idea de que la educaciÃ³n
influye en la democracia. Glaeser et al. (2004) argumentan que las diferencias en la educaciÃ³n son un
factor causal importante no solo para la democracia, sino tambiÃ©n para otras instituciones polÃ­ticas.
La investigaciÃ³n de User destaca que la correlaciÃ³n entre educaciÃ³n y democracia no implica causalidad.
Mostraron que, a pesar de un aumento en la educaciÃ³n en un paÃ­s, no hay una tendencia clara hacia una
mayor democratizaciÃ³n en ese paÃ­s. Esto sugiere que otros factores podrÃ­an estar influyendo en la
relaciÃ³n entre educaciÃ³n y democracia.
La investigaciÃ³n muestra que la relaciÃ³n entre educaciÃ³n y democracia desaparece al controlar los
efectos fijos por paÃ­s, indicando la influencia de otros factores. AdemÃ¡s, se destaca la robustez de estos
hallazgos en diferentes tÃ©cnicas y muestras.
El estudio de User indica que el impacto de la educaciÃ³n en la democracia, seÃ±alado por Glaeser et al.
(2004), desaparece cuando se consideran efectos temporales en las regresiones. Esto sugiere que el
aumento global en la educaciÃ³n y la democracia en las Ãºltimas dÃ©cadas podrÃ­a estar influyendo en los
resultados. AdemÃ¡s, no se encuentra efecto de la educaciÃ³n en otras medidas de instituciones polÃ­ticas.
User estÃ¡ investigando la relaciÃ³n entre ingreso y democracia, encontrando poca evidencia de un
efecto causal directo. AdemÃ¡s, proponen una teorÃ­a respaldada por evidencia empÃ­rica para explicar las
diferencias en los factores que afectan la evoluciÃ³n de la educaciÃ³n, el ingreso y la democracia.
I. EducaciÃ³n y democracia
User utiliza el Ãndice de Derechos PolÃ­ticos de Freedom House para medir la democracia, donde 7
representa la menor cantidad de libertad polÃ­tica y 1 la mayor. TambiÃ©n utiliza la variable relacionada
de Bollen (1990), transformada entre 0 y 1. Prefiere observaciones quinquenales en lugar de promediar
los datos para evitar introducir una correlaciÃ³n serial adicional.
La variable principal, los aÃ±os promedio de escolaridad en la poblaciÃ³n mayor de 25 aÃ±os, proviene de
Barro y Lee (2000) y abarca intervalos de cinco aÃ±os entre 1960 y 2000. En nuestra muestra base, esta
variable varÃ­a de 0.04 a 12.18 aÃ±os, con una media de 4.44. Los resultados principales se presentan en
la Tabla 1, utilizando datos de Freedom House y estimando una relaciÃ³n agrupada de MCO entre
educaciÃ³n y democracia:
(1)

ğ‘‘ğ‘–,ğ‘¡ =âˆ ğ‘‘ğ‘–,ğ‘¡âˆ’1 + ğ›¾ğ‘ ğ‘–,ğ‘¡âˆ’1 + ğœ‡ + ğ‘£ğ‘–ğ‘¡

donde ğ‘‘ğ‘–,ğ‘¡ es el puntaje de democracia del paÃ­s i en el perÃ­odo t. El valor rezagado de esta variable se
incluye en el lado derecho para capturar la persistencia en la democracia y tambiÃ©n dinÃ¡micas
potencialmente de reversiÃ³n a la media en la democracia. La principal variable de interÃ©s es ğ‘ ğ‘–,ğ‘¡âˆ’1 , el
valor rezagado de aÃ±os promedio de escolaridad. El parÃ¡metro ğ›¾ mide si la educaciÃ³n tiene un efecto
sobre la democracia. El parÃ¡metro ğœ‡ğ‘¡ denota un conjunto completo de efectos temporales, que
capturan los choques comunes a el puntaje de democracia de todos los paÃ­ses, y ğ‘£ğ‘–ğ‘¡ es un tÃ©rmino de
error, que captura todos los otros factores omitidos.
La columna (i) muestra una correlaciÃ³n significativa entre educaciÃ³n y democracia, con una
estimaciÃ³n de Î³ de 0.027 y un error estÃ¡ndar de 0.004, significativo al 1%. Esto implicarÃ­a que un aÃ±o
adicional de escolaridad aumenta el valor de "estado estacionario" de la democracia en 0.093. Esta es
una magnitud significativa en relaciÃ³n con la media de democracia en la muestra, que es 0.57. La

estimaciÃ³n incluye tanto el efecto directo como el indirecto de la educaciÃ³n sobre la democracia a
travÃ©s del ingreso.
La EcuaciÃ³n (1) de la investigaciÃ³n es similar a las regresiones previas al no considerar los efectos
fijos por paÃ­s. Esto puede causar estimaciones incorrectas del efecto de la educaciÃ³n en la democracia
debido a factores omitidos que influyen en ambas variables a largo plazo.
La alternativa es permitir la presencia de tales factores omitidos (que no varÃ­an con el tiempo)
mediante la inclusiÃ³n de efectos fijos por paÃ­s, es decir, estimando un modelo de la forma:
(2)

ğ‘‘ğ‘–,ğ‘¡ =âˆ ğ‘‘ğ‘–,ğ‘¡âˆ’1 + ğ›¾ğ‘ ğ‘–,ğ‘¡âˆ’1 + ğœ‡ğ‘¡ + ğ›¿ğ‘– + ğ‘¢ğ‘–ğ‘¡

, que difiere de (1) Ãºnicamente por el conjunto completo de variables Dummy de paÃ­s, el ğ›¿ğ‘– â€²ğ‘ .
El resto de la Tabla 1 presenta estimaciones de ğ›¾ a partir de modelos similares a (2). La columna (ii) es
idÃ©ntica a la columna (i) excepto por los efectos fijos por paÃ­s, los ğ›¿ğ‘– â€²ğ‘ . Sin embargo, los resultados
son radicalmente diferentes. Ahora, ğ›¾ se estima en -0.005 con un error estÃ¡ndar de 0.019; por lo tanto,
es altamente insignificante y tiene el signo opuesto al predicho por la hipÃ³tesis de la modernizaciÃ³n [y
al encontrado en la regresiÃ³n de MCO agrupada de la columna (i)].
En la regresiÃ³n de la columna (ii), debido a que el regresor ğ‘‘ğ‘–,ğ‘¡âˆ’1 estÃ¡ mecÃ¡nicamente correlacionado
con ğ‘¢ğ‘–ğ‘¡ para ğ‘  < ğ‘¡, la estimaciÃ³n de efectos fijos estÃ¡ndar no es consistente en paneles con una
dimensiÃ³n temporal corta debido a la correlaciÃ³n mecÃ¡nica entre el regresor y el error. Para abordar
esto, en la columna (iii) se utiliza el estimador GMM de Arellano y Bond (1991), que da una
estimaciÃ³n mÃ¡s negativa de -0.017 (SE = 0.022). Las pruebas AR(2) y de Hansen J no rechazan las
restricciones de sobreidentificaciÃ³n implÃ­citas en este procedimiento.
Las columnas adicionales de la Tabla 1 examinan la relaciÃ³n entre educaciÃ³n y democracia al incluir
otras variables. Las columnas (iv) y (v) consideran la estructura de edad y la poblaciÃ³n, pero estas
variables no resultan significativas. Aunque las variables de estructura de edad son conjuntamente
significativas en OLS, no lo son en GMM, y el logaritmo de la poblaciÃ³n no es significativo. El efecto
de la educaciÃ³n sobre la democracia sigue siendo altamente insignificante en ambos casos.
Las columnas (vi) y (vii) incluyen el PIB per cÃ¡pita. Tanto la educaciÃ³n como el PIB per cÃ¡pita
resultan insignificantes, con coeficientes negativos. Esto sugiere que el efecto causal del ingreso sobre
la democracia, otro principio de la hipÃ³tesis de modernizaciÃ³n, tampoco es robusto al considerar
efectos fijos por paÃ­s. Las columnas (viii) y (ix) controlan simultÃ¡neamente el logaritmo de la
poblaciÃ³n, la estructura de edad y el PIB per cÃ¡pita, con resultados similares.

Los resultados se mantienen al
excluir ciertos grupos de paÃ­ses
y al usar diferentes medidas de
democracia o periodos de
tiempo. En general, no hay una
relaciÃ³n empÃ­rica entre
educaciÃ³n y democracia una
vez que se controlan los efectos
fijos por paÃ­s, lo que cuestiona
el efecto causal de la educaciÃ³n
sobre la democracia.

II. Â¿De la educaciÃ³n a las instituciones?
El reciente artÃ­culo de Glaeser et al. (2004) argumenta que
hay un efecto causal de la educaciÃ³n sobre las instituciones.
Lo sustentan al reportar regresiones similares a nuestro
modelo en (2), pero con resultados muy diferentes,
mostrando en particular un efecto positivo de la educaciÃ³n
sobre la democracia. Â¿Por quÃ© sus resultados son diferentes
de los nuestros?
En la Tabla 2A, se replican los resultados utilizando
restricciÃ³n ejecutiva, puntajes de autocracia y democracia de
Polity, y puntajes de autocracia de Przeworski et al. Los
resultados coinciden con las regresiones originales, pero
difieren de las de User al no incluir efectos temporales. Sin
efectos temporales, el parÃ¡metro Î³ se identifica a partir de la
variaciÃ³n a lo largo del tiempo, lo que no corresponde a un
efecto causal.
Los paneles B y C de la Tabla 2 presentan estimaciones con
y sin ingreso per cÃ¡pita, pero incluyendo efectos temporales.
En todos los casos, el efecto de la educaciÃ³n es insignificante y tiene el signo incorrecto, al igual que
en los resultados bÃ¡sicos. AdemÃ¡s, en la mayorÃ­a de las columnas, los efectos temporales son
significativos al nivel del 1% o menos, y en un caso al nivel del 10%. Curiosamente, en este Ãºltimo
caso, la educaciÃ³n sigue siendo insignificante incluso sin efectos temporales.
La evidencia en la Tabla 2 muestra, por lo tanto, que parece no haber efecto de la educaciÃ³n sobre la
democracia ni sobre otras instituciones polÃ­ticas.
III. Conclusiones
La teorÃ­a de la modernizaciÃ³n sugiere que la educaciÃ³n alta es crucial para la democracia, pero este
documento muestra que la evidencia existente no respalda firmemente esta idea, ya que factores no
considerados podrÃ­an explicar la aparente relaciÃ³n entre educaciÃ³n y democracia.
Esta evidencia plantea dos enunciados importantes:
(i) El documento no responde si hay una relaciÃ³n causal a largo plazo entre educaciÃ³n y democracia,
ya que se basa en variaciones quinquenales que podrÃ­an no capturar efectos a largo plazo que podrÃ­an
durar hasta 50 o 100 aÃ±os.
(ii) Los factores omitidos que influyen en la educaciÃ³n y la democracia podrÃ­an relacionarse con la
evoluciÃ³n histÃ³rica del desarrollo econÃ³mico y polÃ­tico. Investigaciones previas sugieren que los
efectos fijos por paÃ­s estÃ¡n correlacionados con determinantes histÃ³ricos del desarrollo institucional,
como las experiencias tempranas con la democracia y condiciones demogrÃ¡ficas.

Universidad de Lima
Facultad de Ciencias Empresariales y EconÃ³micas
Carrera de EconomÃ­a

Resumen Control 3: Lecturas semanas 5-9
Curso: EconometrÃ­a 2

â€œHe insistido en que la econometrÃ­a debe tener relevancia en realidades
concretas, de lo contrario degenera en algo que no merece el nombre de
econometrÃ­a, sino que mÃ¡s bien deberÃ­a llamarse 'jugometrÃ­a.â€
-Ragnar Frisch.

Profesor
Jose Luis Nolazco Cama
Junio de 2024

Lima â€“ PerÃº

COINTEGRATION AND ERROR-CORRECTION MODELS (ENDERS CAP 6)
1. LINEAR COMBINATIONS OF INTEGRATED VARIABLES
Se presenta una ecuaciÃ³n simple por la demanda del dinero
ğ’ğ’• = ğœ·ğŸ + ğœ·ğŸ ğ’‘ğ’• + ğœ·ğŸ ğ’šğ’• + ğœ·ğŸ‘ ğ’“ğ’• + ğ’†ğ’•

(6.1. )

ğ‘ğ‘¡ = nivel de precios
ğ‘¦ğ‘¡ = ingreso real
ğ‘Ÿğ‘¡ = tasa de interÃ©s
ğ‘’ğ‘¡ = termino de perturbaciÃ³n estacionario
ğ›½ğ‘– = parÃ¡metros a estimar
y todas las variables son expresadas en logaritmos, excepto ğ‘Ÿğ‘¡
La hipÃ³tesis de que el mercado de dinero estÃ¡ en equilibrio permite a los investigadores recolectar data
de series de tiempo de la oferta monetaria (= demanda de dinero si el mercado siempre se vacÃ­a), el nivel
de precios, ingreso real, y una tasa de interÃ©s. Los supuestos de comportamiento requieren ğ›½1 = 1, ğ›½2 >
0 y ğ›½3 < 0. Si ğ‘’ğ‘¡ tiene una tendencia estocÃ¡stica, los errores en el modelo serÃ¡n acumulados tal que la
desviaciÃ³n del equilibrio no serÃ¡ eliminada. Es por ello que se necesita que ğ‘’ğ‘¡ sea estacionario.
El problema es que las demÃ¡s variables pueden ser caracterizadas como variables no estacionarias I(1).
Como tal, cada variable puede serpentear sin tendencia a volver en el largo plazo. Sin embargo, la teorÃ­a
de (6.1) afirma que existe una combinaciÃ³n lineal de estas variables no estacionarias que es estacionaria.
ğ‘’ğ‘¡ = ğ‘šğ‘¡ âˆ’ ğ›½0 âˆ’ ğ›½1 ğ‘ğ‘¡ âˆ’ ğ›½2 ğ‘¦ğ‘¡ âˆ’ ğ›½3 ğ‘Ÿğ‘¡
Dentro de un marco de equilibrio, las desviaciones de este deben ser estacionarias. Otros ejemplos
econÃ³micos importantes son:
1. TeorÃ­a de la funciÃ³n del consumo: La versiÃ³n simple de la hipÃ³tesis del consumo permanente
ğ‘
sostiene que el consumo total (ğ‘ğ‘¡ ) es la suma del consumo permanente (ğ‘ğ‘¡ ) y el transitorio
(ğ‘ğ‘¡ğ‘¡ ). Ya que el consumo permanente es proporcional al ingreso permanente, tanto el consumo
como el permanente serÃ¡n variables I(1), lo que requiere que el consumo transitorio sea
estacionario.
2. HipÃ³tesis de la tasa a plazo imparcial: La teoria de los mercados eficientes sostienen que el
precio forward de un activo es el valor esperado del precio spot en el futuro. En este caso la
combinaciÃ³n lineal dependerÃ¡ del error. SegÃºn esta hipÃ³tesis, se requiere que exista una
combinaciÃ³n lineal de tipos de cambio a plazo y al contado no estacionarios que sea estacionaria.
3. Mercado de arbitraje de comoddities y poder de paridad de compra: Los arbitrajistas evitan
que en el corto plazo los precios de los mismos activos no varÃ­en incluso si los precios son no
estacionarios. AdemÃ¡s, el PPP pone restricciones en el movimiento no estacionario de los
niveles de precios y tasas de tipo de cambio. Si et es el logaritmo del tipo de cambio extranjero
ğ‘ğ‘¡ y ğ‘ğ‘¡âˆ— los logaritmos de los niveles de precios domÃ©sticos y extranjeros, la combinaciÃ³n lineal
del PPP en el largo plazo ğ‘’ğ‘¡ + ğ‘ğ‘¡âˆ— âˆ’ ğ‘ğ‘¡ es estacionario.
Todos estos ejemplos ilustran el concepto de cointegraciÃ³n Engle y Granger (1987). Su anÃ¡lisis formal
es la combinaciÃ³n de variables econÃ³micas en equilibrio en el largo plazo
ğ›½1 ğ‘¥1ğ‘¡ + ğ›½2 ğ‘¥2ğ‘¡ + â‹¯ + ğ›½ğ‘› ğ‘¥ğ‘›ğ‘¡ = 0
Donde los ğ›½t son los vectores y los x que estÃ¡ en equilibrio cuando ğ›½ x=0. La desviaciÃ³n del equilibrio
(conocida como error de equilibrio) es ğ‘’ğ‘¡ , tal que:
ğ‘’ğ‘¡ = ğ›½ğ‘¥ğ‘¡
Si el equilibrio es significativo, debe ser que el proceso de error de equilibrio es estacionario. El termino
equilibrio es diferente para economistas y econometristas, los primeros se refieren a una igualdad entre

transacciones deseadas y las verdaderas; mientras que los segundos, hacen referencia a cualquier
relaciÃ³n de variables no estacionarias en el largo plazo. Engle y Granger (1987) definen la cointegraciÃ³n:
Los componentes del vector
denotado por
si:

se dicen que estÃ¡n cointegrados de orden d, b

1. Todos los componentes de ğ‘¥ğ‘¡ , son integrados de orden ğ‘‘
2. Existe un vector beta, tal que la combinaciÃ³n lineal de ğ›½ğ‘¥ğ‘¡ = ğ›½1 ğ‘¥1ğ‘¡ + ğ›½2 ğ‘¥2ğ‘¡ + â‹¯ + ğ›½ğ‘› ğ‘¥ğ‘›ğ‘¡ x es
integrado de orden (ğ‘‘ âˆ’ ğ‘) donde ğ‘ > 0. (beta es el vector de cointegraciÃ³n)
En tÃ©rminos de la ecuaciÃ³n (6,1) (la del inicio) todas las variables que eran I(1) y la combinaciÃ³n lineal
de ğ‘šğ‘¡ âˆ’ ğ›½0 âˆ’ ğ›½1 ğ‘ğ‘¡ âˆ’ ğ›½2 ğ‘¦ğ‘¡ âˆ’ ğ›½3 ğ‘Ÿğ‘¡ = ğ‘’ğ‘¡ es estacionario, entonces las variables estÃ¡n cointegradas de
orden (1,1). El vector ğ‘¥ğ‘¡ es (ğ‘šğ‘¡ , 1, ğ‘ğ‘¡ , ğ‘¦ğ‘¡ , ğ‘Ÿğ‘¡ )Â´ y el vector de cointegraciÃ³n ğ›½ es
(1, âˆ’ ğ›½0 , âˆ’ ğ›½1 , âˆ’ğ›½2 , âˆ’ğ›½3 ). La desviaciÃ³n del equilibrio del mercado monetario a largo plazo es et; dado
que {ğ‘’ğ‘¡ } es estacionario, esta desviaciÃ³n es de naturaleza temporal.
Cuatro puntos a resaltar de la definiciÃ³n:
1. Si bien ya sabemos que es la cointegraciÃ³n. TeÃ³ricamente, es bastante probable que exista una
combinaciÃ³n no lineal de largo plazo entre variables integradas. TambiÃ©n se debe notar que el
vector de cointegraciÃ³n no es Ãºnico. Si existe un beta, si se lo multiplica por un landa (diferente
de cero) tambiÃ©n es un vector de cointegraciÃ³n. Para normalizar el vector con respecto a ğ‘¥1ğ‘¡ , se
elige ğœ† = 1/ ğ›½.
2. En la definiciÃ³n, no todas las variables estÃ¡n son del mismo orden, usualmente habrÃ¡ un nÃºmero
de variables I(d) no cointegradas. Por lo que pasean arbitrariamente en el equilibrio. Dos
variables integradas de diferente orden, no pueden ser cointegradas. Sin embargo, si ğ‘¥1ğ‘¡ y ğ‘¥2ğ‘¡
son CI(2.1), existe una combinaciÃ³n lineal de la forma ğ›½1 ğ‘¥1 + ğ›½2 ğ‘¥2 la cual es I(1). Es posible
que esta combinaciÃ³n de ğ‘¥1ğ‘¡ y ğ‘¥2ğ‘¡ esta cointegrada con variables I(1). Lee y Granger (1990)
usan el termino multicointegraciÃ³n para esto.
3. Puede que halla mÃ¡s de un vector de cointegraciÃ³n independiente para un grupo de variables
I(1). El nÃºmero de vectores de cointegraciÃ³n se llama el rango de cointegraciÃ³n de ğ‘¥ğ‘¡ .
4. La mayor parte de la literatura de cointegraciÃ³n se concentra en el caso en que cada variable
contenga una Ãºnica raÃ­z unitaria. La razÃ³n es que tradicionalmente los anÃ¡lisis se aplican a
variables I(0) y pocas variables son integrados de orden superior a la unidad.
Caso 1: La serie {ğœ‡ğ‘¡ } es un proceso de caminata aleatoria y
{ğœ€ğ‘¦ğ‘¡ } y {ğœ€ğ‘§ğ‘¡ } son ruido blanco. Por lo tanto, las secuencias
{ğ‘¦ğ‘¡ } y {ğ‘§ğ‘¡ } son ambas procesos de caminata aleatoria mÃ¡s
ruido. Aunque cada una es no estacionaria, las dos
secuencias tienen la misma tendencia estocÃ¡stica; por lo
tanto, estÃ¡n cointegradas de manera que la combinaciÃ³n
lineal (ğ‘¦ğ‘¡ âˆ’ ğ‘§ğ‘¡ ) es estacionaria. El tÃ©rmino de error de
equilibrio (ğœ€ğ‘¦ğ‘¡ âˆ’ ğœ€ğ‘§ğ‘¡ ) es un proceso I(0).
Caso 2: Las tres secuencias son procesos de caminata
aleatoria mÃ¡s ruido. Como estÃ¡n construidas, ninguna de las
dos estÃ¡n cointegradas. Sin embargo, la combinaciÃ³n lineal
(ğ‘¦ğ‘¡ + ğ‘§ğ‘¡ âˆ’ ğ‘¤ğ‘¡ ) es estacionaria; por lo tanto, las tres
variables estÃ¡n cointegradas. El error de equilibrio es un
proceso I(0).
En el caso 1, tanto la secuencia ğ‘¦ğ‘¡ como ğ‘§ğ‘¡ fueron construidas como un random walk mÃ¡s un proceso
de ruido. Si bien cuando son 20 realizaciones se observa un declive, cuando se extiende la muestra se
eliminarÃ­a esta tendencia. En cualquier caso, ninguna serie muestra una tendencia a regresar a largo
plazo (dickey Fuller no es capaz de rechazar la ğ»0 ). Aunque ambas series son no estacionarias, se ve

que se mueven juntas. De hecho, la diferencia de las series (ğ‘¦ğ‘¡ âˆ’ ğ‘§ğ‘¡ ) es estacionario, con media cero y
varianza constante.
En el caso 2 ilustra la cointegraciÃ³n entre tres random walk con ruido. Como en el caso 1, ninguna serie
muestra tendencia a retorno en el largo plazo (dickey Fuller tampoco funciona). En contraste al caso
anterior, no hay dos series que aparenten estar cointegradas; cada serie parece deambular de la otra. Sin
embargo, existe la combinaciÃ³n lineal ğ‘’ğ‘¡ = ğ‘¦ğ‘¡ + ğ‘§ğ‘¡ â€“ ğ‘¤ğ‘¡ . Por lo tanto, se deduce que el comportamiento
dinÃ¡mico de al menos una variable debe estar restringido por los valores de las otras variables en el
sistema.
Se dispone de un grÃ¡fico de dispersiÃ³n del caso 1 de ğ‘¦ğ‘¡ con el valor
asociado ğ‘§ğ‘¡ , entonces se ve que hay una fuerte relaciÃ³n entre las
variables, de hecho, la recta de mÃ­nimos cuadrados revela que esta es la
relaciÃ³n de largo plazo de equilibrio de la serie, y las desviaciones de
la lÃ­nea son las desviaciones estacionarias.
TambiÃ©n se observa el caso de {ğ‘§ğ‘¡ } y {ğ‘¦ğ‘¡ }, que son las sendas temporales de dos random walk con ruido
que no estÃ¡n cointegrados, siendo. En el grÃ¡fico (a), ambas parecen vagar sin mostrar ninguna tendencia
a acercarse. El grÃ¡fico (b) muestra el diagrama de dispersiÃ³n de las dos secuencias y la lÃ­nea de regresiÃ³n
zt = ğ›½0 + ğ›½1yt. Sin embargo, esta lÃ­nea de regresiÃ³n es engaÃ±osa. Como se muestra en el grÃ¡fico (c), los
residuos de la regresiÃ³n no son estacionarios.

2. COINTEGRATION AND COMMON TRENDS
La observaciÃ³n de Stock y Watson (1988) de que las variables cointegradas comparten tendencias
estocÃ¡sticas comunes proporciona una manera muy Ãºtil de entender las relaciones de cointegraciÃ³n. Si
usamos un vector ğ‘¥ğ‘¡ con dos variables ğ‘¦ğ‘¡ y ğ‘§ğ‘¡ , podemos escribir cada variable como un paseo aleatorio
mÃ¡s un componente irregular:
ğ‘¦ğ‘¡ = ğœ‡ğ‘¦ğ‘¡ + ğ‘’ğ‘¦ğ‘¡ (6.4)
ğ‘§ğ‘¡ = ğœ‡ğ‘§ğ‘¡ + ğ‘’ğ‘§ğ‘¡ (6.5)
Donde ğœ‡ es un proceso de ruido blanco que representa la tendencia estocÃ¡stica, y ğ‘’ es el componente
estacionario de la variable
Si ğ‘Œğ‘¡ y ğ‘ğ‘¡ son cointegradas de orden (1,1), debe de haber valores no nulos de ğ›½1 y ğ›½2 para los cuales la
combinaciÃ³n lineal ğ›½1 ğ‘Œğ‘¡ + ğ›½2 ğ‘ğ‘¡ sea estacionaria. Por ello, considere la siguiente suma:

Para que ğœ·ğŸ ğ’šğ’• + ğœ·ğŸ ğ’›ğ’• sea estacionario, el tÃ©rmino (ğœ·ğŸ ğğ’šğ’• + ğœ·ğŸ ğğ’›ğ’• ) debe anularse, ya que si
cualquiera de las dos tendencias aparece en (6.6), la combinaciÃ³n lineal ğ›½1 ğ‘¦ğ‘¡ + ğ›½2 ğ‘§ğ‘¡ lo tendrÃ¡. Por lo
tanto, dado que el segundo tÃ©rmino entre parÃ©ntesis es estacionario, la condiciÃ³n necesaria y suficiente
para que {yt} y {zt} sean cointegradas de orden 1 es:
ğœ·ğŸ ğğ’šğ’• + ğœ·ğŸ ğğ’›ğ’• = ğŸ (ğŸ”. ğŸ•)

Claramente, ğœ‡ğ‘¦ğ‘¡ y ğœ‡ğ‘§ğ‘¡ son variables cuyos valores realizados cambiarÃ¡n continuamente con el tiempo.
Como excluimos que ğ›½1 y ğ›½2 sean iguales a 0, se sigue quÃ© (6.7) se cumple para todo t si y sÃ³lo si
ğœ‡ğ‘¦ğ‘¡ = âˆ’ğ›½2 ğœ‡ğ‘§ğ‘¡ /ğ›½1
Para valores no nulos de ğ›½1 y ğ›½2 , la Ãºnica manera de asegurar la igualdad es que las tendencias
estocÃ¡sticas sean idÃ©nticas hasta un escalar. Por lo tanto, hasta el escalar âˆ’ğ›½2 âˆ• ğ›½1, los dos procesos
estocÃ¡sticos {ğ‘¦ğ‘¡ } y {ğ‘§ğ‘¡ } que son I(1) deben tener la misma tendencia estocÃ¡stica si estÃ¡n cointegrados de
orden (1, 1).
Siguiendo un caso donde los ğœ€ son ruido blanco y ğœ‡ es un proceso de paseo aleatorio puro que representa
la misma tendencia estocÃ¡stica para ğ‘¦ğ‘¡ y ğ‘§ğ‘¡ :
ğ‘¦ğ‘¡ = ğœ‡ğ‘¡ + ğœ€ğ‘¦ğ‘¡
ğ‘§ğ‘¡ = ğœ‡ğ‘¡ + ğœ€ğ‘§ğ‘¡
ğœ‡ğ‘¡ = ğœ‡ğ‘¡âˆ’1 + ğœ€ğ‘¡
El valor de ğœ‡0 se inicializÃ³ en 0 y se extrajeron 3 conjuntos de 20 nÃºmeros para representar las secuencias
{ğœ€ğ‘¦ğ‘¡ }, {ğœ€ğ‘§ğ‘¡ } y {ğœ€ğ‘¡ }, y con estos errores y el valor inicial de ğœ‡0 se construyen las secuencias {ğ‘¦ğ‘¡ , ğ‘§ğ‘¡ , ğœ‡ğ‘¡ }.
Luego, al restar ğ‘§ğ‘¡ de ğ‘¦ğ‘¡ se consigue una secuencia estacionaria
ğ‘¦ğ‘¡ âˆ’ ğ‘§ğ‘¡ = (ğœ‡ğ‘¡ + ğœ€ğ‘¦ğ‘¡ ) âˆ’ (ğœ‡ğ‘¡ + ğœ€ğ‘§ğ‘¡ ) = ğœ€ğ‘¦ğ‘¡ âˆ’ ğœ€ğ‘§ğ‘¡
Para plantear el punto usando la terminologÃ­a de Engle y Granger, multiplicamos el vector cointegrante
ğ›½ = (1,âˆ’1) por el vector ğ‘¥ğ‘¡ = (ğ‘¦ğ‘¡ , ğ‘§ğ‘¡ )â€² que produce la secuencia estacionaria =ğœ€ğ‘¡ = ğœ€ğ‘¦ğ‘¡ âˆ’ ğœ€ğ‘§ğ‘¡ . La idea
esencial de Stock y Watson (1988) es que los parÃ¡metros del vector de cointegraciÃ³n deben ser tales que
purguen la tendencia de la combinaciÃ³n lineal. Cualquier otra combinaciÃ³n lineal de las dos variables
contiene una tendencia de manera que el vector de cointegraciÃ³n es Ãºnico hasta un escalar de
normalizaciÃ³n. Por lo tanto, ğ›½3 ğ‘¦ğ‘¡ + ğ›½4 ğ‘§ğ‘¡ no puede ser estacionario a menos que ğ›½3 âˆ• ğ›½4 = ğ›½1 âˆ• ğ›½2.
Luego, se construye una tendencia ğ‘¤ğ‘¡ que es simplemente la sumatoria de tendencias en ğ‘¦ğ‘¡ y ğ‘§ğ‘¡ :
ğœ‡ğ‘¤ğ‘¡ = ğœ‡ğ‘¦ğ‘¡ + ğœ‡ğ‘§ğ‘¡ . En este caso, el vector ğ‘¥ğ‘¡ = (ğ‘¦ğ‘¡ , ğ‘§ğ‘¡ , ğ‘¤ğ‘¡ )â€² tiene el vector de cointegraciÃ³n de (1,1,-1),
tal que la combinaciÃ³n lineal ğ‘¦ğ‘¡ + ğ‘§ğ‘¡ âˆ’ ğ‘¤ğ‘¡ es estacionaria. Considerando:

Este ejemplo demuestra el punto general de que la cointegraciÃ³n ocurrirÃ¡ siempre que la tendencia de
una variable pueda expresarse como una combinaciÃ³n lineal de las tendencias de las otras variables. En
tales circunstancias, siempre es posible encontrar un vector ğ›½ tal que la combinaciÃ³n lineal ğ›½1ğ‘¦ğ‘¡ + ğ›½2ğ‘§ğ‘¡
+ ğ›½3ğ‘¤ğ‘¡ no contenga tendencia. El resultado se generaliza fÃ¡cilmente al caso de n variables:
Considere la representaciÃ³n vectorial donde ğ‘¥ğ‘¡ es el vector (ğ‘¥1ğ‘¡ , ğ‘¥2ğ‘¡ , . . )â€², ğœ‡ğ‘¡ es el vector de tendencias
estocÃ¡sticas (ğœ‡1ğ‘¡ , ğœ‡2ğ‘¡ , â€¦ )â€² y ğ‘’ğ‘¡ es un vector de componentes estacionarios:
ğ‘¥ğ‘¡ = ğœ‡ğ‘¡ + ğ‘’ğ‘¡ (6.8)
Si una tendencia se puede expresar como una combinaciÃ³n lineal de las otras tendencias en el sistema,
significa que existe un vector ğ›½ tal que
ğ›½1 ğœ‡1ğ‘¡ + ğ›½2 ğœ‡2ğ‘¡ + â‹¯ + ğ›½ğ‘› ğœ‡ğ‘›ğ‘¡ = 0
Multiplicando por ğ›½ğ‘– ğ‘ 
ğ›½ğ‘¥ğ‘¡ = ğ›½ğœ‡ğ‘¡ + ğ›½ğ‘’ğ‘¡
Si ğ›½ğœ‡ğ‘¡ es 0, ğ›½ğ‘¥ğ‘¡ serÃ­a igual a ğ›½ğ‘’ğ‘¡ , lo que garantiza su estacionariedad. Esto se generaliza para mÃºltiples
vectores de cointegraciÃ³n

3. COINTEGRATION AND ERROR CORRECTION
Una caracterÃ­stica principal de las variables cointegradas es que sus trayectorias temporales son
influenciadas por el grado de cualquier desviaciÃ³n del equilibrio de largo plazo. DespuÃ©s de todo, si el
sistema debe retornar al equilibrio de largo plazo, los movimientos de al menos algunas de las variables
deben responder a la magnitud del desequilibrio.
La relaciÃ³n entre tasas de interÃ©s a largo y corto plazo muestra cÃ³mo se ajustan las variables hacia un
equilibrio a largo plazo. Si la brecha entre estas tasas es grande, la tasa a corto plazo eventualmente debe
aumentar en relaciÃ³n con la tasa a largo plazo, asÃ­ que las dinÃ¡micas a corto plazo se ven afectadas por
esta discrepancia con la relaciÃ³n a largo plazo. Por ello, es importante reducir la brecha, que se puede
hacer mediante (1) un aumento en la tasa a corto plazo y/o una disminuciÃ³n en la tasa a largo plazo, (2)
un aumento en la tasa a largo plazo, pero un aumento correspondientemente mayor en la tasa a corto
plazo, o (3) una disminuciÃ³n en la tasa a largo plazo, pero una disminuciÃ³n menor en la tasa a corto
plazo. Sin embargo, sin un modelo dinÃ¡mico no se puede determinar cual de las posibilidades ocurrirÃ¡.
El modelo dinÃ¡mico implÃ­cito en esta discusiÃ³n es uno de correcciÃ³n de errores. En un modelo de
correcciÃ³n de errores, las dinÃ¡micas a corto plazo de las variables en el sistema son influenciadas por la
desviaciÃ³n del equilibrio. Si asumimos que ambas tasas de interÃ©s son I(1), un modelo simple de
correcciÃ³n de errores que podrÃ­a aplicarse a la estructura temporal de las tasas de interÃ©s es:

Donde: ğœ€ğ‘ ğ‘¡ y ğœ€ğ¿ğ‘¡ son tÃ©rminos de perturbaciÃ³n de ruido blanco que pueden estar correlacionados, ğ‘Ÿğ¿ğ‘¡ y
ğ‘Ÿğ‘†ğ‘¡ son las tasas de interÃ©s a largo y corto plazo, ğ›¼ğ‘† ğ›¼ğ¿ y ğ›½ son parÃ¡metros.
En este caso, las tasas a corto y largo plazo cambiarÃ­an por los choques estocÃ¡sticos ğœ€ğ‘ ğ‘¡ y ğœ€ğ¿ğ‘¡ y por las
desviaciones de periodos anteriores. Si la desviaciÃ³n resultara positiva (de modo que ğ‘Ÿğ¿ğ‘¡âˆ’1 y ğ›½ğ‘Ÿğ‘†ğ‘¡âˆ’1 >
0), la tasa de interÃ©s a corto plazo aumentarÃ­a y la tasa a largo plazo disminuirÃ­a. El equilibrio a largo
plazo se alcanza cuando ğ‘Ÿğ¿ğ‘¡ = ğ›½ğ‘Ÿğ‘†ğ‘¡ , de modo que el cambio esperado en cada tasa es cero.
AquÃ­ se puede ver la relaciÃ³n entre los modelos de correcciÃ³n de errores y las variables cointegradas.
Primero, Î”ğ‘Ÿğ‘†ğ‘¡ es estacionario, de modo que el lado izquierdo de (6.9) es I(0). Para que (6.9) tenga
sentido, el lado derecho tambiÃ©n debe ser I(0). Dado que ğœ€ğ‘ ğ‘¡ es estacionario, se sigue que la combinaciÃ³n
lineal ğ‘Ÿğ¿ğ‘¡âˆ’1 - ğ›½ğ‘Ÿğ‘†ğ‘¡âˆ’1 tambiÃ©n debe ser estacionaria. (Recordemos el mayor orden de integraciÃ³n en una
igualdad) Por lo tanto, las dos tasas de interÃ©s deben ser cointegradas con el vector de cointegraciÃ³n
(1,âˆ’ğ›½). El mismo argumento se aplica a (6.10).
El punto esencial a tener en cuenta es que la representaciÃ³n de correcciÃ³n de errores requiere que las
dos variables estÃ©n cointegradas de orden ğ¶ğ¼(1,1). Este resultado no se altera si formulamos un modelo
mÃ¡s general introduciendo los cambios rezagados de cada tasa en ambas ecuaciones:

La inspecciÃ³n de (6.11) y (6.12) revela una notable similitud con los modelos VAR del capÃ­tulo anterior.
Este modelo de correcciÃ³n de errores bivariado es un VAR bivariado en primeras diferencias aumentado
por los tÃ©rminos de correcciÃ³n de errores ğ›¼ğ‘† (ğ‘Ÿğ¿ğ‘¡âˆ’1 âˆ’ ğ›½ğ‘Ÿğ‘†ğ‘¡âˆ’1 ) y âˆ’ğ›¼ğ¿ (ğ‘Ÿğ¿ğ‘¡âˆ’1 âˆ’ ğ›½ğ‘Ÿğ‘†ğ‘¡âˆ’1 ). Observa que ğ›¼ğ‘†
y ğ›¼ğ¿ tienen la interpretaciÃ³n de parÃ¡metros de velocidad de ajuste. Cuanto mayor sea ğ›¼ğ‘† , mayor serÃ¡
la respuesta de ğ‘Ÿğ‘†ğ‘¡ a la desviaciÃ³n del perÃ­odo anterior del equilibrio a largo plazo. En el extremo opuesto,
valores muy pequeÃ±os de ğœ¶ğ‘º implican que la tasa de interÃ©s a corto plazo no responde al error de
equilibrio del perÃ­odo anterior.
Para que la secuencia {Î”ğ‘Ÿğ‘†ğ‘¡ } no se vea afectada por la secuencia de tasas de interÃ©s a largo plazo, ğ›¼ğ‘† y
todos los coeficientes ğ‘12 (i) deben ser iguales a cero. Sin embargo, al menos uno de los tÃ©rminos de
velocidad de ajuste en (6.11) y (6.12) debe ser distinto de cero, ya que si tanto ğ›¼ğ‘† como ğ›¼ğ¿ son iguales

a cero, la relaciÃ³n de equilibrio a largo plazo no aparece y el modelo no es de correcciÃ³n de errores o
cointegraciÃ³n.
El resultado puede ser fÃ¡cilmente generalizado al modelo n-variable. Formalmente, el vector (n â‹… 1) de
variables I(1) ğ‘¥ğ‘¡ = (ğ‘¥1ğ‘¡ , ğ‘¥2ğ‘¡ , â€¦ , ğ‘¥ğ‘›ğ‘¡ )â€² tiene una representaciÃ³n de correcciÃ³n de errores si puede
expresarse en la forma:

donde ğœ‹0 es un vector de tÃ©rminos de intercepto de tamaÃ±o (n â‹… 1) con elementos ğœ‹ğ‘–0 ; ğœ‹ğ‘– representa las
matrices de coeficientes de tamaÃ±o (n â‹… n) con elementos ğœ‹ğ‘—ğ‘˜ (i); ğœ‹ representa una matriz con elementos
ğœ‹ğ‘—ğ‘˜ tales que uno o mÃ¡s de los ğœ‹ğ‘—ğ‘˜ â‰  0; ğœ€ğ‘¡ representa un vector de tamaÃ±o (n â‹… 1) con elementos ğœ€ğ‘–ğ‘¡ .
Observa que los tÃ©rminos de perturbaciÃ³n estÃ¡n dispuestos de modo que ğœ€ğ‘–ğ‘¡ puede estar correlacionado
con ğœ€ğ‘—ğ‘¡ . Supongamos que todas las variables en ğ‘¥ğ‘¡ son I(1). Resolviendo (6.13) para ğœ‹ğ‘¥ğ‘¡âˆ’1 obtenemos

Dado que cada expresiÃ³n del lado derecho es estacionaria, ğœ‹ğ‘¥ğ‘¡âˆ’1 tambiÃ©n debe ser estacionaria. Dado
que ğœ‹ solo contiene constantes, cada fila de ğœ‹ es un vector de cointegraciÃ³n de ğ‘¥ğ‘¡ .
La caracterÃ­stica clave en (6.13) es la presencia de la matriz ğœ‹. Hay dos puntos importantes a tener en
cuenta:
1. Si todos los elementos de ğœ‹ son iguales a cero, (6.13) es un VAR tradicional en primeras
diferencias. En tales circunstancias, no hay una representaciÃ³n de correcciÃ³n de errores ya que
Î”ğ‘¥ğ‘¡ no responde a la desviaciÃ³n del perÃ­odo anterior del equilibrio a largo plazo.
2. Si uno o mÃ¡s de los ğœ‹ğ‘—ğ‘˜ difieren de cero, Î”ğ‘¥ğ‘¡ responde a la desviaciÃ³n del perÃ­odo anterior del
equilibrio a largo plazo. Por lo tanto, estimar ğ‘¥ğ‘¡ como un VAR en primeras diferencias no es
apropiado si ğ‘¥ğ‘¡ tiene una representaciÃ³n de correcciÃ³n de errores. Asimismo, la omisiÃ³n de la
expresiÃ³n ğœ‹ğ‘¥ğ‘¡âˆ’1 conlleva un error de especificaciÃ³n si ğ‘¥ğ‘¡ tiene una representaciÃ³n de correcciÃ³n
de errores como en (6.13).
Una buena manera de examinar la relaciÃ³n entre cointegraciÃ³n y correcciÃ³n de errores es estudiar las
propiedades del modelo VAR simple:

Usando operadores de retardo, se puede escribir como:

Y en forma de matriz seria:

Usando la regla de Cramer o matriz inversa, podemos obtener las soluciones

Hemos convertido el sistema de primer orden de dos variables representado por (6.14) y (6.15) en dos
ecuaciones de diferencia de segundo orden univariadas, y ambas variables tienen la misma ecuaciÃ³n
caracterÃ­stica inversa (el denominador).

Al establecer (1 âˆ’ ğ‘11 ğ¿)(1 âˆ’ ğ‘22 ğ¿) âˆ’ ğ‘12 ğ‘21 ğ¿2 = 0 y resolver para L, obtenemos las dos raÃ­ces de
la ecuaciÃ³n caracterÃ­stica inversa. Para trabajar con las raÃ­ces caracterÃ­sticas (en lugar de las raÃ­ces
caracterÃ­sticas inversas), define ğœ† = 1âˆ•L y escribe la ecuaciÃ³n caracterÃ­stica como
(6.18)
Dado que las dos variables tienen la misma ecuaciÃ³n caracterÃ­stica, las raÃ­ces caracterÃ­sticas de (6.18)
determinan las trayectorias temporales de ambas variables. Las siguientes observaciones resumen las
trayectorias temporales de {ğ‘¦ğ‘¡ } y {ğ‘§ğ‘¡ }:
1. Si ambas raÃ­ces caracterÃ­sticas (ğœ†1 , ğœ†2 ) estÃ¡n dentro del cÃ­rculo unitario, (6.16) y (6.17) proporcionan
soluciones estables para {yt} y {zt}. Si t es suficientemente grande o si las condiciones iniciales son
tales que la soluciÃ³n homogÃ©nea es cero, la condiciÃ³n de estabilidad garantiza que las variables son
estacionarias, y al haber estacionariedad las variables no pueden ser cointegradas de orden (1,1)
2. Si alguna de las raÃ­ces estÃ¡ fuera del cÃ­rculo unitario, las soluciones son explosivas. Ninguna de las
variables es estacionaria en diferencias, por lo que no pueden ser CI(1,1). De la misma manera, si
ambas raÃ­ces caracterÃ­sticas son unidad, la segunda diferencia de cada variable serÃ¡ estacionaria.
Dado que cada una es I(2), las variables no pueden ser CI(1,1).
3. Como se puede ver en (6.14) y (6.15), si ğ‘12 = ğ‘21 = 0, la soluciÃ³n es trivial. Para que {yt} y
{zt} sean procesos de raÃ­z unitaria, es necesario que ğ‘11 = ğ‘22 = 1. Se sigue que ğœ†1 = ğœ†2 = 1 y
que las dos variables evolucionan sin ninguna relaciÃ³n de equilibrio a largo plazo; por lo tanto, las
variables no pueden ser cointegradas.
4. Para que {ğ‘¦ğ‘¡ } y {ğ‘§ğ‘¡ } sean CI(1,1), es necesario que una raÃ­z caracterÃ­stica sea igual a la unidad y la
otra sea menor que la unidad en valor absoluto. En este caso, cada variable tendrÃ¡ la misma tendencia
estocÃ¡stica y la primera diferencia de cada variable serÃ¡ estacionaria. Por ejemplo, si ğœ†1 = 1, (6.16)
tendrÃ¡ la forma:

SerÃ­a estacionario si |ğœ†2 | es menor a 1
Por lo tanto, para asegurar que las variables sean CI(1,1), debemos establecer que una de las raÃ­ces
caracterÃ­sticas sea igual a la unidad y la otra a un valor que sea menor que la unidad en valor absoluto.
Para que la raÃ­z mÃ¡s grande de las dos sea igual a la unidad, la fÃ³rmula cuadrÃ¡tica indica que:

DespuÃ©s de una simplificaciÃ³n, los coeficientes satisfacen:
(6.19)
Ahora considera la segunda raÃ­z caracterÃ­stica. Dado que ğ‘12 y/o ğ‘21 deben diferir de cero si las variables
estÃ¡n cointegradas, la condiciÃ³n |ğœ†2 | < 1 requiere
(6.20) y

(6.21)

Las ecuaciones (6.19), (6.20) y (6.21) son restricciones que debemos imponer en los coeficientes de
(6.14) y (6.15) si queremos asegurar que las variables estÃ¡n cointegradas de orden (1, 1). Para entender
cÃ³mo estas restricciones de coeficientes afectan la naturaleza de la soluciÃ³n, escribimos (6.14) y (6.15)
como:
(6.22) o

Estas ecuaciones forman un modelo de correcciÃ³n de errores. Si tanto ğ‘12 como ğ‘21 difieren de cero,
podemos normalizar el vector de cointegraciÃ³n con respecto a cualquiera de las variables. Normalizando
con respecto a ğ‘¦ğ‘¡ , obtenemos:

Podemos ver que ğ‘¦ğ‘¡ y ğ‘§ğ‘¡ cambian en respuesta a la desviaciÃ³n del perÃ­odo anterior del equilibrio a largo
plazo ğ‘¦ğ‘¡âˆ’1 âˆ’ ğ›½ğ‘§ğ‘¡âˆ’1 . Si ğ‘¦ğ‘¡âˆ’1 = ğ›½ğ‘§ğ‘¡âˆ’1 entonces, ğ‘¦ğ‘¡ y ğ‘§ğ‘¡ cambian solo en respuesta a los choques ğœ€ğ‘¦ğ‘¡ y
ğœ€ğ‘§ğ‘¡ . AdemÃ¡s, si ğ›¼ğ‘¦ < 0 y ğ›¼ğ‘§ > 0, ğ‘¦ğ‘¡ disminuye y ğ‘§ğ‘¡ aumenta en respuesta a una desviaciÃ³n positiva del
equilibrio a largo plazo. TambiÃ©n, las condiciones (6.20) y (6.21) aseguran que ğ›½ â‰  0 y que al menos
uno de los parÃ¡metros de velocidad de ajuste (es decir, ğ›¼ğ‘¦ y ğ›¼ğ‘§ ) no es igual a cero. La secuencia {ğ‘§ğ‘¡ }
realiza toda la correcciÃ³n para eliminar cualquier desviaciÃ³n del equilibrio a largo plazo. Dado que {ğ‘¦ğ‘¡ }
no realiza ninguna correcciÃ³n de errores, se dice que {ğ‘¦ğ‘¡ } es dÃ©bilmente exÃ³gena.
Para resaltar algunas de las implicaciones importantes de este modelo simple, hemos mostrado lo
siguiente:
1. Las restricciones necesarias para garantizar que las variables sean CI(1, 1) garantizan que exista un
modelo de correcciÃ³n de errores. En nuestro ejemplo, tanto {ğ‘¦ğ‘¡ } como {ğ‘§ğ‘¡ } son procesos de raÃ­z
unitaria pero la combinaciÃ³n lineal ğ‘¦ğ‘¡ âˆ’ ğ›½ğ‘§ğ‘¡ es estacionaria; el vector de cointegraciÃ³n normalizado
es [1, âˆ’(1 âˆ’ ğ‘22 )/ğ‘21 ]. Las variables tienen una representaciÃ³n de correcciÃ³n de errores con
coeficientes de velocidad de ajuste ğ›¼ğ‘¦ = âˆ’ğ‘12 ğ‘ 21 âˆ• (1 âˆ’ ğ‘22 ) y ğ›¼ğ‘§ = ğ‘21 .
TambiÃ©n se demostrÃ³ que un modelo de correcciÃ³n de errores para variables I(1) implica
necesariamente cointegraciÃ³n. Este hallazgo ilustra el teorema de representaciÃ³n de Granger que
establece que para cualquier conjunto de variables I(1), la correcciÃ³n de errores y la cointegraciÃ³n
son representaciones equivalentes.
2. La cointegraciÃ³n requiere restricciones en los coeficientes de un modelo VAR. Es importante darse
cuenta de que un sistema cointegrado puede ser visto como una forma restringida de un modelo
VAR general.
(6.25)
Claramente, estimar un VAR de variables cointegradas solo con primeras diferencias no es apropiado.
Eliminar la expresiÃ³n ğœ‹xtâˆ’1 de la estimaciÃ³n de (6.25) suprimirÃ­a la parte de correcciÃ³n de errores del
modelo. AdemÃ¡s, es esencial tener en cuenta que las filas de ğœ‹ no son linealmente independientes si las
variables estÃ¡n cointegradas. Al multiplicar cada elemento en la fila 1 por âˆ’(1 âˆ’ a22)âˆ•a12, se obtiene el
elemento correspondiente en la fila 2, haciendo que el determinante de ğœ‹ sea igual a cero, lo que indica
que yt y zt tienen una representaciÃ³n de correcciÃ³n de errores segÃºn (6.23) y (6.24).
Este ejemplo de dos variables ilustra la importancia del trabajo de Johansen (1988) y Stock y Watson
(1988), quienes mostraron que el rango de ğœ‹ puede utilizarse para determinar si dos variables {yt} y
{zt} estÃ¡n cointegradas. Si el determinante de ğœ‹ es cero y la mayor raÃ­z caracterÃ­stica es igual a la unidad
(ğœ†1 = 1), entonces ğœ‹ tiene un rango igual a la unidad. Por otro lado, si el rango de ğœ‹ es cero, significarÃ­a
que ğ‘11 = 1, ğ‘22 = 1 y ğ‘12 = ğ‘21 = 0, lo que implicarÃ­a que el VAR representado por (6.14) y (6.15)
serÃ­a solo una secuencia de primeras diferencias sin vector de cointegraciÃ³n.
En un sistema cointegrado, ambas variables responderÃ¡n a una desviaciÃ³n del equilibrio a largo plazo.
Sin embargo, puede haber casos donde uno de los parÃ¡metros de velocidad de ajuste sea cero, lo que
significa que una de las variables no responde a la discrepancia del equilibrio a largo plazo. Esto se
conoce como una variable dÃ©bilmente exÃ³gena. En tales casos, se puede estimar un modelo
economÃ©trico para la otra variable sin tener en cuenta la primera.
AdemÃ¡s, es necesario reconsiderar la causalidad de Granger en un sistema cointegrado. Si una variable
no responde a los rezagos de la otra en su ecuaciÃ³n de diferencias, entonces la segunda variable se

considera dÃ©bilmente exÃ³gena y no es causada por Granger por la primera. Esto tiene implicaciones
importantes en el anÃ¡lisis causal en modelos cointegrados.
El caso de n variables
Poco cambia en el caso de n variables. La relaciÃ³n entre cointegraciÃ³n, correcciÃ³n de errores y el rango
de la matriz ğœ‹ es invariable al agregar variables adicionales al sistema. La caracterÃ­stica interesante
introducida en el caso de n variables es la posibilidad de mÃºltiples vectores de cointegraciÃ³n. Ahora
consideremos una versiÃ³n mÃ¡s general de (6.25):
(6.26)

Restando ğ‘¥ğ‘¡âˆ’1 de ambos lados de (6.26) y dejando que I sea una matriz identidad de tamaÃ±o (n â‹… n),
obtenemos:
(6.27)

donde ğœ‹ es la matriz de tamaÃ±o (n â‹… n) dada por âˆ’(ğ¼ âˆ’ ğ´1) y ğœ‹ğ‘–ğ‘— denota el elemento en la fila i y la
columna j de ğœ‹. Como se puede observar, (6.27) es un caso especial de (6.13) donde todos los ğœ‹ğ‘– son
iguales a cero. La cuestiÃ³n crucial para la cointegraciÃ³n sigue siendo el rango de la matriz ğœ‹. La Ãºnica
forma de que el rango de una matriz sea cero es que cada uno de sus elementos sea cero. Por lo tanto, si
el rango de ğœ‹ es cero, cada elemento de ğœ‹ debe ser cero, lo que implica que no hay vectores de
cointegraciÃ³n. En este caso, (6.27) es equivalente a un VAR de n variables en primeras diferencias:
ğ›¥ğ‘¥ğ‘¡ = ğœ€ğ‘¡
AquÃ­, cada ğ›¥ğ‘¥ğ‘–ğ‘¡ = ğœ€ğ‘–ğ‘¡ , por lo que todas las secuencias {ğ‘¥ğ‘–ğ‘¡ } son procesos de raÃ­z unitaria y no hay
ninguna combinaciÃ³n lineal de las variables que sea estacionaria.
En el otro extremo, supongamos que ğœ‹ tiene rango completo. La soluciÃ³n a largo plazo de (6.27) estÃ¡
dada por las n ecuaciones independientes:
(6.28)

Cada una de estas ecuaciones n es una restricciÃ³n independiente en la soluciÃ³n a largo plazo de las
variables; las n variables en el sistema enfrentan n restricciones a largo plazo. En este caso, cada una de
las n variables contenidas en el vector ğ‘¥ğ‘¡ debe ser estacionaria con los valores a largo plazo dados por
la soluciÃ³n a 6.28. Las variables no pueden ser CI(1,1) ya que todas son estacionarias. En casos
intermedios, en los que el rango de ğœ‹ es igual a ğ‘Ÿ < ğ‘›, hay ğ‘Ÿ vectores de cointegraciÃ³n. Con ğ‘Ÿ
ecuaciones independientes y ğ‘› variables, hay ğ‘› âˆ’ ğ‘Ÿ tendencias estocÃ¡sticas en el sistema. Si ğ‘Ÿ = 1,
hay un Ãºnico vector de cointegraciÃ³n dado por cualquier fila de la matriz ğœ‹. Cada secuencia {ğ›¥ğ‘¥ğ‘–ğ‘¡ } se
puede escribir en forma de correcciÃ³n de errores.
IMPORTANTE: El punto principal aquÃ­ es que hay tres formas importantes de probar la cointegraciÃ³n.
La metodologÃ­a de Engleâ€“Granger busca determinar si los residuos de la relaciÃ³n de equilibrio son
estacionarios. La metodologÃ­a de Johansen (1988) determina el rango de ğœ‹ y el mÃ©todo de correcciÃ³n
de errores examina los coeficientes de velocidad de ajuste.

4. TESTING FOR COINTEGRATION: THE ENGLEâ€“GRANGER METHODOLOGY
Para explicar el procedimiento de prueba de Engle-Granger, comencemos con el tipo de problema que
probablemente se encuentre en estudios aplicados. Supongamos que se cree que dos variables, digamos
ğ‘¦ğ‘¡ y ğ‘§ğ‘¡ , estÃ¡n integradas de orden 1 y queremos determinar si existe una relaciÃ³n de equilibrio entre las
dos. Engle y Granger (1987) proponen un procedimiento de cuatro pasos para determinar si dos variables
I(1) estÃ¡n cointegradas de orden CI(1, 1).
PASO 1: Preprueba las variables para su orden de integraciÃ³n.
Este paso es fundamental para establecer la base de la prueba de cointegraciÃ³n. La cointegraciÃ³n implica
que dos o mÃ¡s series temporales, aunque no sean estacionarias individualmente, pueden tener una
relaciÃ³n de equilibrio a largo plazo. Para verificar si las variables estÃ¡n cointegradas, primero debemos
determinar su orden de integraciÃ³n. Esto se hace a travÃ©s de pruebas estadÃ­sticas como la prueba
aumentada de Dickey-Fuller, que examina la presencia de raÃ­ces unitarias en las series de tiempo. Si
ambas variables son estacionarias, no hay necesidad de proceder, ya que los mÃ©todos estÃ¡ndar de series
temporales pueden aplicarse. Sin embargo, si las variables tienen diferentes Ã³rdenes de integraciÃ³n, esto
sugiere que no estÃ¡n cointegradas.
PASO 2: Estima la relaciÃ³n de equilibrio a largo plazo.
El Paso 2 implica estimar la relaciÃ³n de equilibrio a largo plazo entre las variables. DespuÃ©s de verificar
en el Paso 1 que tanto {ğ‘¦ğ‘¡ } como {ğ‘§ğ‘¡ } son I(1), procedemos a modelar su relaciÃ³n en tÃ©rminos de una
ecuaciÃ³n de regresiÃ³n simple:
ğ‘¦ğ‘¡ = ğ›½0 + ğ›½1 ğ‘§ğ‘¡ + ğ‘’ğ‘¡
Si las variables estÃ¡n cointegradas, una regresiÃ³n de MÃ­nimos Cuadrados Ordinarios (OLS) proporciona
un estimador "super-consistente" de los parÃ¡metros cointegrados ğ›½0 y ğ›½1 . Este mÃ©todo es
particularmente poderoso porque, como demostrÃ³ Stock (1987), las estimaciones OLS de ğ›½0 y ğ›½1
convergen mÃ¡s rÃ¡pidamente que en modelos OLS que utilizan variables
estacionarias.
Para entender mejor la idea detrÃ¡s de este enfoque, podemos referirnos a
un diagrama de dispersiÃ³n como el mostrado en la Figura 6.1. AquÃ­, se
puede observar que el efecto de la tendencia comÃºn domina sobre el
componente estacionario; ambas variables parecen subir y bajar en
tÃ¡ndem. Esto sugiere una fuerte relaciÃ³n lineal, como lo muestra la lÃ­nea
de regresiÃ³n trazada en la figura.

Para verificar si las variables estÃ¡n realmente cointegradas, calculamos la secuencia residual de esta
ecuaciÃ³n, denotada como Îµt (sombrerito). Esta secuencia contiene los valores estimados de las
desviaciones de la relaciÃ³n de largo plazo. Si estas desviaciones se encuentran estacionarias, lo cual se
puede determinar a travÃ©s de una prueba de Dickey-Fuller sobre estos residuos, entonces concluimos
que las secuencias {yt} y {zt} estÃ¡n cointegradas de orden (1, 1).
ğ›¥ğ‘’Ì‚ğ‘¡ = ğ‘1 ğ‘’Ì‚ğ‘¡âˆ’1 + ğœ€ğ‘¡
En este caso, si no podemos rechazar la hipÃ³tesis nula de ğ‘1 = 0, podemos afirmar que la serie tiene
una raÃ­z unitaria y por consecuencia se concluye que {ğ‘¦ğ‘¡ } y {ğ‘§ğ‘¡ } no estÃ¡n cointegradas. (Es necesario
que los errores estimados sean estacionarios)
En la mayorÃ­a de los estudios aplicados, no es posible utilizar directamente las tablas de Dickey-Fuller.
Esto se debe a que la secuencia ğ‘’t(sombrerito) se genera a partir de una ecuaciÃ³n de regresiÃ³n; el
investigador no conoce el error real ğ‘’ğ‘¡ , solo la estimaciÃ³n del error ğ‘’ğ‘¡ (sombrerito). La metodologÃ­a
utilizada para ajustar la regresiÃ³n en (6.30) selecciona valores de ğ›½0 y ğ›½1 que minimizan la suma de los
residuos al cuadrado. Por lo tanto, para realizar pruebas sobre la estacionariedad de los residuos,
necesitamos tÃ©cnicas adecuadas que tengan en cuenta esta estructura de la regresiÃ³n.

PASO 3: Estima el modelo de correcciÃ³n de errores.
El Paso 3 implica estimar el modelo de correcciÃ³n de errores cuando las variables estÃ¡n cointegradas, lo
que significa que se rechaza la hipÃ³tesis nula de no cointegraciÃ³n. Los residuos de la regresiÃ³n de
equilibrio se utilizan para estimar este modelo de correcciÃ³n de errores. Si {ğ‘¦ğ‘¡ } y {ğ‘§ğ‘¡ } son CI(1, 1),
entonces las variables tienen la forma de correcciÃ³n de errores:

donde ğ›½1 es el parÃ¡metro del vector cointegrado dado por (6.30), ğœ€yt y ğœ€zt son perturbaciones de ruido
blanco (que pueden estar correlacionadas entre sÃ­), y ğ›¼1 , ğ›¼2 , ğ›¼ğ‘¦ , ğ›¼ğ‘§ , ğ›¼11 (ğ‘–), ğ›¼12 (ğ‘–), ğ›¼21 (ğ‘–), ğ›¼22 (ğ‘–) son
todos parÃ¡metros.
Engle y Granger (1987) proponen una manera ingeniosa de evitar las restricciones entre ecuaciones
involucradas en la estimaciÃ³n directa de (6.33) y (6.34). La magnitud del residuo ğ‘’Ì‚ğ‘¡âˆ’1 es la desviaciÃ³n
del equilibrio a largo plazo en el perÃ­odo t âˆ’ 1. Por lo tanto, es posible utilizar los residuos guardados
{ğ‘’Ì‚ğ‘¡âˆ’1 } obtenidos en el Paso 2 como una estimaciÃ³n de la expresiÃ³n ğ‘¦ğ‘¡âˆ’1 âˆ’ Î²1 ztâˆ’1 en (6.33) y (6.34).
AsÃ­, utilizando los residuos guardados de la estimaciÃ³n de la relaciÃ³n de equilibrio a largo plazo, se
estima el modelo de correcciÃ³n de errores como:

AdemÃ¡s del tÃ©rmino de correcciÃ³n de errores eÌ‚tâˆ’1, (6.35) y (6.36) constituyen un VAR en primeras
diferencias.. Todos los procedimientos desarrollados para estimar un VAR se aplican al sistema
representado por las ecuaciones de correcciÃ³n de errores. Es importante destacar:
1. La estimaciÃ³n por OLS es una estrategia eficiente ya que cada ecuaciÃ³n contiene el mismo
conjunto de regresores.
2. Dado que todos los tÃ©rminos en (6.35) y (6.36) son estacionarios [es decir, ğ›¥ğ‘¦ğ‘¡ y sus rezagos,
ğ›¥ğ‘§ğ‘¡ y sus rezagos, y ğ‘’Ì‚ğ‘¡âˆ’1 son I(0)], las estadÃ­sticas de prueba utilizadas en el anÃ¡lisis VAR
tradicional son apropiadas para (6.35) y (6.36). Por ejemplo, las longitudes de rezago pueden
determinarse utilizando una prueba ğœ’2, y la restricciÃ³n de que todos los ğ›¼ğ‘—ğ‘˜ (ğ‘–) = 0 puede
verificarse utilizando una prueba F. Si hay un solo vector cointegrado, las restricciones
relacionadas con ğ›¼y o ğ›¼z pueden realizarse utilizando una prueba t.
PASO 4: EvalÃºa la adecuaciÃ³n del modelo.
El Paso 4 implica evaluar la adecuaciÃ³n del modelo mediante varios procedimientos:
1. Se deben realizar controles diagnÃ³sticos para determinar si los residuos de las ecuaciones de
correcciÃ³n de errores se aproximan al ruido blanco. Si los residuos estÃ¡n correlacionados en
serie, las longitudes de rezago pueden ser demasiado cortas, por lo que se debe reestimar el
modelo utilizando longitudes de rezago que produzcan errores serialmente no correlacionados.
Es posible que se necesite permitir rezagos mÃ¡s largos de algunas variables que de otras. Si es
asÃ­, se puede ganar eficiencia estimando el VAR cercano utilizando el mÃ©todo de regresiones
aparentemente no relacionadas (SUR). Los ejercicios de pronÃ³stico fuera de la muestra
tambiÃ©n son Ãºtiles para seleccionar entre modelos alternativos.
2. Los coeficientes de velocidad de ajuste ğ›¼ğ‘¦ y ğ›¼ğ‘§ son de particular interÃ©s ya que tienen
importantes implicaciones para la dinÃ¡mica del sistema. Como se muestra en la SecciÃ³n 3, los
valores de ğ›¼ğ‘¦ y ğ›¼ğ‘§ estÃ¡n directamente relacionados con las raÃ­ces caracterÃ­sticas del sistema de
ecuaciones de diferencia. La convergencia directa implica que ğ›¼ğ‘¦ sea negativo y ğ›¼ğ‘§ sea positivo.

Si nos centramos en (6.36), es claro que para cualquier valor dado de ğ‘’Ì‚ğ‘¡âˆ’1 , un valor grande de
ğ›¼ğ‘§ estÃ¡ asociado con un valor grande de ğ›¥ğ‘§ğ‘¡ . Si ğ›¼ğ‘§ es cero, el cambio en ğ‘§ğ‘¡ no responde en
absoluto a la desviaciÃ³n del equilibrio a largo plazo en (ğ‘¡ âˆ’ 1). Si ğ›¼ğ‘§ es cero y si todos los
ğ›¼21 (ğ‘–) = 0, entonces se puede decir que {ğ›¥ğ‘¦ğ‘¡ } no causa Granger a {ğ›¥ğ‘§ğ‘¡ }. Sabemos que ğ›¼ğ‘¦ y/o
ğ›¼ğ‘§ deben ser significativamente diferentes de cero si las variables estÃ¡n cointegradas. DespuÃ©s
de todo, si tanto ğ›¼ğ‘¦ como ğ›¼ğ‘§ son cero, no hay correcciÃ³n de error y (6.35) y (6.36) no
comprenden mÃ¡s que un VAR en primeras diferencias. AdemÃ¡s, los valores absolutos de estos
coeficientes de velocidad de ajuste no deben ser demasiado grandes. Las estimaciones puntuales
deben implicar que ğ›¥ğ‘¦ğ‘¡ y ğ›¥ğ‘§ğ‘¡ convergen a la relaciÃ³n de equilibrio a largo plazo.
3. Al igual que en un anÃ¡lisis VAR tradicional, Lutkepohl y Reimers (1992) muestran que el
anÃ¡lisis de innovaciÃ³n (es decir, respuestas a impulsos y anÃ¡lisis de descomposiciÃ³n de varianza)
puede utilizarse para obtener informaciÃ³n sobre las interacciones entre las variables. Como
cuestiÃ³n prÃ¡ctica, las dos innovaciones ğœ€ğ‘¦ğ‘¡ y ğœ€ğ‘§ğ‘¡ pueden estar correlacionadas simultÃ¡neamente
si ğ‘¦ğ‘¡ tiene un efecto simultÃ¡neo en ğ‘§ğ‘¡ y/o si ğ‘§ğ‘¡ tiene un efecto simultÃ¡neo en ğ‘¦ğ‘¡ . Al obtener
funciones de respuesta a impulsos y descomposiciones de varianza, algÃºn mÃ©todo, como una
descomposiciÃ³n de Choleski, debe usarse para ortogonalizar las innovaciones.
La forma de las funciones de respuesta a impulsos y los resultados de las descomposiciones de varianza
pueden indicar si las respuestas dinÃ¡micas de las variables se ajustan a la teorÃ­a. Dado que todas las
variables en (6.35) y (6.36) son I(0), las respuestas a impulsos de Î”yt y Î”zt deben converger a cero. Se
deben de revisar los resultados de cada paso si se obtiene una funciÃ³n de respuesta a impulsos que no
decae o es explosiva
AdemÃ¡s, es importante mencionar que es muy tentador usar las t-estadÃ­sticas para realizar pruebas de
significancia en el vector cointegrado. Sin embargo, se debe evitar esta tentaciÃ³n ya que, en general, los
coeficientes no tienen una distribuciÃ³n t asintÃ³tica.
5. ILLUSTRATING THE ENGLE-GRANGER METHODOLOGY

El proceso comienza generando series de datos simuladas {yt}, {zt} y {wt}, cada una construida como
la suma de un componente de tendencia estocÃ¡stica y un componente irregular autorregresivo. Esto se
logra utilizando secuencias de nÃºmeros aleatorios para representar los componentes estocÃ¡sticos y los
componentes irregulares de cada serie.
DespuÃ©s de construir estas series, se presta atenciÃ³n a si las variables estÃ¡n integradas de orden 1 o si
tienen una raÃ­z unitaria a travÃ©s de pruebas de raÃ­z unitaria y diferentes longitudes de rezago. Luego de
establecer la cointegraciÃ³n entre las variables, se estima la relaciÃ³n de equilibrio a largo plazo con la
metodologÃ­a de Engle-Granger, estimando una regresiÃ³n de cointegraciÃ³n que representa la relaciÃ³n de
largo plazo entre las variables:

DespuÃ©s de estimar la relaciÃ³n de equilibrio, se verifica si los residuos de esta regresiÃ³n son estacionarios
con pruebas de raÃ­z unitaria, lo que es crucial para confirmar la validez del modelo. Una vez confirmada
la cointegraciÃ³n y la estacionariedad de los residuos, se estima el modelo de correcciÃ³n de errores. Este
modelo tiene en cuenta tanto los efectos de corto plazo como los de largo plazo en la relaciÃ³n entre las
variables, y se estima utilizando una metodologÃ­a de ecuaciones en diferencias.
El modelo de correcciÃ³n de errores se presenta como sigue:

donde ğ‘’ğ‘¤ğ‘¡âˆ’1 = ğ‘¤ğ‘¡âˆ’1 + 0.0852 âˆ’ 0.9901ğ‘¦ğ‘¡âˆ’1 âˆ’ 0.9535ğ‘§ğ‘¡âˆ’1 es el valor rezagado del residuo de la
relaciÃ³n de equilibrio utilizando ğ‘¤ğ‘¡ como la variable dependiente.
Finalmente, se llevan a cabo pruebas de diagnÃ³stico para evaluar la adecuaciÃ³n del modelo estimado.
Estas pruebas incluyen la evaluaciÃ³n de la autocorrelaciÃ³n de los residuos, la determinaciÃ³n de la
presencia de efectos de corto plazo y la verificaciÃ³n de si el modelo captura adecuadamente la dinÃ¡mica
de las variables a lo largo del tiempo.
El procedimiento para variables con integraciÃ³n de orden 2 â€“ I(2)
La multicointegraciÃ³n se refiere a una situaciÃ³n en la que una combinaciÃ³n lineal de variables I(2) e I(1)
estÃ¡ integrada de orden cero. Esto significa que una combinaciÃ³n lineal de variables I(2) puede estar
cointegrada con una variable I(1), lo que implica una relaciÃ³n de equilibrio a largo plazo entre ellas.
Por ejemplo, supongamos que ğ‘¥1ğ‘¡ y ğ‘¥2ğ‘¡ son variables I(2) y que ğ‘§ğ‘¡ es I(1). Es posible que una
combinaciÃ³n lineal de ğ‘¥1ğ‘¡ y ğ‘¥2ğ‘¡ sea I(1) y que esta combinaciÃ³n estÃ© cointegrada con ğ‘§ğ‘¡ . Esto se
representa mediante una relaciÃ³n de equilibrio a largo plazo de la forma:
Sin embargo, una especificaciÃ³n mÃ¡s rica permite una relaciÃ³n estacionaria:

Esto permite que la combinaciÃ³n lineal ğ‘¥1ğ‘¡ âˆ’ ğ›½2 ğ‘¥2ğ‘¡ sea I(1) y cointegrada con otras variables I(1) en el
sistema: ğ›¥ğ‘¥2ğ‘¡ y ğ‘§ğ‘¡ . Es importante destacar que ğ›½2 no puede ser cero, ya que si lo fuera, la variable I(2)
ğ‘¥1ğ‘¡ no podrÃ­a estar cointegrada con las variables I(1).
Para verificar la multicointegraciÃ³n, se puede utilizar un procedimiento de dos pasos. Primero, se busca
una relaciÃ³n de cointegraciÃ³n entre las variables I(2), y luego se utiliza esta relaciÃ³n para verificar una
posible cointegraciÃ³n con las variables I(1) restantes. Sin embargo, este procedimiento solo es efectivo
si se conoce el vector cointegrante para el primer paso.
Para realizar este anÃ¡lisis, se estima una ecuaciÃ³n de regresiÃ³n con tÃ©rminos deterministas que pueden
incluir una tendencia cuadrÃ¡tica en el tiempo.

Como la clave es evaluar la estacionalidad de la serie {et}, se estima la siguiente ecuaciÃ³n:

Si es posible rechazar la hipÃ³tesis nula ğœŒ = 0, entonces se puede concluir que hay multicointegraciÃ³n.
AdemÃ¡s del tamaÃ±o de la muestra, los valores crÃ­ticos de la estadÃ­stica t para la hipÃ³tesis nula ğœŒ = 0
dependen del nÃºmero de regresores I(2) (ğ‘š2 = 1 ğ‘œ 2), el nÃºmero de regresores I(1) (ğ‘š1 = 0 ğ‘ 4) y
la forma de los regresores deterministas.

Tomemos como ejemplo las ecuaciones de demanda de dinero en el Reino Unido durante el perÃ­odo
de muestra de 1963Q1 a 1989Q2, estimadas por Haldrup (1994):

La preprueba de las variables indicÃ³ que ğ‘šğ‘¡ (medida por el logaritmo de M1) y ğ‘ğ‘¡ (el logaritmo del
deflactor implÃ­cito de precios) eran I(2), mientras que ğ‘¦ğ‘¡ (el logaritmo del gasto final total) y ğ‘Ÿğ‘¡ (una
medida de la diferencia de tasas de interÃ©s) eran I(1). La presencia de ğ›¥ğ‘ğ‘¡ en la funciÃ³n de demanda de
dinero se explica por la dependencia de la demanda de dinero de la tasa de inflaciÃ³n. Dado un total de
105 observaciones, un regresor I(2) (entonces m2 = 1) y tres regresores I(1), los valores crÃ­ticos al 5%
para modelos sin y con tendencia lineal son -4.56 y -4.91, respectivamente. Utilizando los residuos de
las ecuaciones de demanda de dinero dadas por (6.41) y (6.42), Haldrup encontrÃ³ que las estadÃ­sticas t
para la hipÃ³tesis nula ğœŒ = 0 fueron -2.35 y -2.66, respectivamente. Por lo tanto, es posible concluir que
las dos regresiones son espurias (es decir, no es posible rechazar la hipÃ³tesis nula de no
multicointegraciÃ³n).
A pesar del fracaso de la multicointegraciÃ³n, Haldrup continÃºa experimentando con varias estimaciones
del mecanismo de correcciÃ³n de errores. Un modelo interesante es:

donde los regresores estacionarios pueden incluir valores rezagados de ğ›¥2 ğ‘šğ‘¡ , asÃ­ como valores actuales
y rezagados de ğ›¥2 ğ‘ğ‘¡ , ğ›¥ğ‘¦ğ‘¡ , ğ›¥ğ‘ğ‘¡ y ğ›¥ğ‘Ÿğ‘¡ . La estimaciÃ³n puntual sugiere que ğ›¥2 ğ‘šğ‘¡ disminuirÃ¡ en respuesta
a una discrepancia positiva de la relaciÃ³n de equilibrio a largo plazo. La estadÃ­stica t de âˆ’0.04/0.02 =
2 sugiere que el efecto es significativo justo al nivel del 5%.
6. COINTEGRATION AND PURCHASING POWER PARITY
ğ‘’ğ‘¡ representa el logaritmo del tipo de cambio extranjero, ğ‘ğ‘¡âˆ— representa el logaritmo del nivel de precios
extranjero y ğ‘ğ‘¡ representa el logaritmo del nivel de precios domÃ©sticos. La PPP a largo plazo requieren
que ğ‘’ğ‘¡ + ğ‘ğ‘¡âˆ— âˆ’ ğ‘ğ‘¡ sea estacionario. La cointegraciÃ³n ofrece un mÃ©todo alternativo para comprobar la
teorÃ­a; si la PPP se mantiene, la secuencia formada por ğ‘’ğ‘¡ + ğ‘ğ‘¡âˆ— deberÃ­a estar cointegrada con la secuencia
ğ‘ğ‘¡ .
Denomina al valor en dÃ³lares del nivel de precios extranjero ğ‘“ğ‘¡ = ğ‘’ğ‘¡ + ğ‘ğ‘¡ . La PPP a largo plazo sostiene
que existe una combinaciÃ³n lineal de la forma ğ‘“ğ‘¡ = ğ›½0 + ğ›½1 ğ‘ğ‘¡ + ğ‘¢ğ‘¡ tal que ğ‘¢ğ‘¡ es estacionario y el vector
de cointegraciÃ³n es tal que ğ›½1 = 1.
El siguiente paso fue estimar la relaciÃ³n de equilibrio a largo plazo mediante la regresiÃ³n de cada
ğ‘“ğ‘¡ = ğ‘’ğ‘¡ + ğ‘ğ‘“ğ‘¡ en ğ‘ğ‘¡ de manera que: ğ‘“ğ‘¡ = ğ›½0 + ğ›½1 ğ‘ğ‘¡ + ğ‘¢ğ‘¡
(6.43)
La PPP absoluta establece que ğ‘“ğ‘¡ = ğ‘ğ‘¡ , requiriendo ğ›½0 = 0 y ğ›½1 = 1. El intercepto ğ›½0 es coherente con
la PPP relativa. Sin embargo, se recomienda incluir un tÃ©rmino de intercepto en la regresiÃ³n de
equilibrio, y las simulaciones de Monte Carlo de Engle y Granger (1987) confirman esto.
Los valores estimados de ğ›½1 y sus errores estÃ¡ndar
asociados se reportan en la Tabla 6.4. Cinco de los seis
valores se estiman bastante por debajo de la unidad.
No se deben de sobreestimar los resultados. O sea, no
se debe concluir que cada valor de ğ›½1 es
significativamente diferente de la unidad solo porque
(1 âˆ’ ğ›½1 ) excede dos o tres desviaciones estÃ¡ndar. Las
suposiciones de este tipo de prueba t no son aplicables
porque no se asume que ğ‘ğ‘¡ es la variable exÃ³gena y
ğ‘“ğ‘¡ es la dependiente, o que ğ‘¢ğ‘¡ es ruido blanco.

Se revisaron las raÃ­ces unitarias de los residuos de cada ecuaciÃ³n de regresiÃ³n ğ‘¢ğ‘¡ . Se estima las siguientes
2 ecuaciones utilizando los residuos de cada relaciÃ³n de equilibrio a largo plazo:
âˆ†ğ‘¢ğ‘¡ = ğ‘1 ğ‘¢Ì‚ğ‘¡âˆ’1 + ğœ€ğ‘¡

(6.44)

âˆ†ğ‘¢ğ‘¡ = ğ‘1 ğ‘¢Ì‚ğ‘¡âˆ’1 + âˆ‘ ğ‘1 âˆ†ğ‘¢Ì‚ğ‘¡âˆ’1 + ğœ€ğ‘¡

(6.45)

ğ‘

ğ‘–=1

La Tabla 6.5 informa los valores estimados de ğ‘1 a partir de
(6.44) y (6.45) usando un rezago de cuatro perÃ­odos. Es
importante destacar que la no rechazaciÃ³n de la hipÃ³tesis
nula ğ‘1 = 0 significa que no podemos descartar la hipÃ³tesis
nula de no cointegraciÃ³n. Alternativamente, si âˆ’2 < ğ‘1 < 0,
es posible concluir que la secuencia ğ‘¢ğ‘¡ no tiene una raÃ­z
unitaria y que las secuencias ğ‘“ğ‘¡ y ğ‘ğ‘¡ estÃ¡n cointegradas.
Bajo la hipÃ³tesis nula ğ‘1 = 0, los valores crÃ­ticos para el
estadÃ­stico t dependen del tamaÃ±o de la muestra. Conforme
los resultados de la tabla 6.5, solo para JapÃ³n durante el
perÃ­odo de tipo de cambio fijo, se puede rechazar la hipÃ³tesis
nula de no cointegraciÃ³n. A un nivel de significancia del 5%,
el valor crÃ­tico de t es -3.398 para dos variables y T=100. Por
lo tanto, a este nivel de significancia, podemos rechazar la
hipÃ³tesis nula de no cointegraciÃ³n (aceptamos que las variables estÃ¡n cointegradas) y encontramos a
favor de la PPA. Para los demÃ¡s paÃ­ses en cada perÃ­odo de tiempo, no podemos rechazar la hipÃ³tesis
nula de no cointegraciÃ³n y debemos concluir que la PPA fallÃ³ en general.
El tercer paso en la metodologÃ­a implica la estimaciÃ³n del modelo de correcciÃ³n de errores. Solo el
modelo JapÃ³n/EE. UU. requiere estimaciÃ³n (mantienen la cointegraciÃ³n). Los modelos de correcciÃ³n de
errores finales para los niveles de precios de JapÃ³n y EE. UU. durante el perÃ­odo de 1960-1971 fueron
estimados como:

Los resultados en (6.46) y (6.47) muestran una convergencia directa hacia el equilibrio a largo plazo.
Por ejemplo, si hay una desviaciÃ³n de una unidad de la PPP a largo plazo en el perÃ­odo ğ‘¡ âˆ’ 1, el nivel
de precios japonÃ©s en dÃ³lares disminuye en 0.10548 unidades y el nivel de precios estadounidense
aumenta en 0.01114 unidades en el perÃ­odo t, lo que compensa la discrepancia previa, resaltando que el
coeficiente japonÃ©s es aproximadamente diez veces mayor que el estadounidense en valor absoluto.
Mientras que el nivel de precios de EE. UU. responde ligeramente a las desviaciones de la PPP, el de
JapÃ³n muestra una mayor sensibilidad. El tÃ©rmino de correcciÃ³n de errores para EE. UU. es cerca de 1/3
de una desviaciÃ³n estÃ¡ndar de cero, mientras que para JapÃ³n es aproximadamente 2.5 desviaciones
estÃ¡ndar de cero. Por lo tanto, a un nivel de significancia del 5%, concluimos que el tÃ©rmino de
velocidad de ajuste no difiere significativamente de cero para Estados Unidos, pero sÃ­ para JapÃ³n.
Esto sugiere que Estados Unidos, siendo un paÃ­s grande en comparaciÃ³n con JapÃ³n, tuvo movimientos
de precios independientes de JapÃ³n, mientras que los precios ajustados por tipo de cambio de JapÃ³n
respondieron a los eventos en Estados Unidos.
7. CHARACTERISTIC ROOTS, RANK, AND COINTEGRATION
Engle y Granger (1987): Se utiliza para analizar si hay una relaciÃ³n de equilibrio de largo plazo entre
dos o mÃ¡s series de tiempo. Se basa en la idea de que, si dos series estÃ¡n cointegradas, existe una relaciÃ³n
de equilibrio a largo plazo entre ellas, a pesar de que puedan mostrar comportamientos diferentes en el
corto plazo:
ğ‘Œğ‘¡ = ğ›½10 + ğ›½11 ğ‘ğ‘¡ + ğ‘’1ğ‘¡

ğ‘œ

ğ‘ğ‘¡ = ğ›½20 + ğ›½21 ğ‘Œğ‘¡ + ğ‘’2ğ‘¡

Cuando la muestra es grande, la prueba de raÃ­z unitaria puede ser problemÃ¡tica. Se puede encontrar que
las variables parecen estar cointegradas en una regresiÃ³n, pero no en otra, lo cual es indeseable. Este
problema es mÃ¡s complejo con tres o mÃ¡s variables, ya que no se sabe que variable irÃ¡ al lado izquierdo
y puede haber mÃ¡s de un vector cointegrante, y no existe un procedimiento para la estimaciÃ³n por
separado de los mÃºltiples vectores cointegrantes.
Otro problema con el modelo es que se basa en un mÃ©todo de dos pasos para estimar los coeficientes.
En el primer paso, se calculan los errores de la regresiÃ³n original. En el segundo paso, estos errores se
utilizan para estimar los coeficientes de la ecuaciÃ³n de correcciÃ³n de errores. Esto significa que
cualquier error en el cÃ¡lculo de los errores de la primera etapa afectarÃ¡ los resultados finales.
Los estimadores de mÃ¡xima verosimilitud de Johansen (1998) y Stock y Watson son mÃ©todos que no
requieren el uso de estimadores de dos pasos. Estos mÃ©todos pueden estimar y probar si hay varios
vectores cointegrantes presentes en un conjunto de datos. Permiten al investigador probar diferentes
versiones restringidas del vector cointegrante y los parÃ¡metros de velocidad de ajuste.
El procedimiento de Johansen (1998) se basa en la relaciÃ³n entre el rango de una matriz y sus raÃ­ces
caracterÃ­sticas. Es una generalizaciÃ³n multivariada de la prueba de Dickey-Fuller, que se utiliza para
analizar la estacionariedad de {ğ‘Œğ‘¡ } como dependiente de ğ‘1 en series de tiempo univariadas:
ğ‘Œğ‘¡ = ğ‘1 ğ‘Œğ‘¡âˆ’1 + ğœ€ğ‘¡

ğ‘œ

âˆ†ğ‘Œğ‘¡ = (ğ‘1 âˆ’ 1)ğ‘Œğ‘¡âˆ’1 + ğœ€ğ‘¡

Si (ğ‘1 âˆ’ 1) = 0, el proceso {ğ‘Œğ‘¡ } tiene una raÃ­z unitaria, si (a1 - 1) â‰  0, la secuencia {ğ‘Œğ‘¡ } es estacionaria.
Con Dickey-Fuller probamos formalmente la hipÃ³tesis nula (ğ‘1 âˆ’ 1) = 0.
Ahora consideremos la generalizaciÃ³n simple a n variables:
ğ‘‹ğ‘¡ = ğ´1 ğ‘‹ğ‘¡âˆ’1 + ğœ€ğ‘¡ ,

ğ‘‘ğ‘œğ‘›ğ‘‘ğ‘’ ğ‘‹ğ‘¡ ğ‘¦ ğœ€ğ‘¡ ğ‘ ğ‘œğ‘› ğ‘£ğ‘’ğ‘ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘  ğ‘‘ğ‘’ ğ‘‘ğ‘–ğ‘šğ‘’ğ‘›ğ‘ ğ‘–Ã³ğ‘› ğ‘› âˆ™ 1,

âˆ†ğ‘‹ğ‘¡ = ğ´1 ğ‘‹ğ‘¡âˆ’1 âˆ’ ğ‘‹ğ‘¡âˆ’1 + ğœ€ğ‘¡ ,

ğ´1 ğ‘’ğ‘  ğ‘¢ğ‘›ğ‘ ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘§ ğ‘‘ğ‘’ ğ‘ğ‘ğ‘ŸÃ¡ğ‘šğ‘’ğ‘¡ğ‘Ÿğ‘œğ‘  ğ‘‘ğ‘’ ğ‘‘ğ‘–ğ‘šğ‘’ğ‘›ğ‘ ğ‘–Ã³ğ‘› ğ‘› âˆ™ ğ‘›

= (ğ´1 âˆ’ ğ¼)ğ‘‹ğ‘¡âˆ’1 + ğœ€ğ‘¡

ğ¼ ğ‘’ğ‘  ğ‘™ğ‘ ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘§ ğ‘‘ğ‘’ ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘‘ğ‘ğ‘‘, ğ‘¦ ğœ‹ ğ‘’ğ‘  (ğ´1 âˆ’ ğ¼)

= ğ…ğ‘¿ğ’•âˆ’ğŸ + ğœºğ’•
El rango de (ğ´1 âˆ’ ğ¼) es igual al nÃºmero de vectores cointegrantes. Si (ğ´1 âˆ’ ğ¼) consiste en todos ceros,
es decir, ğ‘Ÿğ‘ğ‘›ğ‘˜(ğœ‹) = 0, todas las secuencias {ğ‘¥ğ‘–ğ‘¡ } son procesos de raÃ­z unitaria y sus variables no estÃ¡n
cointegradas. Si todas las raÃ­ces caracterÃ­sticas son menores que la unidad y si ğ’“ğ’‚ğ’ğ’Œ(ğ…) = ğ’, todas
las variables son estacionarias.
La ecuaciÃ³n ğ’“ğ’‚ğ’ğ’Œ(ğ…) = ğ’ se puede modificar fÃ¡cilmente para permitir la presencia de un tÃ©rmino de
tendencia:
âˆ†ğ‘‹ğ‘¡ = ğ´0 + ğ…ğ‘‹ğ‘¡âˆ’1 + ğœ€ğ‘¡ , ğ´1 : ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘§ ğ‘‘ğ‘’ ğ‘‘ğ‘–ğ‘šğ‘’ğ‘›ğ‘ ğ‘–Ã³ğ‘› ğ‘› âˆ™ 1, ğ‘‘ğ‘’ ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘¡ğ‘’ğ‘  (ğ‘10 , ğ‘20 , â€¦ , ğ‘ğ‘›0 )Â´
Se querrÃ­a incluir el tÃ©rmino de deriva si las variables muestran una clara tendencia a aumentar o
disminuir. A largo plazo, ğœ‹ğ‘‹ğ‘¡âˆ’1 = 0, de modo que cada secuencia {ğ›¥ğ‘¥ğ‘–ğ‘¡ } tiene un valor esperado de
ğ‘ğ‘–0 . Al agregar estos cambios a lo largo del tiempo, se obtiene la expresiÃ³n ğ‘ğ‘–0ğ‘¡ .
Manipulando adecuadamente los elementos de ğ´0 , es posible incluir una constante en el vector o
vectores cointegrantes sin agregar una tendencia determinista en el tiempo al sistema.
Algunos prefieren incluir un intercepto en el vector cointegrante junto con un tÃ©rmino de deriva si las
variables lo requieren segÃºn la teorÃ­a econÃ³mica. Sin embargo, la intercepciÃ³n en el vector cointegrante
no estÃ¡ identificada en presencia de un tÃ©rmino de deriva, ya que parte de la deriva puede incluirse en el
vector de cointegraciÃ³n:
âˆ†ğ‘‹1ğ‘¡ = (ğœ‹11 ğ‘‹1ğ‘¡âˆ’1 + ğœ‹12 ğ‘‹2ğ‘¡âˆ’1 + â‹¯ + ğœ‹1ğ‘› ğ‘‹ğ‘›ğ‘¡âˆ’1 + ğ‘10 ) + ğ‘11 + ğœ€1ğ‘¡
â‹®
âˆ†ğ‘‹ğ‘›ğ‘¡ = ğ‘†ğ‘› (ğœ‹11 ğ‘‹1ğ‘¡âˆ’1 + ğœ‹12 ğ‘‹2ğ‘¡âˆ’1 + â‹¯ + ğœ‹1ğ‘› ğ‘‹ğ‘›ğ‘¡âˆ’1 + ğ‘10 ) + ğ‘ğ‘›1 + ğœ€1ğ‘¡

Donde ğ‘ğ‘–1 se define como el valor que satisface ğ‘ ğ‘– ğ‘10 + ğ‘ğ‘–1 = ğ‘10 . , dividiendo ğ‘10 en dos partes y
colocando una dentro de la relaciÃ³n cointegrante.
Es necesario un mÃ©todo de identificaciÃ³n porque la proporciÃ³n de la deriva para incluir en el vector
cointegrante es arbitraria. Aunque se necesita un tÃ©rmino de deriva fuera de la relaciÃ³n cointegrante para
capturar los efectos de una tendencia sostenida de las variables, la mayorÃ­a de los investigadores
incluyen tÃ©rminos de deriva solo si los datos lo justifican.
Es mejor evitar el uso de una tendencia como variable explicativa a menos que tenga una buena razÃ³n
para incluirla en el modelo. Johansen (1994) discute el papel de los regresores deterministas en una
relaciÃ³n cointegrante.
El modelo multivariado se puede generalizar para permitir un proceso autorregresivo de orden superior:
ğ‘‹ğ‘¡ = ğ´1 ğ‘‹ğ‘¡âˆ’1 + ğ´2 ğ‘‹ğ‘¡âˆ’2 + â‹¯ + ğ´ğ‘ ğ‘‹ğ‘¡âˆ’ğ‘ + ğœ€ğ‘¡
ğ‘‹ğ‘¡ : ğ‘’ğ‘  ğ‘¢ğ‘›ğ‘ ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘§ ğ‘‘ğ‘’ ğ‘‘ğ‘–ğ‘šğ‘’ğ‘›ğ‘ ğ‘–Ã³ğ‘› ğ‘› âˆ™ 1, ğ‘‘ğ‘’ ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘¡ğ‘’ğ‘  (ğ‘‹1ğ‘¡ , ğ‘‹2ğ‘¡ , â€¦ , ğ‘‹ğ‘›ğ‘¡ )Â´
ğœ€ğ‘¡ : ğ‘’ğ‘  ğ‘¢ğ‘› ğ‘¢ğ‘› ğ‘£ğ‘’ğ‘ğ‘¡ğ‘œğ‘Ÿ ğ‘› âˆ’ ğ‘‘ğ‘–ğ‘šğ‘’ğ‘›ğ‘ ğ‘–ğ‘œğ‘›ğ‘ğ‘™ ğ‘–. ğ‘–. ğ‘‘ ğ‘ğ‘œğ‘› ğ‘šğ‘’ğ‘‘ğ‘–ğ‘ ğ‘ğ‘’ğ‘Ÿğ‘œ ğ‘¦ ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘§ ğ‘‘ğ‘’ ğ‘£ğ‘ğ‘Ÿğ‘–ğ‘ğ‘›ğ‘§ğ‘ ğ›´ğœ€ .
Al realizar cÃ¡lculos matemÃ¡ticos, obtenemos:
ğ‘âˆ’1

âˆ†ğ‘‹ğ‘¡ = ğœ‹ğ‘‹ğ‘¡âˆ’1 + âˆ‘ ğœ‹ğ‘– âˆ†ğ‘‹ğ‘¡âˆ’ğ‘– + ğœ€ğ‘¡
ğ‘–=1

El rango de la matriz ğœ‹ es clave; ya que indica el nÃºmero de vectores cointegrantes independientes. Si
el rango(ğœ‹) = 0, la matriz es nula y la ecuaciÃ³n es el modelo VAR usual en primeras diferencias. Si ğœ‹
tiene rango n, el proceso vectorial es estacionario. En casos intermedios, si ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘œ(ğœ‹) = 1, hay un solo
vector cointegrante y ğœ‹ğ‘‹ğ‘¡âˆ’1 es el tÃ©rmino de correcciÃ³n de errores. Para otros casos en los que
1 < ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘œ(ğœ‹) < ğ‘›, hay mÃºltiples vectores cointegrantes. El nÃºmero de vectores cointegrantes
distintos se puede obtener verificando la significancia de las raÃ­ces caracterÃ­sticas de ğœ‹.
En la prÃ¡ctica, solo podemos obtener estimaciones de ğœ‹ y sus raÃ­ces caracterÃ­sticas, y usamos dos
estadÃ­sticas de prueba para determinar el nÃºmero de raÃ­ces caracterÃ­sticas que no difieren
significativamente de la unidad:
ğ‘›

ğœ†ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ (ğ‘Ÿ) = âˆ’ğ‘‡ âˆ‘ ln (1 âˆ’ ğœ†Ì‚ğ‘– )
ğ‘–=ğ‘Ÿ+1

ğœ†ğ‘šğ‘ğ‘¥ (ğ‘Ÿ, ğ‘Ÿ + 1) = âˆ’ğ‘‡ ln (1 âˆ’ ğœ†Ì‚ğ‘Ÿ+1 )
ğ‘‘ğ‘œğ‘›ğ‘‘ğ‘’ ğœ†Ì‚ğ‘– ğ‘ ğ‘œğ‘› ğ‘™ğ‘œğ‘  ğ‘£ğ‘ğ‘™ğ‘œğ‘Ÿğ‘’ğ‘  ğ‘’ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘‘ğ‘œğ‘  ğ‘‘ğ‘’ ğ‘™ğ‘ğ‘  ğ‘Ÿğ‘Ã­ğ‘ğ‘’ğ‘  ğ‘ğ‘ğ‘Ÿğ‘ğ‘ğ‘¡ğ‘’ğ‘ŸÃ­ğ‘ ğ‘¡ğ‘–ğ‘ğ‘ğ‘  ğ‘œğ‘ğ‘¡ğ‘’ğ‘›ğ‘–ğ‘‘ğ‘œğ‘  ğ‘ ğ‘ğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘Ÿ ğ‘‘ğ‘’ ğ‘™ğ‘ ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘§ ğœ‹
La primera estadÃ­stica prueba si el nÃºmero de vectores cointegrantes es menor o igual a r, ğœ†ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ es igual
a cero cuando todas las ğœ†ğ‘– = 0., mientras que la segunda prueba si es exactamente ğ‘Ÿ o ğ‘Ÿ + 1. Si el
valor estimado de la raÃ­z caracterÃ­stica estÃ¡ cerca de cero, ğœ†ğ‘šğ‘ğ‘¥ serÃ¡ pequeÃ±o
Los valores crÃ­ticos se obtienen mediante el enfoque de Monte Carlo y dependen:
1. Del nÃºmero de componentes no estacionarias
2. De la forma de A0 en el modelo.
Un ejemplo en Dinamarca hecho por Johansen and Juselius (1990) ilustra que los resultados de las
pruebas ğœ†ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ ğ‘¦ ğœ†ğ‘šğ‘ğ‘¥ pueden entrar en conflicto. La prueba ğœ†max tiene la hipÃ³tesis alternativa mÃ¡s
precisa y generalmente se prefiere para determinar el nÃºmero de vectores cointegrantes.
8. HYPOTHESIS TESTING
En las pruebas de Dickey-Fuller y en el procedimiento de Johansen, es crucial determinar
correctamente la forma de los regresores determinÃ­sticos. Los valores crÃ­ticos de las estadÃ­sticas ğœ†ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’
y ğœ†ğ‘šğ‘ğ‘¥ varÃ­an dependiendo de si se incluye un tÃ©rmino de intercepciÃ³n en el vector de cointegraciÃ³n.

En lugar de asumir la forma de A0 de manera arbitraria, se pueden probar formas restringidas del vector,
permitiendo examinar restricciones importantes en estudios como la demanda de dinero, como la
proporcionalidad a largo plazo entre el dinero y los precios, asÃ­ como las elasticidades del ingreso y la
tasa de interÃ©s en la demanda de dinero. En la ecuaciÃ³n (6.1) ğ‘šğ‘¡ = ğ›½0 + ğ›½1 ğ‘ğ‘¡ + ğ›½2 ğ‘¦ğ‘¡ + ğ›½3 ğ‘Ÿğ‘¡ + ğ‘’ğ‘¡ , las
restricciones relevantes son ğ›½1 = 1, ğ›½2 > 0 ğ‘¦ ğ›½3 < 0.
En las pruebas de cointegraciÃ³n, sÃ³lo las combinaciones lineales estacionarias de variables son
relevantes. Si las restricciones en los parÃ¡metros de ğœ‹ no afectan el nÃºmero de vectores de cointegraciÃ³n,
este nÃºmero se mantiene constante. Para determinar si hay una constante en lugar del sesgo no
restringido A0 en el vector de cointegraciÃ³n, se comparan las raÃ­ces caracterÃ­sticas de dos formas del
modelo. La estadÃ­stica resultante sigue una distribuciÃ³n ğœ’2 con (n - r) grados de libertad, donde n es el
nÃºmero de raÃ­ces caracterÃ­sticas y r es el nÃºmero de vectores de cointegraciÃ³n.

La prueba compara las diferencias entre ğ‘™ğ‘›(1 âˆ’ ğœ†Ì‚âˆ—ğ‘– ) y ğ‘™ğ‘›(1 âˆ’ ğœ†Ì‚ğ‘– ) para evaluar si las restricciones en
el vector de cointegraciÃ³n tienen un efecto significativo. Valores pequeÃ±os sugieren que incluir la
constante es aceptable, pero esto aumenta la probabilidad de encontrar una combinaciÃ³n lineal
estacionaria de las variables. Un valor alto de ğœ†Ì‚âˆ—ğ‘Ÿ+1 indica que las restricciones inflan artificialmente el
nÃºmero de vectores de cointegraciÃ³n. Johansen (1991) demostrÃ³ que, con una estadÃ­stica de prueba
suficientemente grande, se puede rechazar la hipÃ³tesis nula de una constante en el vector de
cointegraciÃ³n, sugiriendo una tendencia lineal en las variables. Johansen y Juselius (1990) aplicaron
esta prueba a su modelo de demanda de dinero danesa y concluyeron que las variables no mostraban
una tendencia lineal, justificando asÃ­ la inclusiÃ³n de la constante en el vector de cointegraciÃ³n.
Para probar otras restricciones en el vector de cointegraciÃ³n, Johansen define las matrices ğ›¼ y ğ›½, donde
ğœ‹ = ğ›¼ğ›½â€². Estas matrices permiten estimar el modelo como un modelo de correcciÃ³n de errores y
seleccionar los vectores de cointegraciÃ³n mÃ¡s significativos. Sin embargo, debido a las restricciones
entre ecuaciones, no es posible estimar ğ›¼ y ğ›½ utilizando MCO. Empleando la estimaciÃ³n de mÃ¡xima
verosimilitud, se puede estimar el modelo, determinar el rango de ğœ‹ y seleccionar ğ›¼ de manera que
ğœ‹ = ğ›¼ğ›½â€².
En un modelo donde el rango de la matriz ğœ‹ es igual a 1, las ecuaciones toman la forma:
ğœŸğ’™ğ’Šğ’• = ğœ¶ğ’Š (ğ’™ğŸğ’•âˆ’ğŸ + ğœ·ğŸ ğ’™ğŸğ’•âˆ’ğŸ +Â·Â·Â· + ğœ·ğ’ ğ’™ğ’ğ’•âˆ’ğŸ ) +Â·Â·Â· + ğœºğ’Šğ’• (ğ’Š = ğŸ, â€¦ , ğ’)
o en forma matricial:

Para probar restricciones en los parÃ¡metros ğ›¼ y ğ›½', se compara el nÃºmero de vectores de cointegraciÃ³n
bajo la hipÃ³tesis nula y alternativa. La estadÃ­stica de prueba es:

AsintÃ³ticamente, esta estadÃ­stica tiene una distribuciÃ³n ğœ’2 con grados de libertad iguales al nÃºmero de
restricciones impuestas en ğ›½. Los valores pequeÃ±os de ğœ†Ì‚âˆ—ğ‘– en relaciÃ³n con ğœ†Ì‚ğ‘– (para i â‰¤ r) implican un
nÃºmero reducido de vectores de cointegraciÃ³n. Por lo tanto, la restricciÃ³n incrustada en la hipÃ³tesis nula
es vinculante si el valor calculado de la estadÃ­stica de prueba excede el de una tabla ğœ’2. Por ejemplo,
Johansen y Juselius prueban la restricciÃ³n de que el dinero y el ingreso se mueven proporcionalmente.
Su relaciÃ³n de equilibrio de largo plazo estimada es ğ‘š2ğ‘¡ = 1.03ğ‘¦ğ‘¡ âˆ’ 5.21ğ‘–ğ‘¡ğ‘ + 4.22ğ‘–ğ‘¡ğ‘‘ + 6.06.
Restringen el coeficiente de ingreso a la unidad y encuentran los valores restringidos de los ğœ†Ì‚âˆ—ğ‘– . Dado
que el modelo irrestricto tiene ğ‘Ÿ = 1 y âˆ’ğ‘‡ ğ‘™ğ‘›(1 âˆ’ ğœ†Ì‚1 ) = 30.09, la ecuaciÃ³n (6.59) se convierte en
âˆ’30.04 + 30.09 = 0.05. Al tener solo una restricciÃ³n en ğ›½, la estadÃ­stica de prueba sigue una
distribuciÃ³n ğœ’2 con 1 grado de libertad. Sin embargo, dado que el valor obtenido, 0.05, no es
significativo, se concluye que la restricciÃ³n no es vinculante.

Para probar restricciones en ğ›¼, se sigue un procedimiento similar. Se restringe ğ›¼ y se comparan las r
raÃ­ces caracterÃ­sticas mÃ¡s significativas de los modelos restringido y no restringido utilizando la
ecuaciÃ³n (6.59). Si el valor calculado de esta ecuaciÃ³n supera el valor crÃ­tico de una tabla ğœ’2, con grados
de libertad igual al nÃºmero de restricciones en ğ›¼, entonces las restricciones pueden ser rechazadas. Por
ejemplo, Johansen y Juselius (1990) probaron la restricciÃ³n de que solo la demanda de dinero responde
a las desviaciones del equilibrio de largo plazo, expresada formalmente como ğ›¼2 = ğ›¼3 = ğ›¼4 = 0. Al
calcular la diferencia de la estadÃ­stica de prueba con las raÃ­ces caracterÃ­sticas restringidas y no
restringidas, encontraron un valor significativo, lo que sugiere un respaldo parcial a la hipÃ³tesis de que
la restricciÃ³n no es vinculante. En resumen, si hay un solo vector de cointegraciÃ³n, tanto los mÃ©todos de
Engle-Granger como los de Johansen tienen la misma distribuciÃ³n asintÃ³tica. AdemÃ¡s, se puede
emplear el modelo de correcciÃ³n de errores estimado para probar restricciones en ğ›¼, siendo la estadÃ­stica
t equivalente a la prueba de Johansen en este caso.
Pruebas de longitud de rezago y causalidad
La prueba de longitud de rezago se puede entender considerando el sistema en la forma de (6.54), donde
todas las ğ›¥ğ‘¥ğ‘¡âˆ’ğ‘– son variables estacionarias. Esto permite usar la Regla 1 de Sims, Stock y Watson
(1990), que implica probar los coeficientes de interÃ©s en variables estacionarias con media cero
utilizando una distribuciÃ³n normal. Dado que la longitud del rezago depende solo de los valores de los
diversos ğœ‹i, una distribuciÃ³n ğœ’2 es adecuada para probar cualquier restricciÃ³n relacionada con la
longitud del rezago. La estadÃ­stica de prueba
se
compara
con
una
distribuciÃ³n ğœ’2 con grados de libertad igual al nÃºmero de restricciones en el sistema. Alternativamente,
se puede utilizar el AIC o SBC multivariado para determinar la longitud del rezago. Si se desea probar
las longitudes del rezago para una sola ecuaciÃ³n, un test F es apropiado.
La regla tambiÃ©n implica que no se pueden realizar pruebas de causalidad de Granger en un sistema
cointegrado utilizando un test F estÃ¡ndar. Si el rango (ğœ‹) = 0, la causalidad de Granger implica sÃ³lo
variables estacionarias, lo que permite utilizar una distribuciÃ³n F estÃ¡ndar para las pruebas. Sin embargo,
si las variables estÃ¡n cointegradas, la causalidad de Granger involucra los coeficientes de ğœ‹, que
multiplican variables no estacionarias. En este caso, no es apropiado utilizar un estadÃ­stico F para probar
la causalidad de Granger, ya que no se pueden escribir las restricciones de la prueba como restricciones
en un conjunto de variables I(0). AdemÃ¡s, las pruebas de exogeneidad de bloque tambiÃ©n estÃ¡n
descartadas en caso de que una variable estÃ© cointegrada con otras, ya que no se puede utilizar una
prueba ğœ’2 estÃ¡ndar para determinar su inclusiÃ³n en las ecuaciones correspondientes.
Diferenciar o no diferenciar
Diferenciar variables no estacionarias en un VAR puede ser problemÃ¡tico si estÃ¡n cointegradas, ya que
excluimos las relaciones de equilibrio de largo plazo entre ellas, lo que afecta negativamente a las
estimaciones y pruebas estadÃ­sticas al perder informaciÃ³n importante. Por ello, es preferible usar
primeras diferencias si las variables I(1) no estÃ¡n cointegradas, ya que:
1. Evita la pÃ©rdida de poder en las pruebas al evitar estimar demasiados parÃ¡metros adicionales.
2. Permite pruebas de causalidad de Granger que siguen una distribuciÃ³n F estÃ¡ndar.
3. Ofrece respuestas de impulso mÃ¡s consistentes en horizontes de pronÃ³stico largo.
Determinar la cointegraciÃ³n de variables I(1) es crucial. Se sugiere realizar pruebas de longitud de
rezago independientes de la cointegraciÃ³n y estimar un VAR irrestricto con ajuste estacional, seguido de
una prueba de cointegraciÃ³n. Si las variables no estÃ¡n cointegradas, se estiman en primeras diferencias;
si lo estÃ¡n, se utiliza el modelo de correcciÃ³n de errores. Esto permite inferencias sobre cualquier
variable, excepto los vectores de cointegraciÃ³n, mediante estadÃ­sticas estÃ¡ndar, y proporciona
estimaciones consistentes mediante respuestas de impulso y descomposiciones de varianza.
Pruebas sobre MÃºltiples Vectores Cointegrantes
Cuando el rango de ğœ‹ supera uno, no es sencillo interpretar los vectores de cointegraciÃ³n. Con mÃºltiples
vectores de cointegraciÃ³n, cualquier combinaciÃ³n lineal de estos tambiÃ©n es un vector de cointegraciÃ³n.

Afortunadamente, es posible identificar relaciones de comportamiento separadas al restringir
adecuadamente los vectores de cointegraciÃ³n individuales. La Ãºnica complicaciÃ³n radica en ser claro
sobre el nÃºmero de restricciones impuestas al sistema. Es importante destacar que si hay r relaciones de
cointegraciÃ³n en un sistema de n variables, existe un vector de cointegraciÃ³n para cada subconjunto de
(ğ‘› âˆ’ ğ‘Ÿ + 1) variables. Por ejemplo, si hay dos vectores de cointegraciÃ³n en un sistema de tres
variables, hay un vector de cointegraciÃ³n para cada par bilateral de variables (2 = ğ‘› âˆ’ ğ‘Ÿ + 1). Por
tanto, hay un vector de cointegraciÃ³n para cada subconjunto de tres variables. En general, la matriz ğ›½â€²
serÃ¡ una matriz r â‹… n de parÃ¡metros de cointegraciÃ³n, y cada subconjunto de ğ‘› âˆ’ ğ‘Ÿ + 1 variables serÃ¡
cointegrado. Las operaciones estÃ¡ndar de fila y columna en ğ›½â€² no implican restricciones en los vectores
de cointegraciÃ³n; simplemente resultan en vectores de cointegraciÃ³n adicionales que son combinaciones
lineales de los originales.
EJEMPLO 1: EXCLUSIÃ“N DE VARIABLES DENTRO DE UNA ECUACIÃ“N
Con mÃºltiples vectores de cointegraciÃ³n, no puedes probar si un ğ›½ij particular es igual a cero, ya que
esta suposiciÃ³n no restringe el espacio de cointegraciÃ³n. En el caso general donde ğ›½â€² es una matriz r â‹… n,
una restricciÃ³n de exclusiÃ³n comprobable implica la exclusiÃ³n de r o mÃ¡s variables de un vector de
cointegraciÃ³n. Por lo tanto, excluir r variables de un vector de cointegraciÃ³n implica solo una restricciÃ³n.
Si el valor de la muestra de la estadÃ­stica ğœ’2 con un grado de libertad (ya que solo hay una restricciÃ³n
involucrada) supera un valor crÃ­tico, se rechaza la hipÃ³tesis nula de que este conjunto de variables
contiene una relaciÃ³n de cointegraciÃ³n.
EJEMPLO 2: EXCLUSIÃ“N DE VARIABLES ENTRE ECUACIONES
Supongamos que quieres probar si x4t puede ser excluido del conjunto de relaciones de cointegraciÃ³n.
La restricciÃ³n ğ›½14 = ğ›½24 = 0 implica solo una restricciÃ³n en el espacio de cointegraciÃ³n. En el caso
general donde ğ›½â€² es una matriz r â‹… n, la prueba ğ›½1ğ‘— = ğ›½2ğ‘— =Â·Â·Â·= ğ›½ğ‘Ÿğ‘— = 0 aÃºn involucra solo una
restricciÃ³n. Esto se debe a que ğ‘¥ğ‘–ğ‘¡ puede ser eliminado de ğ‘Ÿ âˆ’ 1 ecuaciones usando operaciones simples
de fila y columna.
EJEMPLO 3: RESTRICCIONES CONDICIONALES
TambiÃ©n es posible restringir un vector de cointegraciÃ³n condicionalmente a los valores de todos los
otros vectores de cointegraciÃ³n. Por ejemplo, podrÃ­as querer determinar si (1, 0, ğ›½23 , ğ›½24 )â€² es un vector
de cointegraciÃ³n para los valores normalizados dados de ğ›½12 , ğ›½13 ğ‘¦ ğ›½14 . Cortell, Davis y Smith (1999)
consideran el problema de identificaciÃ³n en detalle considerable. Examinan cuatro relaciones de
comportamiento en un sistema de siete variables, y concluyen que no pudieron rechazar las restricciones
a niveles de significancia convencionales.
La primera ecuaciÃ³n es la ecuaciÃ³n de demanda de dinero. Las siguientes tres
ecuaciones son una funciÃ³n simple de consumo, una funciÃ³n de inversiÃ³n y una
funciÃ³n de demanda de importaciones, respectivamente. Se asume que el consumo,
la inversiÃ³n y las importaciones son funciones solo del ingreso y la tasa de interÃ©s.
La Prueba en Presencia de Variables I(2)
TambiÃ©n es posible probar la multicointegraciÃ³n utilizando la metodologÃ­a de Johansen. Se considera
un sistema VAR donde el problema de la multicointegraciÃ³n se refiere a los rangos tanto de ğœ‹ como de
ğ›¤. Para ilustrar el procedimiento, se comienza con un sistema de tres variables que son
multicointegradas. Se define r como el rango de ğœ‹ y ğ‘Ÿ1 como el rango de Î“, de modo que si r = r1 = 1,
hay una relaciÃ³n de equilibrio. Si r = 0, la multicointegraciÃ³n falla, y si ğ‘Ÿ = 1 y ğ‘Ÿ1 = 0, la relaciÃ³n de
equilibrio tiene una forma especÃ­fica. Sin embargo, la estimaciÃ³n de los rangos de ğœ‹ y Î“ puede ser
complicada. Por ejemplo, si las variables I(2) estÃ¡n cointegradas de cierta manera, se debe estimar su
rango adecuadamente.
Si tomas la primera diferencia, se sigue que ğœ‹11 ğ›¥ğ‘¥1ğ‘¡ + ğœ‹12 ğ›¥ğ‘¥2ğ‘¡ + ğœ‹13 ğ›¥ğ‘¥3ğ‘¡ es I(0). DeberÃ­as ser capaz
de identificar el problema. Para cualquier vector de cointegraciÃ³n en ğœ‹, es posible estimar un vector de
cointegraciÃ³n idÃ©ntico para las primeras diferencias de las variables. Sin embargo, una combinaciÃ³n

lineal de las dos relaciones no es estacionaria. Si consideras el resultado obtenido al restar la relaciÃ³n
I(0) de la relaciÃ³n I(1), observarÃ¡s que lo que se ha hecho es cambiar el subÃ­ndice temporal para las
variables en la relaciÃ³n de cointegraciÃ³n. La clave estÃ¡ en encontrar vectores de cointegraciÃ³n en ğ›¤ que
no sean combinaciones lineales de los de ğœ‹.
En el caso mÃ¡s general considerado por Johansen (1995), donde ğ‘Ÿğ‘ğ‘›ğ‘˜(ğœ‹) = ğ‘Ÿ y ğ‘  denota el nÃºmero de
vectores de cointegraciÃ³n en Î“ que son ortogonales a los de ğœ‹:
1. Si r = 0, no hay relaciÃ³n entre las variables que sea estacionaria.
2. En un sistema con n variables, si ğ‘Ÿ + ğ‘  = ğ‘› âˆ’ 1, hay un vector de multicointegraciÃ³n Ãºnico. El
nÃºmero de tendencias estocÃ¡sticas I(2) en un sistema de n variables se calcula como ğ‘› âˆ’ ğ‘Ÿ âˆ’ ğ‘ .
3. El valor de s debe ser tal que ğ‘  < ğ‘› âˆ’ ğ‘Ÿ. Para que el anÃ¡lisis de las variables I(2) sea adecuado, los
valores de r y s deben satisfacer la condiciÃ³n de ğ‘  + ğ‘Ÿ < ğ‘›. Si ğ‘  = ğ‘› âˆ’ ğ‘Ÿ, entonces ğ‘¥ğ‘¡ no contiene
variables I(2).
La prueba de cointegraciÃ³n de Johansen con variables I(2) implica un proceso de dos pasos. Primero,
se estima un modelo para determinar el rango de ğœ‹, utilizando estadÃ­sticas como ğœ†ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ y ğœ†ğ‘šğ‘ğ‘¥ . Luego,
se determina el valor de s condicional al valor de ğ‘Ÿ, lo que implica encontrar vectores de cointegraciÃ³n
en ğ›¤ que sean independientes de los de ğœ‹.
âˆ—
El procedimiento implica considerar la hipÃ³tesis nula de que ğ‘  = ğ‘ 0 y calcular una estadÃ­stica ğ‘„ğ‘Ÿ,ğ‘ 

Por lo tanto, se construye de la misma manera que una estadÃ­stica ğœ†ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ . Las diferencias principales
radican en que se prueba el rango de ğ›¤ condicional al valor de ğ‘Ÿ y que se obtiene el nÃºmero de vectores
de cointegraciÃ³n ortogonales a los de ğœ‹. Los valores crÃ­ticos necesarios para determinar el valor de s
âˆ—
deben ser modificados en funciÃ³n de r. Si el valor muestral de ğ‘„ğ‘Ÿ,ğ‘ 
supera el valor crÃ­tico calculado por
Johansen, se rechaza la hipÃ³tesis nula ğ‘  = ğ‘ 0 a favor de la alternativa ğ‘  > ğ‘ 0.
9. ILLUSTRATING THE JOHANSEN METHODOLOGY
Siga los cuatro pasos siguientes al implementar el procedimiento de Johansen:
PASO 1: Es una buena prÃ¡ctica realizar pruebas previas de todas las variables para evaluar su orden de
integraciÃ³n. Represente los datos para ver si es probable que haya una tendencia temporal lineal en el
proceso de generaciÃ³n de datos. En la mayorÃ­a de los casos, tendrÃ¡ variables integradas del mismo orden.
En otros casos, puede comprobar la multicointegraciÃ³n. Los resultados de la prueba pueden ser bastante
sensibles a la longitud del retraso, por lo que es importante tener cuidado. El procedimiento mÃ¡s comÃºn
es estimar una autorregresiÃ³n vectorial utilizando los datos no diferenciados. A continuaciÃ³n, utilice las
mismas pruebas de longitud de retardo que en un VAR tradicional. Comience con la longitud de retardo
mÃ¡s larga que se considere razonable y pruebe si se puede acortar. Por ejemplo, si queremos probar si
los retrasos 2 a 4 son importantes, podemos estimar los siguientes dos VAR:
ğ‘¥ğ‘¡ = ğ´0 + ğ´1 ğ‘¥ğ‘¡âˆ’1 + ğ´2 ğ‘¥ğ‘¡âˆ’2 + ğ´3 ğ‘¥ğ‘¡âˆ’3 + ğ´4 ğ‘¥ğ‘¡âˆ’4 + ğ‘’1ğ‘¡
ğ‘‹ğ‘¡ = ğ´0 + ğ´1 ğ‘¥ğ‘¡âˆ’1 + ğ‘’2ğ‘¡
DÃ³nde ğ‘¥ğ‘¡ es el vector de variables (ğ‘› âˆ™ 1), ğ´0 es el vector de tÃ©rminos de intercepto(ğ‘› âˆ™ 1), ğ´ğ‘– es la
matriz de coeficientes (ğ‘› âˆ™ ğ‘›), y ğ‘’1ğ‘¡ y ğ‘’2ğ‘¡ son los vectores de tÃ©rminos de error (ğ‘› âˆ™ 1),
Estime el primer sistema con cuatro rezagos de cada variable en cada ecuaciÃ³n y llame a la matriz de
varianza/covarianza de los residuos ğ›´4 . Ahora estime la segunda ecuaciÃ³n usando solo un retraso de
cada variable en cada ecuaciÃ³n y llame a la matriz de varianza/covarianza de los residuos ğ›´1 . A pesar de
que estamos trabajando con variables no estacionarias, podemos realizar pruebas de longitud de retardo
utilizando el estadÃ­stico de la prueba de razÃ³n de verosimilitud recomendado por Sims (1980):

Siguiendo a Sims, usa la distribuciÃ³n ğœ’2 con grados de libertad iguales al nÃºmero de restricciones de
coeficiente. Dado que cada ğ´ğ‘– tiene coeficientes ğ‘›2 , restringir ğ´2 = ğ´3 = ğ´4 = 0 implica
restricciones de 3ğ‘›2 . Alternativamente, puede seleccionar la longitud del retardo ğ‘ utilizando las
generalizaciones multivariantes del AIC o SBC. En el modelo que nos ocupa, deberÃ­a encontrar que el
mÃ©todo de general a especÃ­fico y el AIC seleccionan una longitud de retraso de 2, mientras que el SBC
selecciona una longitud de retraso de 1.
PASO 2: Estime el modelo y determine el rango de Ï€. Muchos paquetes de software estadÃ­stico de series
temporales contienen una rutina para estimar el modelo. AquÃ­, basta con decir que OLS no es apropiado
porque es necesario imponer restricciones de ecuaciones cruzadas en la matriz Ï€. En la mayorÃ­a de las
circunstancias, puede optar por estimar el modelo de tres formas: (1) con todos los elementos de ğ´0
iguales a cero, (2) con una deriva o (3) con un tÃ©rmino constante en el vector de cointegraciÃ³n.
Si pretendemos que no conocemos la forma del proceso de generaciÃ³n de datos, es posible que queramos
incluir un tÃ©rmino de intersecciÃ³n en los vectores de cointegraciÃ³n, y esto se puede probar. Si seguimos
el mÃ©todo de general a especÃ­fico y usamos una longitud de retardo de 2, el modelo estimado tiene la
forma:
Cualquier evidencia de que los errores no son ruido blanco generalmente significa que las longitudes de
retraso son demasiado cortas.
En el ejemplo que se plantea en el libro, a pesar de que el proceso real de generaciÃ³n de datos pueda
contener solo un vector de cointegraciÃ³n, las realizaciones son tales que los investigadores dispuestos a
usar el nivel de significaciÃ³n del 10% concluirÃ­an incorrectamente que hay dos vectores de
cointegraciÃ³n. No rechazar una hipÃ³tesis nula incorrecta es siempre un peligro inherente al uso de
intervalos de confianza amplios.
PASO 3: Analice los vectores de cointegraciÃ³n normalizados y los coeficientes de velocidad de ajuste.
Considere las siguientes pruebas:
1. La prueba de que ğ›½0 = 0 implica una restricciÃ³n en un vector de cointegraciÃ³n; Por lo tanto,
la prueba de razÃ³n de verosimilitud tiene una distribuciÃ³n ğœ’ 2 con un grado de libertad. El valor
calculado de ğœ’ 2 = 0,011234 no es significativo a niveles convencionales. Por lo tanto, no
podemos rechazar la hipÃ³tesis nula de que ğ›½0 = 0. Por lo tanto, es posible utilizar la forma del
modelo en la que no hay ni una deriva ni una intersecciÃ³n en el vector de cointegraciÃ³n. Por lo
tanto, para aclarar la cuestiÃ³n relativa al nÃºmero de vectores de cointegraciÃ³n, serÃ­a prudente
reestimar el modelo excluyendo la constante del vector de cointegraciÃ³n.
2. Restringir el vector de cointegraciÃ³n normalizado de modo que ğ›½2 = âˆ’1 ğ‘¦ ğ›½3 = 1 implica
dos restricciones en un vector de cointegraciÃ³n; Por lo tanto, la prueba de razÃ³n de verosimilitud
tiene una distribuciÃ³n ğœ’ 2 con dos grados de libertad. El valor calculado de ğœ’ 2 = 0,55350 no
es significativo a niveles convencionales. Por lo tanto, no podemos rechazar la hipÃ³tesis nula
de que ğ›½2 = âˆ’1 ğ‘¦ ğ›½3 = 1.
3. Para probar la restricciÃ³n conjunta Î² = (0,âˆ’1,âˆ’1, 1) implica las tres restricciones ğ›½0 = 0, ğ›½2 =
âˆ’1 ğ‘¦ ğ›½3 = 1. El valor calculado de ğœ’ 2 con tres grados de libertad es 1,8128, por lo que el
nivel de significaciÃ³n es 0,612. Por lo tanto, no podemos rechazar la hipÃ³tesis nula de que el
vector de cointegraciÃ³n es (0,âˆ’1,âˆ’1, 1).
PASO 4: Por Ãºltimo, la contabilidad de la innovaciÃ³n y las pruebas de causalidad en el modelo de
correcciÃ³n de errores de (6.62) podrÃ­an ayudar a identificar un modelo estructural y determinar si el
modelo estimado parece ser razonable. Dado que los datos simulados no tienen significado
econÃ³mico, aquÃ­ no se lleva a cabo la contabilidad de la innovaciÃ³n.

10. ERROR-CORRECTION AND ADL TESTS
En el mÃ©todo de Engleâ€“Granger, se estima la relaciÃ³n de equilibrio de largo plazo a partir de una
regresiÃ³n de zt sobre yt o de una regresiÃ³n de yt sobre zt. En el mÃ©todo de Johansen, todas las variables
se tratan de manera simÃ©trica. Los mÃ©todos pueden ser usados cuando no se quiera especificar una
variable "dependiente" y un conjunto de variables "independientes". Supongamos que y t y zt estÃ¡n
cointegradas de orden (1, 1) y el modelo de correcciÃ³n de errores (ECM) estÃ¡ representado de forma
reducida por (i) y (ii), luego en la relaciÃ³n entre los tÃ©rminos de error y los shocks estructurales en (iii)
(i)
(iii)
(ii)
donde ğœ€yt y ğœ€zt son las innovaciones estructurales en Î”yt y Î”zt, y los cij son coeficientes. Los shocks
estructurales estÃ¡n incorrelacionados en el sentido de que Eğœ€ytğœ€zt = 0. Por ahora, supongamos que los
valores de los cij son desconocidos. Ortogonalizando los dos errores e1t = pe2t + vt donde ğœŒ es el
coeficiente de regresiÃ³n y vt es la innovaciÃ³n. Sustituimos en la ecuaciÃ³n anterior y aÃ±adimos que a =
a1 â€“ pa2 obtenemos
(iv)
El problema general es que Î”zt estarÃ¡ correlacionado con el tÃ©rmino de error v t, lo que genera
simultaneidad, OLS no puede utilizarse. Para que los problemas de simultaneidad e identificaciÃ³n
desaparezcan y que OLS sea una estrategia eficiente de estimaciÃ³n y prueba se deben dar las
suposiciones de que que zt es dÃ©bilmente exÃ³geno (a2 = 0) y causalmente anterior a yt (c21 = 0).
CointegraciÃ³n con Exogeneidad DÃ©bil
Siguiendo a Engle, Hendry y Richard (1983), una variable x it es dÃ©bilmente exÃ³gena para el conjunto
de parÃ¡metros P si la distribuciÃ³n marginal de x it no contiene informaciÃ³n Ãºtil para realizar inferencias
sobre P. En un sistema cointegrado, si una variable no responde a la discrepancia de la relaciÃ³n de
equilibrio de largo plazo, es dÃ©bilmente exÃ³gena. Por lo tanto, si el parÃ¡metro de velocidad de ajuste ğ›¼i
es cero, la variable en cuestiÃ³n es dÃ©bilmente exÃ³gena. Se estima la ecuaciÃ³n no restringida
(v)
donde a partir de (iv), los coeficientes estimados son tales que ğ›½1 = ğ›¼1 âˆ’ ğœŒğ›¼2, ğ›½2 = (ğ›¼1 âˆ’ ğœŒğ›¼2)ğ›½ y ğ›½3 = ğœŒ.
Dado que los coeficientes son no restringidos, esta forma del modelo se llama a menudo un rezago
distribuido autorregresivo. Si zt es dÃ©bilmente exÃ³geno (es decir, si ğ›¼2 = 0), tus estimaciones de
coeficientes deberÃ­an ser tales que ğ›½1 = ğ›¼1, ğ›½2 = ğ›¼1ğ›½ y ğ›½3 = ğœŒ. AsÃ­, puedes identificar ğ›¼1, ğ›½ y ğœŒ a partir
de ğ›½1, ğ›½2 y ğ›½3.
(vi)
Aunque la exogeneidad dÃ©bil permite identificar el modelo, todavÃ­a
existe el problema
de probar adecuadamente para la cointegraciÃ³n. Dado que {yt} y {zt} son I(1), las estadÃ­sticas de prueba
de la hipÃ³tesis nula ğ›½1 = 0 y ğ›½2 = 0 en (v) no son estÃ¡ndar y necesitan ser tabuladas. La forma habitual
de probar la cointegraciÃ³n es utilizar la t-estadÃ­stica para la hipÃ³tesis nula ğ›½1 = 0 si esto ocurre no hay
correcciÃ³n de errores, por lo que yt no estÃ¡ cointegrado con zt.
Si comparas (v) con (i), puedes ver el beneficio de emplear la exogeneidad dÃ©bil. Dado que (v) tendrÃ¡
una varianza mÃ¡s pequeÃ±a que el tÃ©rmino de error en (i), los coeficientes de(v) pueden estimarse con
mÃ¡s precisiÃ³n que el coeficiente de (i). Los coeficientes de ytâˆ’1 y ztâˆ’1 no estÃ¡n restringidos.En los
enfoques de Engleâ€“Granger y Johansen, la llamada RestricciÃ³n de Factor ComÃºn obliga a que los
cambios a corto plazo en Î”yt sean una proporciÃ³n constante de la desviaciÃ³n del perÃ­odo anterior
respecto al equilibrio de largo plazo.
Inferencia sobre el Vector de CointegraciÃ³n: Supongamos que asumimos que la exogeneidad dÃ©bil se
cumple y concluimos que las variables estÃ¡n cointegradas (de modo que ğ›¼1 < 0 y ğ›¼2 = 0).
Como tal, es posible escribir (ii) y (v) como

(vii)
(viii)

Un problema de simultaneidad existe si los regresores que aparecen en (vii) dependen del tÃ©rmino de
error vt. La variable I(0) ytâˆ’1 âˆ’ ğ›½ztâˆ’1 estÃ¡ pre-determinada, por lo que no hay necesidad de preocuparse
por la influencia de ğ‘£ğ‘¡ en el tÃ©rmino de correcciÃ³n de errores. El problema clave concierne a la relaciÃ³n
contemporÃ¡nea entre Î”yt y Î”zt. Si Î”zt no se ve afectada por innovaciones en Î”yt, es apropiado realizar
inferencia sobre (vii) utilizando pruebas t y F estÃ¡ndar.
La ortogonalizaciÃ³n e1t = pe2t + vt donde e2t y vt no estÃ¡n correlacionados, es una descomposiciÃ³n de
Choleski en la que ğ›¥ğ‘§ğ‘¡ no responde a innovaciones en Î”yt pero Î”yt responde a innovaciones en Î”zt. Si
c21 = 0, se cumple que a e1t = ğœŒe2t + ğœ€yt y e2t = ğœ€zt. Dado que Î”zt = e2t no depende de ğœ€yt, no hay
retroalimentaciÃ³n de Î”yt a Î”zt, por lo que es posible utilizar inferencia estÃ¡ndar en (vi) o (vii).
Finalmente, nota que ğœŒ es el coeficiente de la variable estacionaria Î”zt. Por lo tanto, es apropiado
construir intervalos de confianza para ğœŒ utilizando una distribuciÃ³n t. Dado que zt puede ser en realidad
un vector de variables I(1), puedes estimar (v) para y t y un conjunto de variables dÃ©bilmente exÃ³genas
zt. Por ejemplo, con dos variables dÃ©bilmente exÃ³genas, z 1t y z2t, el modelo de correcciÃ³n de errores se
generaliza a

donde b1 = âˆ’ğ›½1/ğ›¼1 y b2 = âˆ’ğ›½2/ğ›¼1. Para probar la cointegraciÃ³n, utiliza el estadÃ­stico t para la hipÃ³tesis
nula ğ›¼1 = 0. Dado que tienes tres variables I(1) en el modelo, obtÃ©n los valores crÃ­ticos de la Tabla F con
k = 3. Por supuesto, si partimos de un proceso de orden superior, se deben agregar lags adicionales de
Î”ytâˆ’i, Î”z1tâˆ’i y Î”z2tâˆ’i a la ecuaciÃ³n. Al igual que en el caso de dos variables, debes asumir que Î”yt no tiene
efectos contemporÃ¡neos en ningÃºn valor de Î”zi.
11. COMPARING THE THREE METHODS
En esta secciÃ³n se comparan las pruebas de cointegraciÃ³n de Engle-Granger, Johansen y ADL utilizando
letras del Tesoro a tres meses y tasas de interÃ©s a 10 aÃ±os. Como ya hemos verificado que las tasas
individuales actÃºan como un proceso I(1), podemos omitir el paso preliminar de realizar pruebas previas
para raÃ­ces unitarias.
1. MetodologÃ­a Engle-Granger:
Dado que cada tasa actÃºa como un proceso de raÃ­z unitaria, podemos comenzar estimando la relaciÃ³n
de equilibrio de largo plazo
ğ‘Ÿğ¿ğ‘¡ = 1.642 + 0.915ğ‘Ÿğ‘†ğ‘¡ (6.71)
A continuaciÃ³n, probamos la estacionariedad de los residuos. Al
hacer las pruebas de rezagos se sugiere 1 rezago o 3. Si adoptamos
el SBC y utilizamos un cambio rezagado, obtenemos_
Con los valores crÃ­ticos, rechazamos la hipÃ³tesis nula de no cointegraciÃ³n.
Dado que no hacemos ninguna suposiciÃ³n sobre la exogeneidad dÃ©bil,
podemos usar ğ‘Ÿğ‘†ğ‘¡ como la variable del lado izquierdo:
De esta forma, la prueba de Engle-Granger tambiÃ©n respalda el hallazgo
de cointegraciÃ³n ya que la regresiÃ³n de los residuos produce:
2. MetodologÃ­a Johansen: Sea ğ‘¥ğ‘¡ el vector [ğ‘Ÿğ¿ğ‘¡ , ğ‘Ÿğ‘†ğ‘¡ ]â€² . Si se estima el
VAR no restringido, el SBC sugiere un rezago de 1, y el AIC un rezago de 8, pero se usarÃ¡ 1 rezago por
simplicidad. Dada esta longitud de rezago, es posible estimar el modelo. El valor estimado de la matriz
ğœ‹âˆ— es tal que:

Obtenemos las raÃ­ces caracterÃ­sticas ğœ†1 = 0.1295 y ğœ†2 = 0.0136. Luego, aplicamos la formula
âˆ’T ln(1 âˆ’ ğœ†1) + âˆ’T ln(1 âˆ’ ğœ†2), donde ğ»0 significa no cointegraciÃ³n, y ğ»1 significa 1 o 2 vectores
cointegrantes. Si el valor de la formula excede el VC, rechazamos H0, y habrÃ­a por lo menos 1 vector
cointegrante. SegÃºn los valores otorgado, se rechaza H0
Normalizando el vector de cointegraciÃ³n con respecto al rendimiento ğ‘Ÿğ¿ğ‘¡
ğ‘Ÿğ¿ğ‘¡ = 0.912 + 1.051ğ‘Ÿğ‘†ğ‘¡
Una diferencia clave entre esta estimaciÃ³n de la relaciÃ³n de equilibrio de largo plazo y las de la prueba
de Engle-Granger es que se puede realizar una inferencia estÃ¡ndar sobre los coeficientes del vector
de cointegraciÃ³n. Si reestima el modelo que impone la restricciÃ³n, y luego prueba la presencia de la
intersecciÃ³n, encontrarÃ¡ que el tÃ©rmino constante en el vector de cointegraciÃ³n es muy significativo.
El punto importante es que el estadÃ­stico t de los tÃ©rminos de correcciÃ³n de errores implica que la tasa
de largo plazo se ajusta a la discrepancia de la relaciÃ³n de equilibrio de largo plazo, pero la tasa de corto
plazo no. En otras palabras, ğ‘Ÿğ‘ ğ‘¡ es dÃ©bilmente exÃ³gena. Como tal, las desviaciones de la relaciÃ³n de largo
plazo son bastante duraderas.
3. MetodologÃ­a de CorrecciÃ³n de Errores:
Para usar esta metodologÃ­a es necesario asumir que una de las variables es dÃ©bilmente exÃ³gena. Si
asumimos que la tasa de corto plazo lo es, podemos estimar una ecuaciÃ³n de la forma:

Como no estamos tratando todas las variables simÃ©tricamente, no hay necesidad de restringir la longitud
del rezago representada por el polinomio ğ´1 (ğ¿) para que sea la misma que la de ğ´2 (ğ¿). Y segÃºn ciertas
pruebas, para este caso un rezago 6 es apropiado. Luego, se estima la ecuaciÃ³n:

Con los valores crÃ­ticos se rechaza la hipÃ³tesis nula de que hay cointregraciÃ³n, por lo que se concluye
que las variables estÃ¡n cointegradas
4. ComparaciÃ³n:
En este ejemplo particular, los tres enfoques encuentran que las variables estÃ¡n cointegradas. Sin
embargo, el enfoque de Engle-Granger no nos permite realizar fÃ¡cilmente inferencia del vector de
cointegraciÃ³n, pero el enfoque de Johansen nos permite concluir que dos tasas se mueven 1:1 a largo
plazo.
Si asumimos que ğ›½2 â‰  0, es posible realizar una inferencia sobre el coeficiente de ğ‘Ÿğ‘†ğ‘¡âˆ’1 en la relaciÃ³n
de equilibrio de largo plazo. Reestimamos:
âˆ†ğ‘Ÿğ¿ğ‘¡ = âˆ’0.187(0.914ğ‘Ÿğ¿ğ‘¡âˆ’1 âˆ’ ğ‘Ÿğ‘†ğ‘¡âˆ’1 âˆ’ 0.604) + 0.612âˆ†ğ‘Ÿğ‘†ğ‘¡ + ğ´1 (ğ¿)âˆ†ğ‘Ÿğ¿ğ‘¡âˆ’1 + ğ´2 (ğ¿)âˆ†ğ‘Ÿğ‘†ğ‘¡âˆ’1 + ğ‘£ğ‘¡
Donde ğ›½2 (= 0,187) es el coeficiente de una variable estacionaria que tiene una distribuciÃ³n t estÃ¡ndar,
si suponemos que ğ›½1 = ğ›½2 y reestimamos:
âˆ†ğ‘Ÿğ¿ğ‘¡ = âˆ’0.175(ğ‘Ÿğ¿ğ‘¡âˆ’1 âˆ’ ğ‘Ÿğ‘†ğ‘¡âˆ’1 âˆ’ 2.01) + 0.604âˆ†ğ‘Ÿğ‘†ğ‘¡ + ğ´1 (ğ¿)âˆ†ğ‘Ÿğ¿ğ‘¡âˆ’1 + ğ´2 (ğ¿)âˆ†ğ‘Ÿğ‘†ğ‘¡âˆ’1 + ğ‘£ğ‘¡
Podemos rastrear los efectos de un shock unitario en âˆ†ğ‘Ÿğ‘†ğ‘¡
Se podrÃ­a proceder a realizar la contabilidad de la innovaciÃ³n estimando una ecuaciÃ³n de la forma
âˆ†ğ‘Ÿğ‘†ğ‘¡ = ğ´3 (ğ¿)âˆ†ğ‘Ÿğ¿ğ‘¡ + ğ´4 (ğ¿)âˆ†ğ‘Ÿğ‘†ğ‘¡ + ğ‘’2ğ‘¡
DÃ³nde la ecuaciÃ³n estÃ¡ en primeras diferencias ya que la ecuaciÃ³n âˆ†ğ‘Ÿğ‘†ğ‘¡ no contiene un tÃ©rmino de
correcciÃ³n de errores. Y el supuesto de que âˆ†ğ‘Ÿğ‘†ğ‘¡ es dÃ©bilmente exÃ³geno implica un ordenamiento causal
de las innovaciones.

VECTOR AUTOREGRESSIONS (STOCK Y WATSON, 2001)
Christopher Sims (1980) proporcionÃ³ un nuevo marco macroeconomÃ©trico muy prometedor: las
autorregresiones vectoriales (VAR). Una autorregresiÃ³n univariante es un modelo lineal de una sola
ecuaciÃ³n y una sola variable en el que el valor actual de una variable se explica por sus propios valores
rezagados. Un VAR es un modelo lineal de n-ecuaciÃ³n y n-variable en el que cada variable se explica a
su vez por sus propios valores rezagados, mÃ¡s los valores actuales y pasados de las restantes ğ‘› âˆ’
1 variables. Este sencillo marco proporciona una forma sistemÃ¡tica de capturar dinÃ¡micas enriquecidas
en mÃºltiples series temporales, y el conjunto de herramientas estadÃ­sticas que venÃ­a con los VAR era
fÃ¡cil de usar e interpretar. Como argumentaron Sims (1980) y otros en una serie de influyentes artÃ­culos
iniciales, los VAR ofrecÃ­an la promesa de proporcionar un enfoque coherente y creÃ­ble para la
descripciÃ³n de datos, la predicciÃ³n, la inferencia estructural y el anÃ¡lisis de polÃ­ticas.
En este artÃ­culo, evaluamos quÃ© tan bien los VAR han abordado cuatro tareas macroeconomÃ©tricas.
1.
2.
3.
4.

DescripciÃ³n de datos
PronÃ³stico
Inferencia Estructural
AnÃ¡lisis de PolÃ­ticas

Nuestra respuesta es "depende". En la descripciÃ³n y previsiÃ³n de datos, los VAR han demostrado ser
herramientas potentes y fiables que ahora, con razÃ³n, son de uso diario. Sin embargo, la inferencia
estructural y el anÃ¡lisis de polÃ­ticas son inherentemente mÃ¡s difÃ­ciles porque requieren diferenciar entre
correlaciÃ³n y causalidad; Este es el "problema de identificaciÃ³n", en la jerga de la econometrÃ­a. Este
problema no puede ser resuelto por una herramienta puramente estadÃ­stica, ni siquiera una poderosa
como un VAR, sino que se requiere teorÃ­a econÃ³mica o conocimiento institucional para resolver el
problema de identificaciÃ³n (causalidad versus correlaciÃ³n).
Un vistazo al interior de la caja de herramientas del VAR:
Los VAR vienen en tres variedades: de forma reducida, recursivos y estructurales.
Una forma reducida VAR expresa cada variable como una funciÃ³n lineal de sus propios valores
pasados, considerando los valores pasados de todas las demÃ¡s variables y un tÃ©rmino de error no
correlacionado en serie. Cada ecuaciÃ³n se estima mediante regresiÃ³n de mÃ­nimos cuadrados ordinarios.
El nÃºmero de valores rezagados a incluir en cada ecuaciÃ³n se puede determinar mediante varios mÃ©todos
diferentes.
Los tÃ©rminos de error en estas regresiones son los movimientos "sorpresa" en las variables despuÃ©s de
tener en cuenta sus valores pasados. Si las diferentes variables estÃ¡n correlacionadas entre sÃ­, como suele
ocurrir en las aplicaciones macroeconÃ³micas, entonces los tÃ©rminos de error en el modelo de forma
reducida tambiÃ©n se correlacionan entre ecuaciones.
Un VAR recursivo construye los tÃ©rminos de error en cada ecuaciÃ³n de regresiÃ³n para que no estÃ©n
correlacionados con el error en las ecuaciones anteriores. Esto se hace incluyendo juiciosamente algunos
valores contemporÃ¡neos como regresores.
Considere un VAR de tres variables, ordenado como 1) la inflaciÃ³n, 2) la tasa de desempleo y 3) la tasa
de interÃ©s. En la primera ecuaciÃ³n del VAR recursivo correspondiente, la inflaciÃ³n es la variable
dependiente, y los regresores son los valores rezagados de las tres variables. En la segunda ecuaciÃ³n, la
tasa de desempleo es la variable dependiente, y los regresores son los rezagos de las tres variables mÃ¡s
el valor actual de la tasa de inflaciÃ³n. La tasa de interÃ©s es la variable dependiente en la tercera ecuaciÃ³n,
y los regresores son los rezagos de las tres variables, el valor actual de la tasa de inflaciÃ³n mÃ¡s el valor
actual de la tasa de desempleo. La estimaciÃ³n de cada ecuaciÃ³n por mÃ­nimos cuadrados ordinarios
produce residuos que no estÃ¡n correlacionados entre ecuaciones. Evidentemente, los resultados
dependen del orden de las variables: al cambiar el orden, cambian las ecuaciones, los coeficientes y los
residuos del VAR, y hay ğ‘›! VAR recursivos que representan todos los ordenamientos posibles.

Un VAR estructural utiliza la teorÃ­a econÃ³mica para clasificar los vÃ­nculos contemporÃ¡neos entre las
variables. Los VAR estructurales requieren "identificar supuestos" que permitan interpretar causalmente
las correlaciones. Estos supuestos de identificaciÃ³n pueden involucrar todo el VAR, de modo que se
expliquen todos los vÃ­nculos causales en el modelo, o solo una ecuaciÃ³n, de modo que solo se identifique
un vÃ­nculo causal especÃ­fico. De esta manera se producen variables instrumentales que permiten estimar
los vÃ­nculos contemporÃ¡neos mediante la regresiÃ³n de variables instrumentales. El nÃºmero de VAR
estructurales estÃ¡ limitado Ãºnicamente por la inventiva del investigador.
Poner a prueba el VAR de tres variables:
La prÃ¡ctica estÃ¡ndar en el anÃ¡lisis VAR es informar los resultados de las pruebas de causalidad de
Granger, las respuestas a impulsos y las descomposiciones de la varianza del error de pronÃ³stico. Estas
estadÃ­sticas son calculadas automÃ¡ticamente (o casi) por muchos paquetes economÃ©tricos (RATS,
Eviews, TSP y otros). Debido a la complicada dinÃ¡mica del VAR, estas estadÃ­sticas son mÃ¡s informativas
que los coeficientes de regresiÃ³n VAR estimados o las estadÃ­sticas R2, que normalmente no se informan.
Los estadÃ­sticos de causalidad de Granger examinan si los valores rezagados de una variable ayudan a
predecir otra variable.
Las respuestas a impulsos trazan la respuesta de los valores actuales y futuros de cada una de las
variables a un aumento de una unidad en el valor actual de uno de los errores VAR, asumiendo que este
error vuelve a cero en perÃ­odos posteriores y que todos los demÃ¡s errores son iguales a cero. El
experimento mental implÃ­cito de cambiar un error mientras se mantiene constantes los demÃ¡s tiene mÃ¡s
sentido cuando los errores no estÃ¡n correlacionados entre ecuaciones, por lo que las respuestas de
impulso se calculan tÃ­picamente para VAR recursivos y estructurales.
Â¿QuÃ© tan bien realizan los VAR las cuatro tareas?
Pasamos ahora a una evaluaciÃ³n de los VAR en la realizaciÃ³n de las cuatro tareas macroeconomÃ©tricas,
destacando tanto los Ã©xitos como las deficiencias.
DescripciÃ³n de los datos:
Debido a que los VAR involucran valores actuales y retrasados de mÃºltiples series temporales, capturan
comovimientos que no se pueden detectar en modelos univariados o bivariados. Las estadÃ­sticas estÃ¡ndar
de resumen del VAR, como las pruebas de causalidad de Granger, las funciones de respuesta al impulso
y las descomposiciones de la varianza, son mÃ©todos bien aceptados y ampliamente utilizados para
representar estos comovimientos. Estas estadÃ­sticas resumidas son Ãºtiles porque proporcionan objetivos
para los modelos macroeconÃ³micos teÃ³ricos.
Por supuesto, los mÃ©todos de VAR descritos aquÃ­ tienen algunas limitaciones. Una de ellas es que los
mÃ©todos estÃ¡ndar de inferencia estadÃ­stica (como el cÃ¡lculo de errores estÃ¡ndar para las respuestas a
impulsos) pueden dar resultados engaÃ±osos si algunas de las variables son muy persistentes. Otra
limitaciÃ³n es que, sin modificaciones, los VAR estÃ¡ndar pasan por alto no linealidades,
heterocedasticidad condicional y desviaciones o rupturas en los parÃ¡metros.
PronÃ³stico:
Los VAR pequeÃ±os se han convertido en un punto de referencia con el que se juzgan los nuevos sistemas
de predicciÃ³n. Sin embargo, si bien son Ãºtiles como punto de referencia, los VAR pequeÃ±os de dos o tres
variables son a menudo inestables y, por lo tanto, malos predictores del futuro (Stock y Watson, 1996).
Los sistemas de predicciÃ³n VAR de Ãºltima generaciÃ³n contienen mÃ¡s de tres variables y permiten que
los parÃ¡metros variables en el tiempo capturen desviaciones importantes en los coeficientes (Sims,
1993).
Sin embargo, la adiciÃ³n de variables al VAR crea complicaciones, ya que el nÃºmero de parÃ¡metros del
VAR aumenta a medida que aumenta el cuadrado del nÃºmero de variables. Desafortunadamente, los
datos de series cronolÃ³gicas macroeconÃ³micas no pueden proporcionar estimaciones fiables de todos
estos coeficientes sin mÃ¡s restricciones.

Una forma de controlar el nÃºmero de parÃ¡metros en los modelos VAR grandes es imponer una estructura
comÃºn a los coeficientes, ejemplo: mÃ©todos bayesianos.
Inferencia Estructural:
A continuaciÃ³n, se presentan tres crÃ­ticas importantes al modelado estructural del VAR:
1. En gran parte, los shocks, al igual que los de la regresiÃ³n convencional, reflejan factores
omitidos en el modelo. Si estos factores se correlacionan con las variables incluidas, entonces
las estimaciones del VAR contendrÃ¡n el sesgo de las variables omitidas.
2. En segundo lugar, las reglas de polÃ­tica cambian con el tiempo, y las pruebas estadÃ­sticas
formales revelan una inestabilidad generalizada en los VAR de baja dimensiÃ³n (Stock y Watson,
1996). Los VAR estructurales de parÃ¡metros constantes que pasan por alto esta inestabilidad se
identifican incorrectamente.
3. En tercer lugar, las convenciones de temporizaciÃ³n de los VAR no reflejan necesariamente la
disponibilidad de datos en tiempo real, lo que socava el mÃ©todo comÃºn de identificaciÃ³n de
restricciones basado en supuestos de tiempo.
En esta discusiÃ³n, hemos distinguido cuidadosamente entre VAR recursivos y estructurales: los VAR
recursivos utilizan un mÃ©todo mecÃ¡nico arbitrario para modelar la correlaciÃ³n contemporÃ¡nea en las
variables, mientras que los VAR estructurales utilizan la teorÃ­a econÃ³mica para asociar estas
correlaciones con relaciones causales.
A pesar de estas crÃ­ticas, creemos que es posible tener supuestos identificativos creÃ­bles en un VAR. Un
enfoque consiste en explotar el conocimiento institucional detallado. Otro ejemplo es Bernanke y Mihov
(1998), quienes utilizan un modelo del mercado de reservas para identificar los shocks de polÃ­tica
monetaria. Un enfoque diferente de la identificaciÃ³n consiste en utilizar restricciones a largo plazo para
identificar las perturbaciones.
AnÃ¡lisis de polÃ­ticas:
A travÃ©s de un VAR se pueden analizar dos tipos de polÃ­ticas: las innovaciones puntuales, en las que se
mantiene la misma regla; y cambios en la regla de polÃ­tica. El efecto estimado de las innovaciones
puntuales es una funciÃ³n de las respuestas impulsivas a una innovaciÃ³n polÃ­tica, y ya se han examinado
los posibles escollos asociados a ellas. Las cosas son mÃ¡s difÃ­ciles si se quiere estimar el efecto de
cambiar las reglas polÃ­ticas. Si las verdaderas ecuaciones estructurales implican expectativas (por
ejemplo, una curva de Phillips expectativa), entonces las expectativas dependerÃ¡n de la regla de polÃ­tica;
por lo que, en general, todos los coeficientes del VAR dependerÃ¡n de la regla. Esta es sÃ³lo una versiÃ³n
de la crÃ­tica de Lucas (1976). La importancia prÃ¡ctica de la crÃ­tica de Lucas para este tipo de anÃ¡lisis de
la polÃ­tica del VAR es un tema de debate.
ConclusiÃ³n:
Los VAR son herramientas poderosas para describir datos y generar pronÃ³sticos de referencia
multivariantes confiables. Queda trabajo tÃ©cnico por hacer, sobre todo extender los VAR a dimensiones
mÃ¡s altas y estructuras no lineales mÃ¡s ricas. Sin embargo, incluso sin estas importantes extensiones, los
VAR han hecho contribuciones duraderas al conjunto de herramientas del macroeconometrista para
abordar estas dos tareas.
Los VAR estructurales pueden capturar propiedades dinÃ¡micas ricas de mÃºltiples series temporales, pero
sus implicaciones estructurales son tan sÃ³lidas como sus esquemas de identificaciÃ³n. Si bien hay algunos
ejemplos de tratamientos reflexivos de la identificaciÃ³n en los VAR, con demasiada frecuencia en la
literatura del VAR el tema central de la identificaciÃ³n se maneja ignorÃ¡ndolo. En algunos campos de la
economÃ­a, como la economÃ­a laboral y las finanzas pÃºblicas, la identificaciÃ³n puede obtenerse de manera
creÃ­ble utilizando experimentos naturales que permiten extraer alguna variaciÃ³n exÃ³gena de una relaciÃ³n
que de otro modo estarÃ­a cargada de sesgo de endogeneidad y variables omitidas.
Desafortunadamente, este tipo de experimentos naturales son raros en macroeconomÃ­a. Aunque los VAR
tienen limitaciones en lo que respecta a la inferencia estructural y el anÃ¡lisis de polÃ­ticas, tambiÃ©n las

tienen las alternativas. Los modelos macroeconÃ³micos de equilibrio general estocÃ¡stico dinÃ¡mico
calibrado son explÃ­citos en cuanto a los vÃ­nculos causales y las expectativas, y proporcionan un marco
intelectualmente coherente para el anÃ¡lisis de polÃ­ticas. Pero la generaciÃ³n actual de estos modelos no
se ajusta bien a los datos. En el otro extremo, los modelos simples de una sola ecuaciÃ³n, por ejemplo,
las regresiones de la inflaciÃ³n frente a las tasas de interÃ©s rezagadas, son fÃ¡ciles de estimar y, a veces,
pueden producir buenos pronÃ³sticos. Pero si es difÃ­cil distinguir correlaciÃ³n y causalidad en un VAR, lo
es aÃºn mÃ¡s en los modelos de una sola ecuaciÃ³n, que pueden, en cualquier caso, verse como una ecuaciÃ³n
extraÃ­da de un VAR mÃ¡s grande.
Si se utilizan sabiamente y se basan en el razonamiento econÃ³mico y los detalles institucionales, los
VAR pueden ajustarse a los datos y, en el mejor de los casos, pueden proporcionar estimaciones
razonables de algunas conexiones causales. El desarrollo y la combinaciÃ³n de una buena teorÃ­a y detalles
institucionales con mÃ©todos estadÃ­sticos flexibles como los VAR deberÃ­an mantener ocupados a los
macroeconomistas hasta bien entrado el nuevo siglo.
MODELACIÃ“N: VAR DEL PAPER
A muchos macroeconomistas les gusta pensar que conocen las respuestas a estas y otras preguntas
similares, tal vez con un modesto rango de incertidumbre. En las siguientes dos secciones, echamos un
vistazo cuantitativo a estas y otras preguntas relacionadas utilizando varios VAR de tres variables
estimados utilizando datos trimestrales de EE. UU. sobre la tasa de inflaciÃ³n de precios (ğœ‹ğ‘¡ ), la tasa de
desempleo (ğ‘¢ğ‘¡ ) y la tasa de interÃ©s (ğ‘…ğ‘¡ , especÃ­ficamente, la tasa de fondos federales) desde 1960: ğ¼
hasta 2000: ğ¼ğ‘‰.2 Primero, construimos y examinamos estos modelos como una forma de mostrar el
conjunto de herramientas del VAR
En nuestro ejemplo de tres variables, consideramos dos VAR estructurales relacionados. Cada uno
incorpora un supuesto diferente que identifica la influencia causal de la polÃ­tica monetaria sobre el
desempleo, la inflaciÃ³n y las tasas de interÃ©s. La primera se basa en una versiÃ³n de la "regla de Taylor",
en la que se modela que la Reserva Federal establece la tasa de interÃ©s en funciÃ³n de las tasas pasadas
de inflaciÃ³n y desempleo.5 En este sistema, la Fed establece la tasa de fondos federales R de acuerdo
con la regla
En nuestro ejemplo de tres variables, consideramos dos VAR estructurales relacionados. Cada uno
incorpora un supuesto diferente que identifica la influencia causal de la polÃ­tica monetaria sobre el
desempleo, la inflaciÃ³n y las tasas de interÃ©s. La primera se basa en una versiÃ³n de la "regla de Taylor",
en la que se modela que la Reserva Federal establece la tasa de interÃ©s en funciÃ³n de las tasas pasadas
de inflaciÃ³n y desempleo. En este sistema, la Fed establece la tasa de fondos federales R de acuerdo con
la regla:

ğ‘Ÿ âˆ— : tasa de interÃ©s real deseada
:valores promedio de la inflaciÃ³n
tasa de desempleo en los Ãºltimos cuatro trimestres
valor objetivo de inflaciÃ³n
valor objetivo de desempleo
Esta relaciÃ³n se convierte en la ecuaciÃ³n de la tasa de interÃ©s en el VAR estructural.
La regla de Taylor es "retrospectiva" en el sentido de que la Fed reacciona a la informaciÃ³n pasada
y
son promedios de los Ãºltimos cuatro trimestres de inflaciÃ³n y desempleo), y varios investigadores
han argumentado que el comportamiento de la Fed se describe mÃ¡s apropiadamente por el

comportamiento prospectivo. Por ello, nos planteamos otra variante del modelo en el que la Fed
reacciona a las previsiones de inflaciÃ³n y desempleo a cuatro trimestres vista. Esta regla de Taylor tiene
la misma forma que la regla anterior, pero con
ty
trimestres calculados a partir de la forma reducida VAR.

reemplazados por pronÃ³sticos de cuatro

Â¿QuÃ© tan sensibles son los resultados a la suposiciÃ³n de identificaciÃ³n especÃ­fica utilizada en este VAR
estructural, a saber, que la Fed sigue la regla de Taylor retrospectiva?
Da la casualidad de que es muy sensible. Las respuestas impulsivas en las tasas de interÃ©s reales son
muy similares bajo cualquiera de las dos reglas. Sin embargo, en el modelo prospectivo, el choque
monetario produce un aumento de 0,5 puntos porcentuales en la tasa de desempleo en el plazo de un
aÃ±o, y la tasa de inflaciÃ³n cae bruscamente al principio, fluctÃºa y luego deja una disminuciÃ³n neta de
0,5 puntos porcentuales despuÃ©s de seis aÃ±os. SegÃºn la regla retrospectiva, esta subida de tipos de 100
puntos bÃ¡sicos produce una leve desaceleraciÃ³n econÃ³mica y un modesto descenso de la inflaciÃ³n dentro
de varios aÃ±os; bajo la regla prospectiva, con esta misma acciÃ³n la Fed obtiene una gran victoria contra
la inflaciÃ³n a costa de una recesiÃ³n rÃ¡pida y aguda.
Si la intervenciÃ³n es un movimiento inesperado en la tasa de interÃ©s de los fondos federales, entonces el
efecto estimado de esta polÃ­tica sobre las tasas futuras de inflaciÃ³n y desempleo se resume mediante las
funciones de respuesta al impulso. Esto puede parecer una polÃ­tica un tanto extraÃ±a, pero se puede
utilizar la misma mecÃ¡nica para evaluar una intervenciÃ³n mÃ¡s realista, como aumentar la tasa de fondos
federales en 50 puntos bÃ¡sicos y mantener este aumento durante un aÃ±o. Esta polÃ­tica puede diseÃ±arse
en un VAR utilizando la secuencia correcta de innovaciones de polÃ­tica monetaria para mantener la tasa
de interÃ©s de los fondos federales en este nivel sostenido durante cuatro trimestres, teniendo en cuenta
que en el VAR, las acciones sobre las tasas de interÃ©s en trimestres anteriores afectan a las de trimestres
posteriores (Sims, 1982; Waggoner y Zha, 1999). El anÃ¡lisis del segundo tipo de polÃ­tica â€”un cambio
en la propia regla monetariaâ€” es mÃ¡s complicado.
El anÃ¡lisis del segundo tipo de polÃ­tica â€”un cambio en la propia regla monetariaâ€” es mÃ¡s complicado.
Una forma de evaluar a un candidato a una nueva regla de polÃ­tica monetaria es preguntarse cuÃ¡l serÃ­a
el efecto de los shocks monetarios y no monetarios en la economÃ­a bajo la nueva regla. Dado que esta
pregunta involucra todas las perturbaciones estructurales, responderla requiere un modelo
macroeconÃ³mico completo de la determinaciÃ³n simultÃ¡nea de todas las variables, y esto significa que
se deben especificar todos los vÃ­nculos causales en el VAR estructural. En este caso, el anÃ¡lisis de la
polÃ­tica se lleva a cabo de la siguiente manera: se estima un VAR estructural en el que se identifican
todas las ecuaciones, luego se forma un nuevo modelo reemplazando la regla de polÃ­tica monetaria. La
comparaciÃ³n de las respuestas impulsivas en los dos modelos muestra cÃ³mo el cambio en la polÃ­tica ha
alterado los efectos de los shocks monetarios y no monetarios en las variables del modelo.

THE DYNAMIC EFFECTS OF AGGREGATE DEMAND AND SUPPLY DISTURBANCES
(BLANCHARD-QUAH, 1989)
Abstract: Interpretamos que las fluctuaciones en el Producto Interno Bruto (PIB) y el desempleo se
deben a dos tipos de perturbaciones: las que tienen un efecto permanente en la producciÃ³n y las que no
lo tienen. Las primeras las vemos como perturbaciones en la oferta, mientras que las segundas las
consideramos perturbaciones en la demanda. Las perturbaciones en la demanda tienen un efecto en
forma de montÃ­culo en la producciÃ³n y el desempleo, como una imagen especular. El efecto de las
perturbaciones en la oferta en la producciÃ³n aumenta gradualmente con el tiempo, alcanzando su punto
mÃ¡ximo despuÃ©s de dos aÃ±os y estabilizÃ¡ndose despuÃ©s de cinco aÃ±os.
IntroducciÃ³n: En los Ãºltimos tiempos, el PBI ya ha sido aceptado ampliamente como un proceso de
raÃ­z unitaria, aclarando que una innovaciÃ³n positiva en el PBI deberÃ­a llevar a revisar al alza el
pronÃ³stico del PBI para todos los horizontes.
Al considerar esto, si solo hay un tipo de perturbaciÃ³n, la interpretaciÃ³n es clara y se puede identificar y
entender fÃ¡cilmente su efecto en la economÃ­a con una representaciÃ³n estimada de promedio mÃ³vil
univariante. Sin embargo, si hay mÃºltiples tipos de perturbaciones, la interpretaciÃ³n se complica, ya que
la respuesta econÃ³mica serÃ­a una combinaciÃ³n de los efectos dinÃ¡micos de cada perturbaciÃ³n, y en este
caso se podrÃ­an imponer restricciones a priori en la respuesta del PBI a cada una de las perturbaciones
o aprovechar la informaciÃ³n de variables macro distintas al PBI
El enfoque de este paper se basa en suponer que existen dos tipos de perturbaciones independientes (sin
correlaciÃ³n), se asume que ninguna tiene efecto a largo plazo en el desempleo, pero la primera
perturbaciÃ³n sÃ­ tiene un efecto a largo plazo en la producciÃ³n (que se conocerÃ¡ como perturbaciones de
oferta) y la segunda no (se conocerÃ¡ como perturbaciones de demanda).
Bajo estas restricciones, las perturbaciones en la demanda causan picos en la producciÃ³n y el desempleo
que desaparecen despuÃ©s de uno a tres aÃ±os, mientras que las perturbaciones en la oferta aumentan
gradualmente la producciÃ³n y pueden aumentar temporalmente el desempleo, luego disminuye
gradualmente.
Hay que tener en cuenta que, aunque la descripciÃ³n dinÃ¡mica es precisa, la contribuciÃ³n exacta de las
perturbaciones en la demanda y la oferta a las fluctuaciones en la producciÃ³n no estÃ¡ claramente
definida. La serie de producciÃ³n basada en la demanda muestra similitudes con los ciclos econÃ³micos,
pero al realizar la descomposiciÃ³n de varianza, las contribuciones precisas de cada tipo de perturbaciÃ³n
no estÃ¡n bien estimadas
1. IdentificaciÃ³n
Los supuestos son:
â€¢
â€¢
â€¢
â€¢
â€¢

Dos perturbaciones que afectan al desempleo y la producciÃ³n, ambas sin efectos a largo plazo
en el desempleo, pero difieren en la producciÃ³n
PerturbaciÃ³n con efecto a largo plazo en la producciÃ³n (permanente): De Oferta
PerturbaciÃ³n sin efecto a largo plazo en la producciÃ³n (temporal): De Demanda
Ambas perturbaciones no estÃ¡n correlacionadas entre sÃ­ (pueden correlacionarse en serie, pero
bajo ciertas condiciones, cada una puede representarse como una serie de rezagos de
perturbaciones no correlacionadas)
Las innovaciones en el crecimiento de la producciÃ³n y el desempleo son combinaciones lineales
de estas perturbaciones.

Ahora derivamos el proceso conjunto seguido por la producciÃ³n y el desempleo implicado por nuestras
suposiciones. Siendo ğ‘Œ el logaritmo del PBI y ğ‘ˆ el nivel de la tasa de desempleo, asÃ­ como ğ‘’ğ‘‘ y ğ‘’ğ‘  serÃ­an
las dos perturbaciones (d de demanda, s de supply). X serÃ¡ el vector (âˆ†ğ‘Œ, ğ‘ˆ)â€² y ğ‘’ el vector de las
perturbaciones (ğ‘’ğ‘‘ , ğ‘’ğ‘  )â€².

Las suposiciones anteriores implican que X sigue un proceso estacionario dado por:
âˆ

ğ‘‹(ğ‘¡) = ğ´(0) ğ‘’(ğ‘¡) + ğ´(1)ğ‘’(ğ‘¡ âˆ’ 1) + â‹¯ = âˆ‘ ğ´(ğ‘—)ğ‘’(ğ‘¡ âˆ’ ğ‘—)

(1)

ğ‘—=0

En esta ecuaciÃ³n, ğ‘Œ y ğ‘ˆ son expresados como rezagos distribuidos de las dos perturbaciones, ğ‘’ğ‘‘ y ğ‘’ğ‘  , y
como ambas son no correlacionadas, su matriz de covarianza de varianza es diagonal, por lo que se
puede asumir que es una matriz identidad por conveniencia.
El efecto contemporÃ¡neo de ğ‘’ en ğ‘‹ se describe con ğ´(0); los efectos rezagados son ğ´(ğ‘—), ğ‘— â‰¥ 1. Al ser
X estacionario, las perturbaciones no tienen efecto a largo plazo en el desempleo ni en el PIB, y se
agrega una restricciÃ³n de que la suma de los elementos de la primera fila de A sea cero, lo que implica
que ğ‘’ğ‘‘ no afecta el nivel de ğ‘Œ, pues la suma de sus efectos en ğ‘Œ es 0: âˆ‘âˆ
ğ‘—=0 ğ‘11 (ğ‘—) = 0
Ahora mostramos cÃ³mo recuperar esta representaciÃ³n a partir de los datos. Dado que X es estacionario,
tiene una representaciÃ³n de media mÃ³vil de Wold:
âˆ

ğ‘‹(ğ‘¡) = ğœˆ(ğ‘¡) + ğ¶(1)ğœˆ(ğ‘¡ âˆ’ 1) + â‹¯ = âˆ‘ ğ¶(ğ‘—) ğœˆ(ğ‘¡ âˆ’ ğ‘—) (2)
ğ‘—=0

Esta representaciÃ³n de media mÃ³vil es Ãºnica y se puede obtener primero estimando y luego invirtiendo
la representaciÃ³n autorregresiva vectorial de X de la manera habitual.
Al comparar las ecuaciones (1) y (2), vemos que ğœˆ, el vector de innovaciones, y ğ‘’, el vector de
perturbaciones originales, estÃ¡n relacionados por ğœˆ = ğ´(0)ğ‘’, y que ğ´(ğ‘—) = ğ¶(ğ‘—)ğ´(0), para todo j. AsÃ­
que conocer A(0) permite recuperar ğ‘’ a partir de ğœˆ, y obtener A(j) a partir de C(j). Asimismo, se menciÃ³n
que A(0) es identificable mediante un argumento matemÃ¡tico y el factor Q de Choleski
En resumen, el procedimiento que realizan es el siguiente: Primero estiman una representaciÃ³n
autorregresiva vectorial para ğ‘‹, y la invierten para obtener (2). Luego, construyen la matriz ğ´(0); y se
usa para obtener ğ´(ğ‘—) = ğ¶(ğ‘—)ğ´(0), y ğ‘’ğ‘¡ = ğ´(0)âˆ’1 ğœˆğ‘¡ . Esto proporciona la producciÃ³n y el desempleo
como funciones de las perturbaciones de demanda y oferta actuales y pasadas.
2. InterpretaciÃ³n
Interpretar los residuos como perturbaciones "estructurales" en sistemas de baja dimensionalidad
siempre es arriesgado. La interpretaciÃ³n de perturbaciones de oferta y demanda de los investigadores se
basa en una perspectiva keynesiana tradicional. Se proporciona un modelo simple para ilustrar estas
ideas, basado en el trabajo de Stanley Fischer (1977):
ğ‘Œ: Logaritmo de la producciÃ³n
ğ‘: Empleo
ğœƒ: Productividad
Ì…: RepresentaciÃ³n del pleno empleo
ğ‘
ğ‘ƒ: Logaritmo de nivel de precios
ğ‘Š: Salario nominal
ğ‘€: Oferta monetaria
La ecuaciÃ³n (3) dice que la demanda agregada es una funciÃ³n de los saldos reales y la productividad,
(4) es la funciÃ³n de producciÃ³n al relacionar producciÃ³n, empleo y productividad, y asume retornos
constantes a escala, (5) describe el comportamiento de fijaciÃ³n de precios y es funciÃ³n del salario
nominal y la productividad, (6) caracteriza el comportamiento de fijaciÃ³n de salarios en la economÃ­a: el
salario se elige un perÃ­odo por adelantado y se establece de manera que se logre el pleno empleo
(esperado).
TambiÃ©n debemos especificar cÃ³mo evolucionan ğ‘€ y ğœƒ: (a travÃ©s de shocks de demanda y oferta)

Ì… âˆ’ ğ‘, al resolver para desempleo y crecimiento de la producciÃ³n
Definiendo el desempleo ğ‘ˆ como ğ‘
obtenemos:
âˆ†ğ‘Œ = ğ‘’ğ‘‘ (ğ‘¡) âˆ’ ğ‘’ğ‘‘ (ğ‘¡ âˆ’ 1) + ğ‘ âˆ™ (ğ‘’ğ‘  (ğ‘¡) âˆ’ ğ‘’ğ‘  (ğ‘¡ âˆ’ 1)) + ğ‘’ğ‘  (ğ‘¡)
ğ‘ˆ = âˆ’ğ‘’ğ‘‘ (ğ‘¡) âˆ’ ğ‘ âˆ™ ğ‘’ğ‘  (ğ‘¡)
Ambas ecuaciones cumplen con las restricciones de la ecuaciÃ³n (1), ya que, por rigideces nominales,
las perturbaciones en la demanda tendrÃ¡n efectos temporales y a corto plazo en la producciÃ³n y el
desempleo, mientras que, a largo plazo solo habrÃ¡ efecto con las perturbaciones de oferta. Asimismo,
ninguna perturbaciÃ³n afecta a largo plazo al desempleo
Cuestionamientos:
Aunque se podrÃ­a cuestionar sobre la no correlaciÃ³n entre las perturbaciones de oferta y demanda, el
modelo sugiere que incluso al ser son independientes, las perturbaciones en la oferta podrÃ­an afectar
directamente la demanda agregada, por lo que la independencia no limita los posibles impactos de estas
perturbaciones en la producciÃ³n y el desempleo.
AdemÃ¡s, aunque se podrÃ­a pensar que las perturbaciones de demanda pueden tener efectos permanentes,
los autores argumentan que estos efectos son mÃ­nimos en comparaciÃ³n con los de la oferta, por lo que
los consideran transitorios y los excluyen de su anÃ¡lisis.
Sin embargo, si hay mÃºltiples fuentes de perturbaciones con diversos efectos en la producciÃ³n y el
desempleo, la interpretaciÃ³n de solo dos perturbaciones puede ser insuficiente, lo que podrÃ­a complicar
la estimaciÃ³n al tener que considerar mÃºltiples factores.
Tendencia y ciclo:
DespuÃ©s de la estimaciÃ³n, podemos crear dos series de producciÃ³n: una que muestre solo los efectos de
las perturbaciones en la oferta, que serÃ¡ no estacionaria y otra que muestre solo los efectos de las
perturbaciones en la demanda, que serÃ¡ estacionaria. Es tentador asociar la primera serie a la
"tendencia" de la producciÃ³n y la segunda al "ciclo econÃ³mico". Sin embargo, esto no estÃ¡ justificado,
ya que las perturbaciones en la oferta tambiÃ©n afectan tanto al ciclo econÃ³mico como a la tendencia.
3. EstimaciÃ³n
Antes de la estimaciÃ³n, nos encontramos con un problema final. Nuestra representaciÃ³n asume que el
desempleo y la primera diferencia del logaritmo del PIB son estacionarios. Sin embargo, los datos de
EE. UU. despuÃ©s de la guerra sugieren un aumento gradual del desempleo y una disminuciÃ³n del
crecimiento del PIB desde los aÃ±os 70. Esto plantea dos problemas:
1. Nuestras suposiciones bÃ¡sicas podrÃ­an estar equivocadas: Por ejemplo, el desempleo podrÃ­a ser
no estacionario y estar afectado por perturbaciones de demanda y oferta
2. CÃ³mo manejar la tendencia temporal aparente en el desempleo y la desaceleraciÃ³n aparente en
el crecimiento desde mediados de la dÃ©cada de 1970: Al no haber una soluciÃ³n especÃ­fica, se
adopta un enfoque eclÃ©ctico, donde se presentan los resultados de la estimaciÃ³n permitiendo un
cambio en la tasa de crecimiento del PBI, y se ajusta una lÃ­nea de regresiÃ³n de tendencia
temporal para capturar los cambios en el desempleo
Se estimÃ³ un sistema VAR en el crecimiento real del PIB y la tasa de desempleo, permitiendo ocho
rezagos, utilizando datos desde 1950 hasta 1987. Los datos del PIB son trimestrales; y los datos
mensuales de desempleo se promedian para obtener observaciones trimestrales. Antes de estimar el
VAR, se eliminan las medias de muestra diferentes para el crecimiento del PIB y la tasa de desempleo
cuando se permite un cambio en estas variables. Se analizarÃ¡ solo el caso base
4. Efectos dinÃ¡micos de las perturbaciones de demanda y oferta
Se verÃ¡n estos efectos en las Figuras 1 y 2, los ejes verticales en estas figuras representan
simultÃ¡neamente el logaritmo del producto y la tasa de desempleo, mientras que el eje horizontal
representa el tiempo en trimestres. Las figuras 3-6 usan bandas y ofrecen la misma informaciÃ³n

Perturbaciones en la demanda:
Las perturbaciones en la demanda generan un aumento temporal en
la producciÃ³n y el desempleo, que alcanza su punto mÃ¡ximo despuÃ©s
de dos a cuatro trimestres. Sin embargo, estos efectos desaparecen
despuÃ©s de unos tres a cinco aÃ±os, y la respuesta en la producciÃ³n es
menor si no se consideran cambios en el desempleo a largo plazo.
Permitir un cambio en la tasa de crecimiento de la producciÃ³n reduce
la importancia de los cambios a largo plazo en el desempleo en las
respuestas a las perturbaciones en la demanda. Estos efectos
dinÃ¡micos son consistentes con una visiÃ³n tradicional en la que los
movimientos en la demanda agregada se acumulan hasta que el ajuste
de precios y salarios lleva a la economÃ­a de vuelta al equilibrio.
Perturbaciones en la oferta:
Las perturbaciones en la oferta aumentan gradualmente la producciÃ³n
con el tiempo, alcanzando su punto mÃ¡ximo despuÃ©s de unos ocho
trimestres en el caso base. Este efecto disminuye y se estabiliza
eventualmente, aunque la estimaciÃ³n a largo plazo es imprecisa. En
cuanto al desempleo, una perturbaciÃ³n positiva inicialmente lo eleva
ligeramente, pero luego se revierte despuÃ©s de algunos trimestres,
regresando al valor original. Estos efectos en el desempleo cesan
aproximadamente cinco aÃ±os despuÃ©s.

Los resultados son consistentes en diferentes enfoques de anÃ¡lisis, pero varÃ­an en la respuesta inicial del
desempleo a las perturbaciones en la demanda, y como las rigideces nominales y reales afectan el
desempleo y la producciÃ³n:
â€¢
â€¢

Las rigideces nominales podrÃ­an justificar por quÃ©, frente a un incremento en la oferta (como un
aumento en la productividad), la demanda total no se eleva inicialmente lo necesario como para
equilibrar el incremento en la producciÃ³n y mantener estable el desempleo.
Las rigideces de los salarios reales pueden justificar por quÃ© los incrementos en la productividad
pueden reducir el desempleo despuÃ©s de algunos trimestres, lo cual perdura hasta que los
salarios reales se adaptan al nuevo nivel de productividad mÃ¡s alto.

Las figuras 1 y 2 analizan la relaciÃ³n entre el desempleo y la producciÃ³n, conocida como la ley de Okun.
Bajo diferentes perturbaciones, esta relaciÃ³n varÃ­a, ya que mientras que las perturbaciones en la demanda
muestran una relaciÃ³n cercana entre la producciÃ³n y el desempleo, las perturbaciones en la oferta no la
muestran.
A largo plazo, la producciÃ³n se mantiene alta, pero el desempleo regresa a su nivel inicial. Esto sugiere
un coeficiente de Okun mayor para las perturbaciones en la oferta que para las perturbaciones
en la demanda.

5. Contribuciones relativas de las perturbaciones de demanda y oferta
DespuÃ©s de analizar los efectos dinÃ¡micos de cada tipo de perturbaciÃ³n, evaluamos su contribuciÃ³n
relativa a las fluctuaciones en producciÃ³n y desempleo de dos formas, a y b:
a) Perturbaciones de la demanda y los ciclos de negocios de NBER
Se compararÃ¡n las series de tiempo histÃ³ricas del componente de demanda de la producciÃ³n con la
cronologÃ­a de los ciclos econÃ³micos del NBER (BurÃ³ Nacional de InvestigaciÃ³n EconÃ³mica) de manera
informal. Podemos formar los componentes de demanda de la estimaciÃ³n del proceso conjunto para
producciÃ³n y desempleo, los que representan los caminos temporales de producciÃ³n y desempleo sin
perturbaciones en la oferta
Al establecer las innovaciones de demanda en cero, generamos las series temporales de los
"componentes de oferta". La restricciÃ³n identificativa de que las perturbaciones de demanda no tienen
efecto a largo plazo en la producciÃ³n hace que el componente de demanda en el nivel de producciÃ³n sea
estacionario
Las series temporales de estos componentes se presentan en las Figuras 7 a 10. Superpuestas en estas
series temporales estÃ¡n los picos y valles del NBER. Los picos se dibujan como lÃ­neas verticales sobre
el eje horizontal, y los valles como lÃ­neas verticales debajo del eje.

Los altibajos del componente de demanda en la producciÃ³n coinciden estrechamente con los ciclos
econÃ³micos del NBER. Las recesiones de 1974-1975 y 1979-1980 se atribuyen aproximadamente por
igual a perturbaciones adversas en la oferta y la demanda, segÃºn nuestras estimaciones. Las
perturbaciones negativas en la oferta preceden a las negativas en la demanda en la recesiÃ³n de 1974-75,
mientras que en la de 1979-80, una gran perturbaciÃ³n negativa en la oferta es seguida por una en la
demanda un aÃ±o despuÃ©s.
Es importante notar que el componente de oferta en la producciÃ³n, presentado en la Figura 7, claramente
no es una tendencia determinista. Exhibe un crecimiento mÃ¡s lento a finales de la dÃ©cada de 1950, asÃ­
como en la dÃ©cada de 1970.
Las Figuras 9 y 10 revelan los componentes de oferta y demanda en el desempleo. Las fluctuaciones del
desempleo por demanda se asemejan a las de la demanda en el PIB, lo que confirma nuestro hallazgo
anterior sobre las respuestas opuestas del desempleo y el crecimiento de la producciÃ³n a las
perturbaciones de la demanda. El modelo indica que las perturbaciones en la oferta contribuyen
significativamente a las variaciones en el desempleo, especialmente con aumentos en la dÃ©cada de 1950
y durante las crisis petroleras de la dÃ©cada de 1970.
b) DescomposiciÃ³n de Varianza
El anÃ¡lisis previo es empÃ­rico. En este caso, se usarÃ¡ una evaluaciÃ³n estadÃ­stica formal a travÃ©s de las
descomposiciones de varianza de la producciÃ³n y el desempleo en perturbaciones de oferta y demanda
en varios momentos.
Las Tablas 2 y 2A-C muestran cÃ³mo se distribuye la variabilidad en diferentes casos. El error de
pronÃ³stico se descompone en la contribuciÃ³n de la demanda y la oferta. Los nÃºmeros en las tablas
indican el porcentaje de varianza del error de pronÃ³stico atribuible a la demanda, con la contribuciÃ³n de

la oferta representada por el complemento a 100. Los nÃºmeros entre parÃ©ntesis muestran el rango de un
desvÃ­o estÃ¡ndar. Nuestras restricciones identificativas solo limitan la contribuciÃ³n de las perturbaciones
en la oferta a medida que aumenta el horizonte, dejando otros aspectos sin restricciones.

Dos conclusiones importantes se desprenden de estas tablas:
Primero, los datos no brindan una respuesta precisa sobre la contribuciÃ³n relativa de las
perturbaciones en la demanda y la oferta a los cambios en la producciÃ³n a corto y mediano plazo.
Esto se debe a que los resultados varÃ­an segÃºn diferentes tratamientos.
Por ejemplo, en el caso base, las perturbaciones en la demanda representan el 98% de las fluctuaciones
en la producciÃ³n a cuatro trimestres, y esta contribuciÃ³n disminuye al 79% cuando no se permite un
cambio, pero hay una tendencia temporal en el desempleo, y disminuye al 39% si no hay cambios ni
tendencia. AdemÃ¡s, los mÃ¡rgenes de error estÃ¡ndar son bastante grandes en cada caso, lo que indica
incertidumbre en las estimaciones.
En segundo lugar, las estimaciones sobre cÃ³mo contribuyen diferentes perturbaciones al desempleo
no muestran mucha variaciÃ³n en los distintos enfoques de cambio y tendencia. La influencia de las
perturbaciones en la demanda, a cuatro trimestres, en las fluctuaciones del desempleo varÃ­a del 80% al
96%. En todos los casos, parece que las perturbaciones en la demanda son bastante significativas para
las fluctuaciones en el desempleo en todos los horizontes.
6. Conclusiones y extensiones
Se asumieron dos tipos de perturbaciones en la producciÃ³n y el desempleo, una permanente (oferta, se
acumula durante mucho tiempo) y otra transitoria (demanda, efecto de montÃ­culo que desaparece en
unos aÃ±os). Las perturbaciones en la demanda contribuyen significativamente a las fluctuaciones de
corto y mediano plazo en la producciÃ³n, pero no podemos cuantificar esto con precisiÃ³n debido a la falta
de datos detallados.
Por el lado de las extensiones, se recomiendan dos cosas: Primero, analizar mÃ¡s variables macro junto
con nuestros componentes de oferta y demanda del PIB (y los resultados preliminares ya respaldan
nuestra interpretaciÃ³n de los choques). Segundo, ampliar el sistema para incluir desempleo, producciÃ³n,
precios y salarios, lo que nos permitirÃ¡ explorar diferentes preguntas desde otra perspectiva, y ayudarÃ¡
a identificar mejor las perturbaciones de oferta y demanda

